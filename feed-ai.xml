<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI-Pulse - AI - Artificial Intelligence</title>
    <link>https://thephoenixagency.github.io/AI-Pulse</link>
    <description>AI - Artificial Intelligence news from AI-Pulse</description>
    <language>en</language>
    <lastBuildDate>Tue, 17 Feb 2026 16:54:55 GMT</lastBuildDate>
    <atom:link href="https://thephoenixagency.github.io/AI-Pulse/feed-ai.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title><![CDATA[Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment]]></title>
      <link>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</link>
      <description><![CDATA[Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems â€” trained in just four days using 48 of Nvidia's latest B200 graphics processors.
The model, called NousCoder-14B, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment:]]></description>
      <pubDate>Wed, 07 Jan 2026 20:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</guid>
    </item>
    <item>
      <title><![CDATA[Codex is Open Sourcing AI models]]></title>
      <link>https://huggingface.co/blog/hf-skills-training-codex</link>
      <description><![CDATA[Back to Articles GOAL: End-to-end Machine Learning experiments Setup and Install Install Codex Install the Hugging Face Skills Connect to Hugging Face Your first AI Experiment Instruct Codex to do an end-to-end fine-tuning experiment Updating the Training Report Dataset Validation Review Before Submitting Track Progress using the Training Report Use Your Model Hardware and Cost What's Next Resources Codex Hugging Face Skills Building on our work to get Claude Code to train open source models, we are now getting Codex to go further.]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hf-skills-training-codex</guid>
    </item>
    <item>
      <title><![CDATA[Anthropic lÃ¨ve 30 milliards de dollars et talonne dÃ©sormais OpenAI]]></title>
      <link>https://siecledigital.fr/2026/02/16/anthropic-senvole-a-380-milliards-de-dollars/</link>
      <description><![CDATA[La bataille des valorisations dans lâ€™intelligence artificielle franchit un nouveau cap. En effet, dans un communiquÃ© de presse, lâ€™amÃ©ricain Anthropic annonce une valorisation de 380 milliards de dollars Ã  lâ€™issue dâ€™une levÃ©e de fonds massive de 30 milliards de dollars. Une opÃ©ration qui confirme lâ€™emballement des marchÃ©s pour les acteurs capables de monÃ©tiser lâ€™IA Ã  [â€¦]]]></description>
      <pubDate>Mon, 16 Feb 2026 10:28:19 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/anthropic-senvole-a-380-milliards-de-dollars/</guid>
    </item>
    <item>
      <title><![CDATA[AprÃ¨s des milliards investis, Microsoft prend ses distances avec OpenAI et devient concurrent direct]]></title>
      <link>https://siecledigital.fr/2026/02/16/microsoft-prepare-sa-rupture-avec-openai/</link>
      <description><![CDATA[Longtemps prÃ©sentÃ©e comme lâ€™alliance la plus structurante de lâ€™intelligence artificielle, la relation entre Microsoft et OpenAI semble entrer dans une nouvelle phase. AprÃ¨s avoir investi plus de 13 milliards de dollars et intÃ©grÃ© massivement les modÃ¨les de lâ€™entreprise dans ses produits, Microsoft ne veut plus dÃ©pendre de son partenaire historique. Dans une interview accordÃ©e au [â€¦]]]></description>
      <pubDate>Mon, 16 Feb 2026 10:24:22 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/microsoft-prepare-sa-rupture-avec-openai/</guid>
    </item>
    <item>
      <title><![CDATA[Measuring Open-Source Llama Nemotron Models on DeepResearch Bench]]></title>
      <link>https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent</link>
      <description><![CDATA[Measuring Open-Source Llama Nemotron Models on DeepResearch Bench]]></description>
      <pubDate>Mon, 04 Aug 2025 19:51:50 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent</guid>
    </item>
    <item>
      <title><![CDATA[INESIA : la France se dote dâ€™un nouveau bouclier pour encadrer les IA avancÃ©es]]></title>
      <link>https://siecledigital.fr/2026/02/16/inesia-la-france-structure-sa-strategie-de-securite-de-lia/</link>
      <description><![CDATA[La France poursuit la structuration de son Ã©cosystÃ¨me autour de lâ€™intelligence artificielle. En effet, lâ€™INESIA (Institut National pour lâ€™Evaluation et la SÃ©curitÃ© de lâ€™IA) vient dâ€™adopter sa feuille de route pour la pÃ©riode 2026-2027. DerriÃ¨re ce document stratÃ©gique, lâ€™ambition est de bÃ¢tir une capacitÃ© nationale dâ€™Ã©valuation des systÃ¨mes dâ€™IA avancÃ©s, dans une logique de souverainetÃ© [â€¦]]]></description>
      <pubDate>Tue, 17 Feb 2026 10:43:20 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/inesia-la-france-structure-sa-strategie-de-securite-de-lia/</guid>
    </item>
    <item>
      <title><![CDATA[Cette nouvelle IA ultra rÃ©aliste inquiÃ¨te Hollywood et dÃ©clenche une offensive de Disney]]></title>
      <link>https://siecledigital.fr/2026/02/16/disney-declare-la-guerre-a-seedance-20/</link>
      <description><![CDATA[Ã€ peine lancÃ©, le modÃ¨le vidÃ©o Seedance 2.0 de ByteDance dÃ©clenche dÃ©jÃ  une tempÃªte juridique. Alors que les internautes sâ€™enthousiasment pour ses performances spectaculaires, The Walt Disney Company a dÃ©cidÃ© de contre-attaquer. Le studio accuse la maison mÃ¨re de TikTok dâ€™avoir entraÃ®nÃ© son intelligence artificielle sur son catalogue, sans autorisation. Une mise en demeure pour [â€¦]]]></description>
      <pubDate>Mon, 16 Feb 2026 10:26:04 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/disney-declare-la-guerre-a-seedance-20/</guid>
    </item>
    <item>
      <title><![CDATA[CybersÃ©curitÃ© 2026 : lâ€™IA accÃ©lÃ¨re les attaques, la France en premiÃ¨re ligne]]></title>
      <link>https://siecledigital.fr/2026/02/12/cybersecurite-2026-lia-accelere-les-attaques-la-france-en-premiere-ligne/</link>
      <description><![CDATA[Lâ€™Ã©dition 2026 du Cyber Security Report de Check Point met en lumiÃ¨re une transformation structurelle des attaques observÃ©es tout au long de 2025. Entre lâ€™accÃ©lÃ©ration des opÃ©rations, lâ€™industrialisation des campagnes, et la montÃ©e en puissance de lâ€™intelligence artificielle, le paysage Ã©volue Ã  un rythme soutenu, avec des consÃ©quences directes pour les entreprises et les Ã‰tats. [â€¦]]]></description>
      <pubDate>Fri, 13 Feb 2026 07:56:18 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/12/cybersecurite-2026-lia-accelere-les-attaques-la-france-en-premiere-ligne/</guid>
    </item>
    <item>
      <title><![CDATA[X va bientÃ´t permettre dâ€™envoyer de lâ€™argent directement dans lâ€™application]]></title>
      <link>https://siecledigital.fr/2026/02/12/x-money-elon-musk-lance-les-paiements-sur-x-au-printemps-2026/</link>
      <description><![CDATA[Depuis le rachat de Twitter en 2022, Elon Musk ne cache plus son ambition de transformer X en une Â«Â everything appÂ Â» capable de centraliser lâ€™ensemble des usages numÃ©riques du quotidien. Entre la messagerie, la vidÃ©o, les contenus, et lâ€™intelligence artificielle, la plateforme Ã©volue progressivement vers un modÃ¨le intÃ©grÃ©. Une nouvelle Ã©tape sâ€™apprÃªte dÃ©sormais Ã  Ãªtre [â€¦]]]></description>
      <pubDate>Fri, 13 Feb 2026 07:55:52 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/12/x-money-elon-musk-lance-les-paiements-sur-x-au-printemps-2026/</guid>
    </item>
    <item>
      <title><![CDATA[The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</link>
      <description><![CDATA[The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+]]></description>
      <pubDate>Tue, 03 Feb 2026 15:03:19 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</guid>
    </item>
    <item>
      <title><![CDATA[One Year Since the â€œDeepSeek Momentâ€]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</link>
      <description><![CDATA[Back to Articles The Seeds of Chinaâ€™s Organic Open Source AI Ecosystem DeepSeek R1: A Turning Point From DeepSeek to AI+: Strategic Realignmentt Global Reception and Response This is the first blog in a series that will examine Chinaâ€™s open source communityâ€™s historical advancements in the past year and its reverberations in shaping the entire ecosystem. Much of 2025â€™s progress can be traced back to Januaryâ€™s â€œDeepSeek Momentâ€, when Hangzhou-based AI company DeepSeek released their R-1 model.]]></description>
      <pubDate>Tue, 20 Jan 2026 15:02:10 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</guid>
    </item>
    <item>
      <title><![CDATA[Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI]]></title>
      <link>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</link>
      <description><![CDATA[Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company's workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.
The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce's most aggressive move yet to position Slack at the center of the emerging "agentic AI" movement â€” where software agents work alongside humans to complete complex tasks.]]></description>
      <pubDate>Tue, 13 Jan 2026 13:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture]]></title>
      <link>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</link>
      <description><![CDATA[Back to Articles Discover more in our official blogpost, featuring an interactive experience The journey of building world-class Arabic language models has been one of continuous learning and iteration. Today, we're excited to announce Falcon-H1-Arabic, our most advanced Arabic language model family to date, representing a significant leap forward in both architecture and capabilities. This release embodies months of research, community feedback, and technical innovation, culminating in three powerful models that set new standards for Arabic natural language processing. Building on Success:]]></description>
      <pubDate>Mon, 05 Jan 2026 09:16:51 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</guid>
    </item>
    <item>
      <title><![CDATA[huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning]]></title>
      <link>https://huggingface.co/blog/huggingface-hub-v1</link>
      <description><![CDATA[Back to Articles The Story Behind the Library The Foundation Years (2020-2021) The Great Shift: Git to HTTP (2022) An Expanding API Surface (2022â€“2024) Ready. Xet. Go! (2024-2025) Measuring Growth and Impact Building for the Next Decade Modern HTTP Infrastructure with httpx and hf_xet Agents Made Simple with MCP and Tiny-Agents A Fully-Featured CLI for Modern Workflows Cleaning House for the Future The Migration Guide Acknowledgments TL;DR:]]></description>
      <pubDate>Mon, 27 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface-hub-v1</guid>
    </item>
    <item>
      <title><![CDATA[AI for Food Allergies]]></title>
      <link>https://huggingface.co/blog/hugging-science/ai-for-food-allergies</link>
      <description><![CDATA[Back to Articles Current State of The Art: Where AI Meets Food Allergy Research The need for data Collection release The Protein and Molecular Allergenicity Layer The Clinical, Immunological, and Therapeutic Layer The Food, Ingredient, and Regulatory Layer Accessing the collection Whatâ€™s coming next? Final remarks Appendix SDAP 2.0: Structural Database of Allergenic Proteins DAVIS: Kinase inhibitor binding affinities QsarDB: repository for (Q)SAR models e-Drug3D Database Stanford Drug Data: Offsides/Twosides DrugCentral: open drug information repository MedKG: medical knowledge graph PDBBind+:]]></description>
      <pubDate>Thu, 16 Oct 2025 22:38:11 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hugging-science/ai-for-food-allergies</guid>
    </item>
    <item>
      <title><![CDATA[MCP for Research: How to Connect AI to Research Tools]]></title>
      <link>https://huggingface.co/blog/mcp-for-research</link>
      <description><![CDATA[Back to Articles Research Discovery: Three Layers of Abstraction 1. Manual Research 2. Scripted Tools 3. MCP Integration Setup and Usage Quick Setup Learn More Academic research involves frequent research discovery: finding papers, code, related models and datasets. This typically means switching between platforms like arXiv, GitHub, and Hugging Face, manually piecing together connections.
The Model Context Protocol (MCP) is a standard that allows agentic models to communicate with external tools and data sources.]]></description>
      <pubDate>Mon, 18 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/mcp-for-research</guid>
    </item>
    <item>
      <title><![CDATA[Kimina-Prover: Applying Test-time RL Search on Large Formal Reasoning Models]]></title>
      <link>https://huggingface.co/blog/AI-MO/kimina-prover</link>
      <description><![CDATA[Back to Articles Numina &amp; Kimi Team Figure 1: Performance comparison of theorem proving models on the miniF2F-test dataset. We're excited to announce the release of Kimina-Prover-72B, our state-of-the-art theorem proving model trained with the Kimi k1.5[1] RL pipeline based on Qwen2.5-72B [2]. Alongside it, we are also releasing two distilled variants: Kimina-Prover-Distill-8B and 1.7B (based on Qwen3-8B and Qwen3-1.7B[3] respectively).
Our key innovations include: Test-Time Reinforcement Learning Search:]]></description>
      <pubDate>Thu, 10 Jul 2025 12:54:19 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/AI-MO/kimina-prover</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI recrute le crÃ©ateur dâ€™OpenClaw, lâ€™IA qui agit Ã  votre place sur lâ€™ordinateur et dont tout le monde parle]]></title>
      <link>https://siecledigital.fr/2026/02/16/openai-recrute-le-createur-dopenclaw-pour-accelerer-sur-les-agents-ia/</link>
      <description><![CDATA[Depuis lâ€™arrivÃ©e des navigateurs IA comme Comet de Perplexity, le secteur de lâ€™IA sâ€™oriente vers des agents capables dâ€™agir directement sur nos appareils, dâ€™automatiser des tÃ¢ches et mÃªme dâ€™interagir avec des services tiers. Câ€™est dans ce contexte que le crÃ©ateur dâ€™un projet devenu viral rejoint lâ€™un des acteurs les plus influents du marchÃ©. En effet, [â€¦]]]></description>
      <pubDate>Tue, 17 Feb 2026 10:41:58 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/openai-recrute-le-createur-dopenclaw-pour-accelerer-sur-les-agents-ia/</guid>
    </item>
    <item>
      <title><![CDATA[After all the hype, some AI experts donâ€™t think OpenClaw is all that exciting]]></title>
      <link>https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/</link>
      <description><![CDATA["From an AI research perspective, this is nothing novel," one expert told TechCrunch.]]></description>
      <pubDate>Mon, 16 Feb 2026 13:15:00 GMT</pubDate>
      <source>TechCrunch AI</source>
      <category>ai</category>
      <guid>https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/</guid>
    </item>
    <item>
      <title><![CDATA[OpenClaw creator Peter Steinberger joins OpenAI]]></title>
      <link>https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/</link>
      <description><![CDATA[OpenAI said OpenClaw will live on as an open source project.]]></description>
      <pubDate>Sun, 15 Feb 2026 22:28:02 GMT</pubDate>
      <source>TechCrunch AI</source>
      <category>ai</category>
      <guid>https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/</guid>
    </item>
    <item>
      <title><![CDATA[La bÃªta dâ€™iOS 26.4 apporte des nouveautÃ©s Apple Intelligence aux iPhoneâ€¦Â mais pas en Europe]]></title>
      <link>https://www.numerama.com/tech/2181139-la-beta-dios-26-4-apporte-des-nouveautes-apple-intelligence-aux-iphone-mais-pas-en-europe.html</link>
      <description><![CDATA[Pas de nouveau Siri dans la premiÃ¨re bÃªta d'iOS 26.4, mais de nombreuses Ã©volutions visuelles et quelques changements techniques (RCS chiffrÃ©s, sÃ©curitÃ© antivol par dÃ©faut, etc.) La seule nouveautÃ© qui concerne l'intelligence artificielle est l'introduction de la fonctionnalitÃ© Playlist Playground pour gÃ©nÃ©rer des playlists avec l'IAâ€¦ mais le service est, pour l'instant, indisponible en Europe.]]></description>
      <pubDate>Tue, 17 Feb 2026 09:23:49 GMT</pubDate>
      <source>Numerama Tech</source>
      <category>ai</category>
      <guid>https://www.numerama.com/tech/2181139-la-beta-dios-26-4-apporte-des-nouveautes-apple-intelligence-aux-iphone-mais-pas-en-europe.html</guid>
    </item>
    <item>
      <title><![CDATA[Tuning into the future of collaboration]]></title>
      <link>https://www.technologyreview.com/2026/02/16/1125881/tuning-into-the-future-of-collaboration/</link>
      <description><![CDATA[When work went remote, the sound of business changed. What began as a scramble to make home offices functional has evolved into a revolution in how people hear and are heard. From education to enterprises, companies across industries have reimagined what clear, reliable communication can mean in a hybrid world. For major audio and communicationsâ€¦]]></description>
      <pubDate>Mon, 16 Feb 2026 15:00:00 GMT</pubDate>
      <source>MIT Technology Review</source>
      <category>ai</category>
      <guid>https://www.technologyreview.com/2026/02/16/1125881/tuning-into-the-future-of-collaboration/</guid>
    </item>
    <item>
      <title><![CDATA[OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments]]></title>
      <link>https://huggingface.co/blog/openenv-turing</link>
      <description><![CDATA[Back to Articles What Is OpenEnv? The Calendar Gym: A Production-Grade Benchmark What We Learned Looking Ahead Appendix: Common error cases in tool use Specific error cases found in the wild AI agents often perform impressively in controlled research settings, yet struggle when deployed in real-world systems where they must reason across multiple steps, interact with real tools and APIs, operate under partial information, and recover from errors in stateful, permissioned environmentsâ€”highlighting a persistent gap between research success and production reliability.]]></description>
      <pubDate>Thu, 12 Feb 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openenv-turing</guid>
    </item>
    <item>
      <title><![CDATA[Introducing SyGra Studio]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link>
      <description><![CDATA[Back to Articles Step 1: Configure the data source Step 2: Build the flow visually Step 3: Review and run See it in action! Running Existing Workflows Run the Glaive Code Assistant workflow Get started SyGra 2.0.0 introduces Studio, an interactive environment that turns synthetic data generation into a transparent, visual craft. Instead of juggling YAML files and terminals, you compose flows directly on the canvas, preview datasets before committing, tune prompts with inline variable hints, and watch executions stream liveâ€”all from a single pane.]]></description>
      <pubDate>Thu, 05 Feb 2026 16:52:28 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Daggr: Chain apps programmatically, inspect visually]]></title>
      <link>https://huggingface.co/blog/daggr</link>
      <description><![CDATA[Back to Articles Table of Contents Background Getting Started Node Types Sharing Your Workflows End-to-End Example with Different Nodes Next Steps TL;DR: Daggr is a new, open-source Python library for building AI workflows that connect Gradio apps, ML models, and custom functions. It automatically generates a visual canvas where you can inspect intermediate outputs, rerun individual steps, and manage state for complex pipelines, all in a few lines of Python code!]]></description>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/daggr</guid>
    </item>
    <item>
      <title><![CDATA[Railway secures $100 million to challenge AWS with AI-native cloud infrastructure]]></title>
      <link>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</link>
      <description><![CDATA[Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.
TQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures.]]></description>
      <pubDate>Thu, 22 Jan 2026 14:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</guid>
    </item>
    <item>
      <title><![CDATA[Claude Code costs up to $200 a month. Goose does the same thing for free.]]></title>
      <link>https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free</link>
      <description><![CDATA[The artificial intelligence coding revolution comes with a catch: it's expensive.
Claude Code, Anthropic's terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing â€” ranging from $20 to $200 per month depending on usage â€” has sparked a growing rebellion among the very programmers it aims to serve.
Now, a free alternative is gaining traction.]]></description>
      <pubDate>Mon, 19 Jan 2026 14:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free</guid>
    </item>
    <item>
      <title><![CDATA[Open Responses: What you need to know]]></title>
      <link>https://huggingface.co/blog/open-responses</link>
      <description><![CDATA[Back to Articles What is Open Responses? What do we need to know to build with Open Responses? Client Requests to Open Responses Changes for Inference Clients and Providers Open Responses for Routing Tools Sub Agent Loops Next Steps Open Responses is a new and open inference standard. Initiated by OpenAI, built by the open source AI community, and backed by the Hugging Face ecosystem, Open Responses is based on the Responses API and is designed for the future of Agents. In this blog post, weâ€™ll look at how Open Responses works and why the open source community should use Open Responses.]]></description>
      <pubDate>Thu, 15 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/open-responses</guid>
    </item>
    <item>
      <title><![CDATA[NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI]]></title>
      <link>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</link>
      <description><![CDATA[Back to Articles NVIDIA Cosmos Reason 2: Reasoning Vision Language Model for Physical AI Key Highlights Popular Use Cases Other Models From The Cosmos Family: Cosmos Predict 2.5 Resources NVIDIA today released Cosmos Reason 2, the latest advancement in open, reasoning vision language models for physical AI. Cosmos Reason 2 surpasses its previous version in accuracy and tops the Physical AI Bench and Physical Reasoning leaderboards as the #1 open model for visual understanding. NVIDIA Cosmos Reason 2:]]></description>
      <pubDate>Mon, 05 Jan 2026 22:56:51 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</guid>
    </item>
    <item>
      <title><![CDATA[The Open Evaluation Standard: Benchmarking NVIDIA Nemotron 3 Nano with NeMo Evaluator]]></title>
      <link>https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe</link>
      <description><![CDATA[Back to Articles It has become increasingly challenging to assess whether a modelâ€™s
reported improvements reflect genuine advances or variations in
evaluation conditions, dataset composition, or training data that
mirrors benchmark tasks. The NVIDIA Nemotron approach to openness
addresses this by publishing transparent and reproducible evaluation
recipes that make results independently verifiable.
NVIDIA released Nemotron 3 Nano 30B
A3B
with an explicitly open evaluation approach to make that distinction
clear.]]></description>
      <pubDate>Wed, 17 Dec 2025 13:22:18 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe</guid>
    </item>
    <item>
      <title><![CDATA[We Got Claude to Fine-Tune an Open Source LLM]]></title>
      <link>https://huggingface.co/blog/hf-skills-training</link>
      <description><![CDATA[We Got Claude to Fine-Tune an Open Source LLM]]></description>
      <pubDate>Thu, 04 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hf-skills-training</guid>
    </item>
    <item>
      <title><![CDATA[Building Deep Research: How we Achieved State of the Art]]></title>
      <link>https://huggingface.co/blog/Tavily/tavily-deep-research</link>
      <description><![CDATA[Back to Articles Building for the Future Agent Harness Models Tools Takeaways Context Engineering â€” An Exercise in Curation Context-Managed Web Retrieval Modeling the Human-Web Interaction Doing More with Less Productionizing Agents â€” an Ongoing Challenge Engineering with Non-Determinism Optimal Tooling â€” Less is More Evals Research agents are rapidly becoming one of the most important applications of AI. Research is a foundational knowledge-work task: collecting, reading, and synthesizing information underpins everything from writing and decision-making to coding itself.]]></description>
      <pubDate>Mon, 24 Nov 2025 17:40:14 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Tavily/tavily-deep-research</guid>
    </item>
    <item>
      <title><![CDATA[Building for an Open Future - our new partnership with Google Cloud]]></title>
      <link>https://huggingface.co/blog/google-cloud</link>
      <description><![CDATA[Back to Articles A Partnership for Google Cloud customers The Gateway to Open Models - A Fast Lane for Google Cloud Customers A partnership for Hugging Face customers Building the open future of AI together Today, we are happy to announce a new and deeper partnership with Google Cloud, to enable companies to build their own AI with open models.
â€œGoogle has made some of the most impactful contributions to open AI, from the OG transformer to the Gemma models. I believe in a future where all companies will build and customize their own AI.]]></description>
      <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/google-cloud</guid>
    </item>
    <item>
      <title><![CDATA[Building the Open Agent Ecosystem Together: Introducing OpenEnv]]></title>
      <link>https://huggingface.co/blog/openenv</link>
      <description><![CDATA[Back to Articles The Problem The Solution The RFCs Use cases Whatâ€™s Next With tools like TRL, TorchForge and verl, the open-source community has shown how to scale AI across complex compute infrastructure. But compute is only one side of the coin. The other side is the developer community; the people and tools that make agentic systems possible. Thatâ€™s why Meta and Hugging Face are partnering to launch the OpenEnv Hub: a shared and open community hub for agentic environments.
Agentic environments define everything an agent needs to perform a task:]]></description>
      <pubDate>Thu, 23 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openenv</guid>
    </item>
    <item>
      <title><![CDATA[Google Cloud C4 Brings a 70% TCO improvement on GPT OSS with Intel and Hugging Face]]></title>
      <link>https://huggingface.co/blog/gpt-oss-on-intel-xeon</link>
      <description><![CDATA[Back to Articles Intel and Hugging Face collaborated to demonstrate the real-world value of upgrading to Googleâ€™s latest C4 Virtual Machine (VM) running on Intel Xeon 6 processors (codenamed Granite Rapids (GNR)). We specifically wanted to benchmark improvements in the text generation performance of OpenAI GPT OSS Large Language Model(LLM). The results are in, and they are impressive, demonstrating a 1.7x improvement in Total Cost of Ownership(TCO) over the previous-generation Google C3 VM instances. The Google Cloud C4 VM instance further resulted in:]]></description>
      <pubDate>Thu, 16 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/gpt-oss-on-intel-xeon</guid>
    </item>
    <item>
      <title><![CDATA[Get your VLM running in 3 simple steps on Intel CPUs]]></title>
      <link>https://huggingface.co/blog/openvino-vlm</link>
      <description><![CDATA[Back to Articles With the growing capability of large language models (LLMs), a new class of models has emerged: Vision Language Models (VLMs). These models can analyze images and videos to describe scenes, create captions, and answer questions about visual content.
While running AI models on your own device can be difficult as these models are often computationally demanding, it also offers significant benefits: including improved privacy since your data stays on your machine, and enhanced speed and reliability because you're not dependent on an internet connection or external servers.]]></description>
      <pubDate>Wed, 15 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openvino-vlm</guid>
    </item>
    <item>
      <title><![CDATA[Nemotron-Personas-India: Synthesized Data for Sovereign AI]]></title>
      <link>https://huggingface.co/blog/nvidia/nemotron-personas-india</link>
      <description><![CDATA[Back to Articles Open Data for India's AI Future Whatâ€™s in the Dataset? How We Built It Data Generation Pipeline Embedded Cultural Context Private By Design Who This Is For Practical AI Applications Why It Matters Start Building with Nemotron-Personas-India A compound AI approach to Indian personas grounded in real-world distributions Open Data for India's AI Future India represents one of the world's largest AI opportunities â€” with over 700 million internet users, a multitude of languages, and a rapidly growing developer ecosystem.]]></description>
      <pubDate>Mon, 13 Oct 2025 23:00:42 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nemotron-personas-india</guid>
    </item>
    <item>
      <title><![CDATA[BigCodeArena: Judging code generations end to end with code executions]]></title>
      <link>https://huggingface.co/blog/bigcode/arena</link>
      <description><![CDATA[Back to Articles Motivation The BigCodeArena Platform Real-Time Execution Multi-Language &amp; Framework Support Interactive Testing Multi-Turn Conversations What We've Learned: 5 Months of Community Evaluation Programming Topics in the Wild Language and Framework Popularity User Interaction Patterns Model Rankings from Community Votes Two New Benchmarks: BigCodeReward and AutoCodeArena BigCodeReward: Evaluating Reward Models for Code AutoCodeArena: Automated Code Generation Benchmarks Try It Yourself Open Source Everything What's Next?]]></description>
      <pubDate>Tue, 07 Oct 2025 09:37:25 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/bigcode/arena</guid>
    </item>
    <item>
      <title><![CDATA[SyGra: The One-Stop Framework for Building Data for LLMs andÂ SLMs]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework</link>
      <description><![CDATA[Back to Articles Enter SyGra: One Framework for Every Data Challenge Why SyGraÂ Matters SyGra Architecture Final Thoughts References When we think about building a modelâ€Š-â€Šbe it a Large Language Model (LLM) or a Small Language Model (SLM)â€Š-â€Šthe first thing we need is data. While a vast amount of open data is available, it rarely comes in the exact format required to train or align models.
In practice, we often face scenarios where the raw data isn't enough. We need data that is more structured, domain-specific, complex, or aligned with the task at hand. Let's look at some common situations:]]></description>
      <pubDate>Mon, 22 Sep 2025 06:45:05 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework</guid>
    </item>
    <item>
      <title><![CDATA[SAIR: Accelerating Pharma R&amp;D with AI-Powered Structural Intelligence]]></title>
      <link>https://huggingface.co/blog/SandboxAQ/sair-data-accelerating-drug-discovery-with-ai</link>
      <description><![CDATA[Back to Articles Accessing SAIR 1. Install essentials 2. Authenticate 3. Load the main table (sair.parquet) 4. (Optional) List available structure archives 5. (Optional) Download and extract structures Questions? This summer, SandboxAQ released the Structurally Augmented IC50 Repository (SAIR), the largest dataset of co-folded 3D protein-ligand structures paired with experimentally measured ICâ‚…â‚€ labels, directly linking molecular structure to drug potency and overcoming a longstanding scarcity in training data.]]></description>
      <pubDate>Tue, 02 Sep 2025 16:54:29 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/SandboxAQ/sair-data-accelerating-drug-discovery-with-ai</guid>
    </item>
    <item>
      <title><![CDATA[NVIDIA Releases 6 Million Multi-Lingual Reasoning Dataset]]></title>
      <link>https://huggingface.co/blog/nvidia/multilingual-reasoning-v1</link>
      <description><![CDATA[Back to Articles Authors: Dhruv Nathawani, Shuoyang Ding US, Vitaly Lavrukhin US, Jane Polak Scowcroft US, Oleksii Kuchaiev US NVIDIA continues releasing permissive datasets in support of the open ecosystem with 6 Million Multilingual Reasoning Dataset.
Continuing the success of the recent Nemotron Post-Training Dataset v1 release used in Llama Nemotron Super model, and our Llama Nemotron Post-Training Dataset release earlier this year, weâ€™re excited to release the reasoning dataset translated into five target languages: French, Spanish, German, Italian, and Japanese.]]></description>
      <pubDate>Wed, 20 Aug 2025 22:13:18 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/multilingual-reasoning-v1</guid>
    </item>
    <item>
      <title><![CDATA[Neural Super Sampling is here!]]></title>
      <link>https://huggingface.co/blog/Arm/neural-super-sampling</link>
      <description><![CDATA[Back to Articles Elevated by machine learning Learn about our NSS Model How we trained the model Get started experimenting with NSS today! Neural Super Sampling (NSS), a next-generation AI-powered upscaling solution from Arm is released for graphics and gaming developers to start experimenting today! Elevated by machine learning NSS is designed for real-time performance on future mobile devices with Arm Neural Technology. However, latency depends on implementation factors such as GPU configuration, resolution, and use case.]]></description>
      <pubDate>Tue, 12 Aug 2025 14:52:08 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Arm/neural-super-sampling</guid>
    </item>
    <item>
      <title><![CDATA[ðŸ‡µðŸ‡­ FilBench - Can LLMs Understand and Generate Filipino?]]></title>
      <link>https://huggingface.co/blog/filbench</link>
      <description><![CDATA[Back to Articles FilBench What did we learn from FilBench? Finding #1: Although region-specific LLMs still lag behind GPT-4, collecting data to train these models is still a promising direction Finding #2: Filipino translation is still a difficult task for LLMs Finding #3: Open LLMs Remain a Cost-Effective Choice for Filipino Language Tasks Does your LLM work on Philippine Languages? Try it on FilBench!]]></description>
      <pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/filbench</guid>
    </item>
    <item>
      <title><![CDATA[Introducing AI Sheets: a tool to work with datasets using open AI models!]]></title>
      <link>https://huggingface.co/blog/aisheets</link>
      <description><![CDATA[Introducing AI Sheets: a tool to work with datasets using open AI models!]]></description>
      <pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/aisheets</guid>
    </item>
    <item>
      <title><![CDATA[Welcome GPT OSS, the new open-source model family from OpenAI!]]></title>
      <link>https://huggingface.co/blog/welcome-openai-gpt-oss</link>
      <description><![CDATA[Welcome GPT OSS, the new open-source model family from OpenAI!]]></description>
      <pubDate>Tue, 05 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/welcome-openai-gpt-oss</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face]]></title>
      <link>https://huggingface.co/blog/trackio</link>
      <description><![CDATA[Back to Articles Background Why We Switched to Trackio Using Trackio Installing Usage Visualizing Results Sharing with Spaces Integrated with Transformers and Accelerate Design Principles Next Steps TL;DR: Trackio is a new, open-source, and free experiment tracking Python library that provides a local dashboard and seamless integration with Hugging Face Spaces for easy sharing and collaboration. Since trackio is a drop-in replacement for wandb, you can get started with the syntax you already know!]]></description>
      <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/trackio</guid>
    </item>
    <item>
      <title><![CDATA[TimeScope: How Long Can Your Video Large Multimodal Model Go?]]></title>
      <link>https://huggingface.co/blog/timescope-video-lmm-benchmark</link>
      <description><![CDATA[Back to Articles TL;DR Table of Contents Why TimeScope? Motivating a Better Benchmark for Video Benchmark Design 1. Localized Retrieval 2. Information Synthesis 3. Fine-Grained Temporal Perception Evaluations &amp; Leaderboard What did we learn? Conclusion â€“ Letâ€™s Raise the Bar for Long-Video AI TL;DR TimeScope is an open-source benchmark designed to measure how well vision-language models understand long videos. By adding short â€œneedleâ€ clips into videos ranging from 1 minute to 8 hours, it evaluates three skills: localized retrieval, information synthesis, fine-grained temporal perception.]]></description>
      <pubDate>Wed, 23 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/timescope-video-lmm-benchmark</guid>
    </item>
    <item>
      <title><![CDATA[Five Big Improvements to Gradio MCP Servers]]></title>
      <link>https://huggingface.co/blog/gradio-mcp-updates</link>
      <description><![CDATA[Back to Articles Seamless Local File Support Real-time Progress Notifications Transform OpenAPI Specs to MCP in One Line Improvements to Authentication Modifying Tool Descriptions Conclusion Gradio is an open-source Python package for creating AI-powered web applications. Gradio is compliant with the MCP server protocol and powers thousands of MCP servers hosted on Hugging Face Spaces. The Gradio team is betting big on Gradio and Spaces being the best way to build and host AI-powered MCP servers.]]></description>
      <pubDate>Thu, 17 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/gradio-mcp-updates</guid>
    </item>
    <item>
      <title><![CDATA[Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders]]></title>
      <link>https://huggingface.co/blog/reachy-mini</link>
      <description><![CDATA[Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders]]></description>
      <pubDate>Wed, 09 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/reachy-mini</guid>
    </item>
  </channel>
</rss>