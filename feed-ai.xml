<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI-Pulse - AI - Artificial Intelligence</title>
    <link>https://thephoenixagency.github.io/AI-Pulse</link>
    <description>AI - Artificial Intelligence news from AI-Pulse</description>
    <language>en</language>
    <lastBuildDate>Wed, 18 Feb 2026 08:43:06 GMT</lastBuildDate>
    <atom:link href="https://thephoenixagency.github.io/AI-Pulse/feed-ai.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title><![CDATA[Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment]]></title>
      <link>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</link>
      <description><![CDATA[Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems â€” trained in just four days using 48 of Nvidia's latest B200 graphics processors.
The model, called NousCoder-14B, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment:]]></description>
      <pubDate>Wed, 07 Jan 2026 20:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</guid>
    </item>
    <item>
      <title><![CDATA[Codex is Open Sourcing AI models]]></title>
      <link>https://huggingface.co/blog/hf-skills-training-codex</link>
      <description><![CDATA[Back to Articles GOAL: End-to-end Machine Learning experiments Setup and Install Install Codex Install the Hugging Face Skills Connect to Hugging Face Your first AI Experiment Instruct Codex to do an end-to-end fine-tuning experiment Updating the Training Report Dataset Validation Review Before Submitting Track Progress using the Training Report Use Your Model Hardware and Cost What's Next Resources Codex Hugging Face Skills Building on our work to get Claude Code to train open source models, we are now getting Codex to go further.]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hf-skills-training-codex</guid>
    </item>
    <item>
      <title><![CDATA[Measuring Open-Source Llama Nemotron Models on DeepResearch Bench]]></title>
      <link>https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent</link>
      <description><![CDATA[Back to Articles Core Stack: Model Choices and Technical Innovations Deep Reasoning with Llama Nemotron Evaluation: Transparency and Robustness in Metrics Benchmark Results: DeepResearch Bench For the Hugging Face Developer Community Takeaways Contributors: David Austin, Raja Biswas, Gilberto Titericz Junior, NVIDIA]]></description>
      <pubDate>Mon, 04 Aug 2025 19:51:50 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent</guid>
    </item>
    <item>
      <title><![CDATA[Anthropic lÃ¨ve 30 milliards de dollars et talonne dÃ©sormais OpenAI]]></title>
      <link>https://siecledigital.fr/2026/02/16/anthropic-senvole-a-380-milliards-de-dollars/</link>
      <description><![CDATA[La bataille des valorisations dans lâ€™intelligence artificielle franchit un nouveau cap. En effet, dans un communiquÃ© de presse, lâ€™amÃ©ricain Anthropic annonce une valorisation de 380 milliards de dollars Ã  lâ€™issue dâ€™une levÃ©e de fonds massive de 30 milliards de dollars. Une opÃ©ration qui confirme lâ€™emballement des marchÃ©s pour les acteurs capables de monÃ©tiser lâ€™IA Ã  [â€¦]]]></description>
      <pubDate>Mon, 16 Feb 2026 10:28:19 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/anthropic-senvole-a-380-milliards-de-dollars/</guid>
    </item>
    <item>
      <title><![CDATA[AprÃ¨s des milliards investis, Microsoft prend ses distances avec OpenAI et devient concurrent direct]]></title>
      <link>https://siecledigital.fr/2026/02/16/microsoft-prepare-sa-rupture-avec-openai/</link>
      <description><![CDATA[Longtemps prÃ©sentÃ©e comme lâ€™alliance la plus structurante de lâ€™intelligence artificielle, la relation entre Microsoft et OpenAI semble entrer dans une nouvelle phase. AprÃ¨s avoir investi plus de 13 milliards de dollars et intÃ©grÃ© massivement les modÃ¨les de lâ€™entreprise dans ses produits, Microsoft ne veut plus dÃ©pendre de son partenaire historique. Dans une interview accordÃ©e au [â€¦]]]></description>
      <pubDate>Mon, 16 Feb 2026 10:24:22 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/microsoft-prepare-sa-rupture-avec-openai/</guid>
    </item>
    <item>
      <title><![CDATA[Hugging Face and VirusTotal collaborate to strengthen AI security]]></title>
      <link>https://huggingface.co/blog/virustotal</link>
      <description><![CDATA[Back to Articles Why this matters How the collaboration works Benefits for the community Join us Weâ€™re excited to announce a new collaboration between Hugging Face and VirusTotal, the worldâ€™s leading threat-intelligence and malware analysis platform.
This collaboration enhances the security of files shared across the Hugging Face Hub, helping protect the machine learning community from malicious or compromised assets.
TL;DR - Starting today, every one of the 2.2M+ public model and datasets repositories on the Hugging Face Hub is being continuously scanned with VirusTotal.]]></description>
      <pubDate>Wed, 22 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/virustotal</guid>
    </item>
    <item>
      <title><![CDATA[INESIA : la France se dote dâ€™un nouveau bouclier pour encadrer les IA avancÃ©es]]></title>
      <link>https://siecledigital.fr/2026/02/16/inesia-la-france-structure-sa-strategie-de-securite-de-lia/</link>
      <description><![CDATA[La France poursuit la structuration de son Ã©cosystÃ¨me autour de lâ€™intelligence artificielle. En effet, lâ€™INESIA (Institut National pour lâ€™Evaluation et la SÃ©curitÃ© de lâ€™IA) vient dâ€™adopter sa feuille de route pour la pÃ©riode 2026-2027. DerriÃ¨re ce document stratÃ©gique, lâ€™ambition est de bÃ¢tir une capacitÃ© nationale dâ€™Ã©valuation des systÃ¨mes dâ€™IA avancÃ©s, dans une logique de souverainetÃ© [â€¦]]]></description>
      <pubDate>Tue, 17 Feb 2026 10:43:20 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/inesia-la-france-structure-sa-strategie-de-securite-de-lia/</guid>
    </item>
    <item>
      <title><![CDATA[Cette nouvelle IA ultra rÃ©aliste inquiÃ¨te Hollywood et dÃ©clenche une offensive de Disney]]></title>
      <link>https://siecledigital.fr/2026/02/16/disney-declare-la-guerre-a-seedance-20/</link>
      <description><![CDATA[Ã€ peine lancÃ©, le modÃ¨le vidÃ©o Seedance 2.0 de ByteDance dÃ©clenche dÃ©jÃ  une tempÃªte juridique. Alors que les internautes sâ€™enthousiasment pour ses performances spectaculaires, The Walt Disney Company a dÃ©cidÃ© de contre-attaquer. Le studio accuse la maison mÃ¨re de TikTok dâ€™avoir entraÃ®nÃ© son intelligence artificielle sur son catalogue, sans autorisation. Une mise en demeure pour [â€¦]]]></description>
      <pubDate>Mon, 16 Feb 2026 10:26:04 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/disney-declare-la-guerre-a-seedance-20/</guid>
    </item>
    <item>
      <title><![CDATA[CybersÃ©curitÃ© 2026 : lâ€™IA accÃ©lÃ¨re les attaques, la France en premiÃ¨re ligne]]></title>
      <link>https://siecledigital.fr/2026/02/12/cybersecurite-2026-lia-accelere-les-attaques-la-france-en-premiere-ligne/</link>
      <description><![CDATA[Lâ€™Ã©dition 2026 du Cyber Security Report de Check Point met en lumiÃ¨re une transformation structurelle des attaques observÃ©es tout au long de 2025. Entre lâ€™accÃ©lÃ©ration des opÃ©rations, lâ€™industrialisation des campagnes, et la montÃ©e en puissance de lâ€™intelligence artificielle, le paysage Ã©volue Ã  un rythme soutenu, avec des consÃ©quences directes pour les entreprises et les Ã‰tats. [â€¦]]]></description>
      <pubDate>Fri, 13 Feb 2026 07:56:18 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/12/cybersecurite-2026-lia-accelere-les-attaques-la-france-en-premiere-ligne/</guid>
    </item>
    <item>
      <title><![CDATA[X va bientÃ´t permettre dâ€™envoyer de lâ€™argent directement dans lâ€™application]]></title>
      <link>https://siecledigital.fr/2026/02/12/x-money-elon-musk-lance-les-paiements-sur-x-au-printemps-2026/</link>
      <description><![CDATA[Depuis le rachat de Twitter en 2022, Elon Musk ne cache plus son ambition de transformer X en une Â«Â everything appÂ Â» capable de centraliser lâ€™ensemble des usages numÃ©riques du quotidien. Entre la messagerie, la vidÃ©o, les contenus, et lâ€™intelligence artificielle, la plateforme Ã©volue progressivement vers un modÃ¨le intÃ©grÃ©. Une nouvelle Ã©tape sâ€™apprÃªte dÃ©sormais Ã  Ãªtre [â€¦]]]></description>
      <pubDate>Fri, 13 Feb 2026 07:55:52 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/12/x-money-elon-musk-lance-les-paiements-sur-x-au-printemps-2026/</guid>
    </item>
    <item>
      <title><![CDATA[The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</link>
      <description><![CDATA[The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+]]></description>
      <pubDate>Tue, 03 Feb 2026 15:03:19 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</guid>
    </item>
    <item>
      <title><![CDATA[Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2</link>
      <description><![CDATA[Back to Articles Mixture of Experts (MoE) as the Default Choice The Rush for Supremacy by Modality Big Preferences for Small Models More Permissive Open Source Licenses From Model-First to Hardware-First Reconstruction In Progress This is the second blog in a three-part series on China's open source community's historical advancements since January 2025's "DeepSeek Moment." The first blog is available here, and the third blog is available here.
In this second piece we turn our focus from models to the architectural and hardware choices Chinese companies have made as openness becomes the norm.]]></description>
      <pubDate>Tue, 27 Jan 2026 15:01:45 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2</guid>
    </item>
    <item>
      <title><![CDATA[One Year Since the â€œDeepSeek Momentâ€]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</link>
      <description><![CDATA[Back to Articles The Seeds of Chinaâ€™s Organic Open Source AI Ecosystem DeepSeek R1: A Turning Point From DeepSeek to AI+: Strategic Realignmentt Global Reception and Response This is the first blog in a series that will examine Chinaâ€™s open source communityâ€™s historical advancements in the past year and its reverberations in shaping the entire ecosystem. Much of 2025â€™s progress can be traced back to Januaryâ€™s â€œDeepSeek Momentâ€, when Hangzhou-based AI company DeepSeek released their R-1 model.]]></description>
      <pubDate>Tue, 20 Jan 2026 15:02:10 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</guid>
    </item>
    <item>
      <title><![CDATA[Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI]]></title>
      <link>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</link>
      <description><![CDATA[Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company's workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.
The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce's most aggressive move yet to position Slack at the center of the emerging "agentic AI" movement â€” where software agents work alongside humans to complete complex tasks.]]></description>
      <pubDate>Tue, 13 Jan 2026 13:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture]]></title>
      <link>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</link>
      <description><![CDATA[Back to Articles Discover more in our official blogpost, featuring an interactive experience The journey of building world-class Arabic language models has been one of continuous learning and iteration. Today, we're excited to announce Falcon-H1-Arabic, our most advanced Arabic language model family to date, representing a significant leap forward in both architecture and capabilities. This release embodies months of research, community feedback, and technical innovation, culminating in three powerful models that set new standards for Arabic natural language processing. Building on Success:]]></description>
      <pubDate>Mon, 05 Jan 2026 09:16:51 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</guid>
    </item>
    <item>
      <title><![CDATA[huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning]]></title>
      <link>https://huggingface.co/blog/huggingface-hub-v1</link>
      <description><![CDATA[Back to Articles The Story Behind the Library The Foundation Years (2020-2021) The Great Shift: Git to HTTP (2022) An Expanding API Surface (2022â€“2024) Ready. Xet. Go! (2024-2025) Measuring Growth and Impact Building for the Next Decade Modern HTTP Infrastructure with httpx and hf_xet Agents Made Simple with MCP and Tiny-Agents A Fully-Featured CLI for Modern Workflows Cleaning House for the Future The Migration Guide Acknowledgments TL;DR:]]></description>
      <pubDate>Mon, 27 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface-hub-v1</guid>
    </item>
    <item>
      <title><![CDATA[LeRobot v0.4.0: Supercharging OSS Robot Learning]]></title>
      <link>https://huggingface.co/blog/lerobot-release-v040</link>
      <description><![CDATA[Back to Articles TL;DR Table-of-Contents Datasets: Ready for the Next Wave of Large-Scale Robot Learning What's New in Datasets v3.0? New Feature: Dataset Editing Tools! Simulation Environments: Expanding Your Training Grounds LIBERO Support Meta-World Integration Codebase: Powerful Tools For Everyone The New Pipeline for Data Processing Multi-GPU Training Made Easy Policies: Unleashing Open-World Generalization PI0 and PI0.5 GR00T N1.5 Robots:]]></description>
      <pubDate>Fri, 24 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/lerobot-release-v040</guid>
    </item>
    <item>
      <title><![CDATA[AI for Food Allergies]]></title>
      <link>https://huggingface.co/blog/hugging-science/ai-for-food-allergies</link>
      <description><![CDATA[Back to Articles Current State of The Art: Where AI Meets Food Allergy Research The need for data Collection release The Protein and Molecular Allergenicity Layer The Clinical, Immunological, and Therapeutic Layer The Food, Ingredient, and Regulatory Layer Accessing the collection Whatâ€™s coming next? Final remarks Appendix SDAP 2.0: Structural Database of Allergenic Proteins DAVIS: Kinase inhibitor binding affinities QsarDB: repository for (Q)SAR models e-Drug3D Database Stanford Drug Data: Offsides/Twosides DrugCentral: open drug information repository MedKG: medical knowledge graph PDBBind+:]]></description>
      <pubDate>Thu, 16 Oct 2025 22:38:11 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hugging-science/ai-for-food-allergies</guid>
    </item>
    <item>
      <title><![CDATA[Jupyter Agents: training LLMs to reason with notebooks]]></title>
      <link>https://huggingface.co/blog/jupyter-agent-2</link>
      <description><![CDATA[Back to Articles The past year has been all about giving LLMs more tools and autonomy to solve more complex and open ended tasks. The goal of the Jupyter Agent is to give the model the ultimate tool: code execution. A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can execute code directly inside a Jupyter notebook and use this environment to solve data analysis and data science tasks.]]></description>
      <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/jupyter-agent-2</guid>
    </item>
    <item>
      <title><![CDATA[Kimina-Prover-RL]]></title>
      <link>https://huggingface.co/blog/AI-MO/kimina-prover-rl</link>
      <description><![CDATA[Back to Articles A slimmed-down training pipeline from Kimina Prover, with core features and full compatibility with verl. We are happy to introduce kimina-prover-rl, an open-source training pipeline for formal theorem proving in Lean 4, based on a structured reasoning-then-generation paradigm inspired by DeepSeek-R1.
This training pipelinee is a simplified version of the system we used to train Kimina Prover, preserving the key components of the system and offering full compatibility with the open-source Verl framework.]]></description>
      <pubDate>Thu, 14 Aug 2025 12:13:01 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/AI-MO/kimina-prover-rl</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI recrute le crÃ©ateur dâ€™OpenClaw, lâ€™IA qui agit Ã  votre place sur lâ€™ordinateur et dont tout le monde parle]]></title>
      <link>https://siecledigital.fr/2026/02/16/openai-recrute-le-createur-dopenclaw-pour-accelerer-sur-les-agents-ia/</link>
      <description><![CDATA[Depuis lâ€™arrivÃ©e des navigateurs IA comme Comet de Perplexity, le secteur de lâ€™IA sâ€™oriente vers des agents capables dâ€™agir directement sur nos appareils, dâ€™automatiser des tÃ¢ches et mÃªme dâ€™interagir avec des services tiers. Câ€™est dans ce contexte que le crÃ©ateur dâ€™un projet devenu viral rejoint lâ€™un des acteurs les plus influents du marchÃ©. En effet, [â€¦]]]></description>
      <pubDate>Tue, 17 Feb 2026 10:41:58 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/16/openai-recrute-le-createur-dopenclaw-pour-accelerer-sur-les-agents-ia/</guid>
    </item>
    <item>
      <title><![CDATA[After all the hype, some AI experts donâ€™t think OpenClaw is all that exciting]]></title>
      <link>https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/</link>
      <description><![CDATA["From an AI research perspective, this is nothing novel," one expert told TechCrunch.]]></description>
      <pubDate>Mon, 16 Feb 2026 13:15:00 GMT</pubDate>
      <source>TechCrunch AI</source>
      <category>ai</category>
      <guid>https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/</guid>
    </item>
    <item>
      <title><![CDATA[La bÃªta dâ€™iOS 26.4 apporte des nouveautÃ©s Apple Intelligence aux iPhoneâ€¦Â mais pas en Europe]]></title>
      <link>https://www.numerama.com/tech/2181139-la-beta-dios-26-4-apporte-des-nouveautes-apple-intelligence-aux-iphone-mais-pas-en-europe.html</link>
      <description><![CDATA[Pas de nouveau Siri dans la premiÃ¨re bÃªta d'iOS 26.4, mais de nombreuses Ã©volutions visuelles et quelques changements techniques (RCS chiffrÃ©s, sÃ©curitÃ© antivol par dÃ©faut, etc.) La seule nouveautÃ© qui concerne l'intelligence artificielle est l'introduction de la fonctionnalitÃ© Playlist Playground pour gÃ©nÃ©rer des playlists avec l'IAâ€¦ mais le service est, pour l'instant, indisponible en Europe.]]></description>
      <pubDate>Tue, 17 Feb 2026 09:23:49 GMT</pubDate>
      <source>Numerama Tech</source>
      <category>ai</category>
      <guid>https://www.numerama.com/tech/2181139-la-beta-dios-26-4-apporte-des-nouveautes-apple-intelligence-aux-iphone-mais-pas-en-europe.html</guid>
    </item>
    <item>
      <title><![CDATA[Tuning into the future of collaboration]]></title>
      <link>https://www.technologyreview.com/2026/02/16/1125881/tuning-into-the-future-of-collaboration/</link>
      <description><![CDATA[When work went remote, the sound of business changed. What began as a scramble to make home offices functional has evolved into a revolution in how people hear and are heard. From education to enterprises, companies across industries have reimagined what clear, reliable communication can mean in a hybrid world. For major audio and communicationsâ€¦]]></description>
      <pubDate>Mon, 16 Feb 2026 15:00:00 GMT</pubDate>
      <source>MIT Technology Review</source>
      <category>ai</category>
      <guid>https://www.technologyreview.com/2026/02/16/1125881/tuning-into-the-future-of-collaboration/</guid>
    </item>
    <item>
      <title><![CDATA[OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments]]></title>
      <link>https://huggingface.co/blog/openenv-turing</link>
      <description><![CDATA[Back to Articles What Is OpenEnv? The Calendar Gym: A Production-Grade Benchmark What We Learned Looking Ahead Appendix: Common error cases in tool use Specific error cases found in the wild AI agents often perform impressively in controlled research settings, yet struggle when deployed in real-world systems where they must reason across multiple steps, interact with real tools and APIs, operate under partial information, and recover from errors in stateful, permissioned environmentsâ€”highlighting a persistent gap between research success and production reliability.]]></description>
      <pubDate>Thu, 12 Feb 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openenv-turing</guid>
    </item>
    <item>
      <title><![CDATA[Introducing SyGra Studio]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link>
      <description><![CDATA[Back to Articles Step 1: Configure the data source Step 2: Build the flow visually Step 3: Review and run See it in action! Running Existing Workflows Run the Glaive Code Assistant workflow Get started SyGra 2.0.0 introduces Studio, an interactive environment that turns synthetic data generation into a transparent, visual craft. Instead of juggling YAML files and terminals, you compose flows directly on the canvas, preview datasets before committing, tune prompts with inline variable hints, and watch executions stream liveâ€”all from a single pane.]]></description>
      <pubDate>Thu, 05 Feb 2026 16:52:28 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Daggr: Chain apps programmatically, inspect visually]]></title>
      <link>https://huggingface.co/blog/daggr</link>
      <description><![CDATA[Back to Articles Table of Contents Background Getting Started Node Types Sharing Your Workflows End-to-End Example with Different Nodes Next Steps TL;DR: Daggr is a new, open-source Python library for building AI workflows that connect Gradio apps, ML models, and custom functions. It automatically generates a visual canvas where you can inspect intermediate outputs, rerun individual steps, and manage state for complex pipelines, all in a few lines of Python code!]]></description>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/daggr</guid>
    </item>
    <item>
      <title><![CDATA[Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective]]></title>
      <link>https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl</link>
      <description><![CDATA[Back to Articles Agentic reinforcement learning (RL) extends traditional LLM training by optimizing not just a single-turn response, but an entire decision-making process learned through direct interaction with an environment during training. Unlike traditional single-turn reinforcement learning or offline preference-based methods that rely on static datasets, agentic RL trains policies by actively collecting on-policy data as the agent plans actions, invokes tools, observes outcomes, and adapts its behavior over multi-step trajectories in either simulated or real environments.]]></description>
      <pubDate>Tue, 27 Jan 2026 01:53:15 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl</guid>
    </item>
    <item>
      <title><![CDATA[Railway secures $100 million to challenge AWS with AI-native cloud infrastructure]]></title>
      <link>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</link>
      <description><![CDATA[Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.
TQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures.]]></description>
      <pubDate>Thu, 22 Jan 2026 14:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</guid>
    </item>
    <item>
      <title><![CDATA[Claude Code costs up to $200 a month. Goose does the same thing for free.]]></title>
      <link>https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free</link>
      <description><![CDATA[The artificial intelligence coding revolution comes with a catch: it's expensive.
Claude Code, Anthropic's terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing â€” ranging from $20 to $200 per month depending on usage â€” has sparked a growing rebellion among the very programmers it aims to serve.
Now, a free alternative is gaining traction.]]></description>
      <pubDate>Mon, 19 Jan 2026 14:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free</guid>
    </item>
    <item>
      <title><![CDATA[Open Responses: What you need to know]]></title>
      <link>https://huggingface.co/blog/open-responses</link>
      <description><![CDATA[Back to Articles What is Open Responses? What do we need to know to build with Open Responses? Client Requests to Open Responses Changes for Inference Clients and Providers Open Responses for Routing Tools Sub Agent Loops Next Steps Open Responses is a new and open inference standard. Initiated by OpenAI, built by the open source AI community, and backed by the Hugging Face ecosystem, Open Responses is based on the Responses API and is designed for the future of Agents. In this blog post, weâ€™ll look at how Open Responses works and why the open source community should use Open Responses.]]></description>
      <pubDate>Thu, 15 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/open-responses</guid>
    </item>
    <item>
      <title><![CDATA[NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI]]></title>
      <link>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</link>
      <description><![CDATA[Back to Articles NVIDIA Cosmos Reason 2: Reasoning Vision Language Model for Physical AI Key Highlights Popular Use Cases Other Models From The Cosmos Family: Cosmos Predict 2.5 Resources NVIDIA today released Cosmos Reason 2, the latest advancement in open, reasoning vision language models for physical AI. Cosmos Reason 2 surpasses its previous version in accuracy and tops the Physical AI Bench and Physical Reasoning leaderboards as the #1 open model for visual understanding. NVIDIA Cosmos Reason 2:]]></description>
      <pubDate>Mon, 05 Jan 2026 22:56:51 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</guid>
    </item>
    <item>
      <title><![CDATA[The Open Evaluation Standard: Benchmarking NVIDIA Nemotron 3 Nano with NeMo Evaluator]]></title>
      <link>https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe</link>
      <description><![CDATA[Back to Articles It has become increasingly challenging to assess whether a modelâ€™s
reported improvements reflect genuine advances or variations in
evaluation conditions, dataset composition, or training data that
mirrors benchmark tasks. The NVIDIA Nemotron approach to openness
addresses this by publishing transparent and reproducible evaluation
recipes that make results independently verifiable.
NVIDIA released Nemotron 3 Nano 30B
A3B
with an explicitly open evaluation approach to make that distinction
clear.]]></description>
      <pubDate>Wed, 17 Dec 2025 13:22:18 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe</guid>
    </item>
    <item>
      <title><![CDATA[CUGA on Hugging Face: Democratizing Configurable AI Agents]]></title>
      <link>https://huggingface.co/blog/ibm-research/cuga-on-hugging-face</link>
      <description><![CDATA[Back to Articles Introduction Introduction What is CUGA? Open Source and Open Models Integration with Langflow: Visual Agent Design Made Simple Try the Hugging Face Demo: A Hands-On Preview Conclusion and Call to Action AI agents are rapidly becoming essential for building intelligent applications, but creating robust, adaptable agents that scale across domains remains a challenge. Many existing frameworks struggle with brittleness, tool misuse, and failures when faced with complex workflows.
CUGA (Configurable Generalist Agent) was designed to overcome these limitations.]]></description>
      <pubDate>Mon, 15 Dec 2025 16:01:04 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ibm-research/cuga-on-hugging-face</guid>
    </item>
    <item>
      <title><![CDATA[We Got Claude to Fine-Tune an Open Source LLM]]></title>
      <link>https://huggingface.co/blog/hf-skills-training</link>
      <description><![CDATA[We Got Claude to Fine-Tune an Open Source LLM]]></description>
      <pubDate>Thu, 04 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hf-skills-training</guid>
    </item>
    <item>
      <title><![CDATA[Building Deep Research: How we Achieved State of the Art]]></title>
      <link>https://huggingface.co/blog/Tavily/tavily-deep-research</link>
      <description><![CDATA[Back to Articles Building for the Future Agent Harness Models Tools Takeaways Context Engineering â€” An Exercise in Curation Context-Managed Web Retrieval Modeling the Human-Web Interaction Doing More with Less Productionizing Agents â€” an Ongoing Challenge Engineering with Non-Determinism Optimal Tooling â€” Less is More Evals Research agents are rapidly becoming one of the most important applications of AI. Research is a foundational knowledge-work task: collecting, reading, and synthesizing information underpins everything from writing and decision-making to coding itself.]]></description>
      <pubDate>Mon, 24 Nov 2025 17:40:14 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Tavily/tavily-deep-research</guid>
    </item>
    <item>
      <title><![CDATA[Easily Build and Share ROCm Kernels with Hugging Face]]></title>
      <link>https://huggingface.co/blog/build-rocm-kernels</link>
      <description><![CDATA[Back to Articles Intoduction Build Steps About the kernel Step 1: Project Structure Step 2: Configuration Files Setup Step 3: Building the Kernel Step 4: Uploading the kernel to the Hub Step 5: Let's use it :) Conclusion Related Libraries &amp; Hub Intoduction Custom kernels are the backbone of high-performance deep learning, enabling GPU operations tailored precisely to your workload; whether thatâ€™s image processing, tensor transformations, or other compute-heavy tasks.]]></description>
      <pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/build-rocm-kernels</guid>
    </item>
    <item>
      <title><![CDATA[Join the AMD Open Robotics Hackathon]]></title>
      <link>https://huggingface.co/blog/amd/openroboticshackathon</link>
      <description><![CDATA[Back to Articles Looking to show off your robotics aptitude? The AMD Open Robotics Hackathon hosted by AMD, Hugging Face, and Data Monsters is the place to do it. Whether youâ€™re a student, hobbyist, startup founder, or seasoned engineer, this event brings together makers, coders, and roboticists for a fast-paced, hands-on competition that turns bold ideas into functioning demos.
The first of two in-person hackathons will take place from December 5-7, 2025 in Tokyo Japan. Our next stop will be in Paris France from December 12-14, 2025.
Preparing for the Hackathon:]]></description>
      <pubDate>Thu, 13 Nov 2025 21:37:26 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/amd/openroboticshackathon</guid>
    </item>
    <item>
      <title><![CDATA[Building for an Open Future - our new partnership with Google Cloud]]></title>
      <link>https://huggingface.co/blog/google-cloud</link>
      <description><![CDATA[Back to Articles A Partnership for Google Cloud customers The Gateway to Open Models - A Fast Lane for Google Cloud Customers A partnership for Hugging Face customers Building the open future of AI together Today, we are happy to announce a new and deeper partnership with Google Cloud, to enable companies to build their own AI with open models.
â€œGoogle has made some of the most impactful contributions to open AI, from the OG transformer to the Gemma models. I believe in a future where all companies will build and customize their own AI.]]></description>
      <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/google-cloud</guid>
    </item>
    <item>
      <title><![CDATA[Building the Open Agent Ecosystem Together: Introducing OpenEnv]]></title>
      <link>https://huggingface.co/blog/openenv</link>
      <description><![CDATA[Back to Articles The Problem The Solution The RFCs Use cases Whatâ€™s Next With tools like TRL, TorchForge and verl, the open-source community has shown how to scale AI across complex compute infrastructure. But compute is only one side of the coin. The other side is the developer community; the people and tools that make agentic systems possible. Thatâ€™s why Meta and Hugging Face are partnering to launch the OpenEnv Hub: a shared and open community hub for agentic environments.
Agentic environments define everything an agent needs to perform a task:]]></description>
      <pubDate>Thu, 23 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openenv</guid>
    </item>
    <item>
      <title><![CDATA[Google Cloud C4 Brings a 70% TCO improvement on GPT OSS with Intel and Hugging Face]]></title>
      <link>https://huggingface.co/blog/gpt-oss-on-intel-xeon</link>
      <description><![CDATA[Back to Articles Intel and Hugging Face collaborated to demonstrate the real-world value of upgrading to Googleâ€™s latest C4 Virtual Machine (VM) running on Intel Xeon 6 processors (codenamed Granite Rapids (GNR)). We specifically wanted to benchmark improvements in the text generation performance of OpenAI GPT OSS Large Language Model(LLM). The results are in, and they are impressive, demonstrating a 1.7x improvement in Total Cost of Ownership(TCO) over the previous-generation Google C3 VM instances. The Google Cloud C4 VM instance further resulted in:]]></description>
      <pubDate>Thu, 16 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/gpt-oss-on-intel-xeon</guid>
    </item>
    <item>
      <title><![CDATA[Get your VLM running in 3 simple steps on Intel CPUs]]></title>
      <link>https://huggingface.co/blog/openvino-vlm</link>
      <description><![CDATA[Back to Articles With the growing capability of large language models (LLMs), a new class of models has emerged: Vision Language Models (VLMs). These models can analyze images and videos to describe scenes, create captions, and answer questions about visual content.
While running AI models on your own device can be difficult as these models are often computationally demanding, it also offers significant benefits: including improved privacy since your data stays on your machine, and enhanced speed and reliability because you're not dependent on an internet connection or external servers.]]></description>
      <pubDate>Wed, 15 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openvino-vlm</guid>
    </item>
    <item>
      <title><![CDATA[Nemotron-Personas-India: Synthesized Data for Sovereign AI]]></title>
      <link>https://huggingface.co/blog/nvidia/nemotron-personas-india</link>
      <description><![CDATA[Back to Articles Open Data for India's AI Future Whatâ€™s in the Dataset? How We Built It Data Generation Pipeline Embedded Cultural Context Private By Design Who This Is For Practical AI Applications Why It Matters Start Building with Nemotron-Personas-India A compound AI approach to Indian personas grounded in real-world distributions Open Data for India's AI Future India represents one of the world's largest AI opportunities â€” with over 700 million internet users, a multitude of languages, and a rapidly growing developer ecosystem.]]></description>
      <pubDate>Mon, 13 Oct 2025 23:00:42 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nemotron-personas-india</guid>
    </item>
    <item>
      <title><![CDATA[BigCodeArena: Judging code generations end to end with code executions]]></title>
      <link>https://huggingface.co/blog/bigcode/arena</link>
      <description><![CDATA[Back to Articles Motivation The BigCodeArena Platform Real-Time Execution Multi-Language &amp; Framework Support Interactive Testing Multi-Turn Conversations What We've Learned: 5 Months of Community Evaluation Programming Topics in the Wild Language and Framework Popularity User Interaction Patterns Model Rankings from Community Votes Two New Benchmarks: BigCodeReward and AutoCodeArena BigCodeReward: Evaluating Reward Models for Code AutoCodeArena: Automated Code Generation Benchmarks Try It Yourself Open Source Everything What's Next?]]></description>
      <pubDate>Tue, 07 Oct 2025 09:37:25 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/bigcode/arena</guid>
    </item>
    <item>
      <title><![CDATA[Introducing RTEB: A New Standard for Retrieval Evaluation]]></title>
      <link>https://huggingface.co/blog/rteb</link>
      <description><![CDATA[Back to Articles TL;DR â€“ Weâ€™re excited to introduce the beta version of the Retrieval Embedding Benchmark (RTEB), a new benchmark designed to reliably evaluate the retrieval accuracy of embedding models for real-world applications. Existing benchmarks struggle to measure true generalization, while RTEB addresses this with a hybrid strategy of open and private datasets. Its goal is simple: to create a fair, transparent, and application-focused standard for measuring how models perform on data they havenâ€™t seen before.]]></description>
      <pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/rteb</guid>
    </item>
    <item>
      <title><![CDATA[Smol2Operator: Post-Training GUI Agents for Computer Use]]></title>
      <link>https://huggingface.co/blog/smol2operator</link>
      <description><![CDATA[Back to Articles TL;DR: This work shows how a lightweight visionâ€“language model can acquire GUI-grounded skills and evolve into an agentic GUI coder. We release all training recipes, data-processing tools, resulting model, demo and datasets to enable full reproducibility and foster further research . Find the collection here. This video demonstrates the model obtained through the recipe described below, executing a task end-to-end. Table of Contents Introduction
1.]]></description>
      <pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/smol2operator</guid>
    </item>
    <item>
      <title><![CDATA[SyGra: The One-Stop Framework for Building Data for LLMs andÂ SLMs]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework</link>
      <description><![CDATA[Back to Articles Enter SyGra: One Framework for Every Data Challenge Why SyGraÂ Matters SyGra Architecture Final Thoughts References When we think about building a modelâ€Š-â€Šbe it a Large Language Model (LLM) or a Small Language Model (SLM)â€Š-â€Šthe first thing we need is data. While a vast amount of open data is available, it rarely comes in the exact format required to train or align models.
In practice, we often face scenarios where the raw data isn't enough. We need data that is more structured, domain-specific, complex, or aligned with the task at hand. Let's look at some common situations:]]></description>
      <pubDate>Mon, 22 Sep 2025 06:45:05 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework</guid>
    </item>
    <item>
      <title><![CDATA[mmBERT: ModernBERT goes Multilingual]]></title>
      <link>https://huggingface.co/blog/mmbert</link>
      <description><![CDATA[Back to Articles TL;DR Training Data Training Recipe and Novel Components Architecture Three-Phase Training Approach Novel Training Techniques Results Natural Language Understanding (NLU) Retrieval Performance Learning Languages in the Decay Phase Efficiency Improvements Usage Examples Fine-tuning Examples Encoders Model Family and Links TL;DR This blog post introduces mmBERT, a state-of-the-art massively multilingual encoder model trained on 3T+ tokens of text in over 1800 languages.]]></description>
      <pubDate>Tue, 09 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/mmbert</guid>
    </item>
    <item>
      <title><![CDATA[SAIR: Accelerating Pharma R&amp;D with AI-Powered Structural Intelligence]]></title>
      <link>https://huggingface.co/blog/SandboxAQ/sair-data-accelerating-drug-discovery-with-ai</link>
      <description><![CDATA[Back to Articles Accessing SAIR 1. Install essentials 2. Authenticate 3. Load the main table (sair.parquet) 4. (Optional) List available structure archives 5. (Optional) Download and extract structures Questions? This summer, SandboxAQ released the Structurally Augmented IC50 Repository (SAIR), the largest dataset of co-folded 3D protein-ligand structures paired with experimentally measured ICâ‚…â‚€ labels, directly linking molecular structure to drug potency and overcoming a longstanding scarcity in training data.]]></description>
      <pubDate>Tue, 02 Sep 2025 16:54:29 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/SandboxAQ/sair-data-accelerating-drug-discovery-with-ai</guid>
    </item>
    <item>
      <title><![CDATA[NVIDIA Releases 6 Million Multi-Lingual Reasoning Dataset]]></title>
      <link>https://huggingface.co/blog/nvidia/multilingual-reasoning-v1</link>
      <description><![CDATA[Back to Articles Authors: Dhruv Nathawani, Shuoyang Ding US, Vitaly Lavrukhin US, Jane Polak Scowcroft US, Oleksii Kuchaiev US NVIDIA continues releasing permissive datasets in support of the open ecosystem with 6 Million Multilingual Reasoning Dataset.
Continuing the success of the recent Nemotron Post-Training Dataset v1 release used in Llama Nemotron Super model, and our Llama Nemotron Post-Training Dataset release earlier this year, weâ€™re excited to release the reasoning dataset translated into five target languages: French, Spanish, German, Italian, and Japanese.]]></description>
      <pubDate>Wed, 20 Aug 2025 22:13:18 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/multilingual-reasoning-v1</guid>
    </item>
    <item>
      <title><![CDATA[Neural Super Sampling is here!]]></title>
      <link>https://huggingface.co/blog/Arm/neural-super-sampling</link>
      <description><![CDATA[Back to Articles Elevated by machine learning Learn about our NSS Model How we trained the model Get started experimenting with NSS today! Neural Super Sampling (NSS), a next-generation AI-powered upscaling solution from Arm is released for graphics and gaming developers to start experimenting today! Elevated by machine learning NSS is designed for real-time performance on future mobile devices with Arm Neural Technology. However, latency depends on implementation factors such as GPU configuration, resolution, and use case.]]></description>
      <pubDate>Tue, 12 Aug 2025 14:52:08 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Arm/neural-super-sampling</guid>
    </item>
    <item>
      <title><![CDATA[ðŸ‡µðŸ‡­ FilBench - Can LLMs Understand and Generate Filipino?]]></title>
      <link>https://huggingface.co/blog/filbench</link>
      <description><![CDATA[Back to Articles FilBench What did we learn from FilBench? Finding #1: Although region-specific LLMs still lag behind GPT-4, collecting data to train these models is still a promising direction Finding #2: Filipino translation is still a difficult task for LLMs Finding #3: Open LLMs Remain a Cost-Effective Choice for Filipino Language Tasks Does your LLM work on Philippine Languages? Try it on FilBench!]]></description>
      <pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/filbench</guid>
    </item>
    <item>
      <title><![CDATA[Introducing AI Sheets: a tool to work with datasets using open AI models!]]></title>
      <link>https://huggingface.co/blog/aisheets</link>
      <description><![CDATA[Introducing AI Sheets: a tool to work with datasets using open AI models!]]></description>
      <pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/aisheets</guid>
    </item>
    <item>
      <title><![CDATA[Welcome GPT OSS, the new open-source model family from OpenAI!]]></title>
      <link>https://huggingface.co/blog/welcome-openai-gpt-oss</link>
      <description><![CDATA[Welcome GPT OSS, the new open-source model family from OpenAI!]]></description>
      <pubDate>Tue, 05 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/welcome-openai-gpt-oss</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face]]></title>
      <link>https://huggingface.co/blog/trackio</link>
      <description><![CDATA[Back to Articles Background Why We Switched to Trackio Using Trackio Installing Usage Visualizing Results Sharing with Spaces Integrated with Transformers and Accelerate Design Principles Next Steps TL;DR: Trackio is a new, open-source, and free experiment tracking Python library that provides a local dashboard and seamless integration with Hugging Face Spaces for easy sharing and collaboration. Since trackio is a drop-in replacement for wandb, you can get started with the syntax you already know!]]></description>
      <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/trackio</guid>
    </item>
    <item>
      <title><![CDATA[Ettin Suite: SoTA Paired Encoders and Decoders]]></title>
      <link>https://huggingface.co/blog/ettin</link>
      <description><![CDATA[Back to Articles TL;DR Encoders vs Decoders: The Architecture Divide Training Recipe: Modern Techniques for Both Architectures Sizes Three-Phase Training Process Modern Architecture Components Data Sources and Quality Encoder Results: Beating ModernBERT Decoder Results: Beating Llama 3.2 and SmolLM2 Fair Fight: Encoders vs Decoders on Even Ground Architecture-Specific Advantages Persist Cross-Objective Training Falls Short Beyond Performance:]]></description>
      <pubDate>Wed, 16 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ettin</guid>
    </item>
    <item>
      <title><![CDATA[Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders]]></title>
      <link>https://huggingface.co/blog/reachy-mini</link>
      <description><![CDATA[Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders]]></description>
      <pubDate>Wed, 09 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/reachy-mini</guid>
    </item>
  </channel>
</rss>