<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI-Pulse - AI - Artificial Intelligence</title>
    <link>https://thephoenixagency.github.io/AI-Pulse</link>
    <description>AI - Artificial Intelligence news from AI-Pulse</description>
    <language>en</language>
    <lastBuildDate>Sun, 22 Feb 2026 10:24:44 GMT</lastBuildDate>
    <atom:link href="https://thephoenixagency.github.io/AI-Pulse/feed-ai.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title><![CDATA[Railway secures $100 million to challenge AWS with AI-native cloud infrastructure]]></title>
      <link>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</link>
      <description><![CDATA[Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.
TQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like Amazon Web Services and Google Cloud.
"As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?" said Jake Cooper, Railway's 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. "The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can't keep up."
The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a $20 million Series A from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.
Why three-minute deploy times have become unacceptable in the age of AI coding assistants
Railway's pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using Terraform, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like Claude, ChatGPT, and Cursor can generate working code in seconds.
"When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks," Cooper told VentureBeat. "What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents."
The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.
These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.
"The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day," Lobaton said. "If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes."
Inside the controversial decision to abandon Google Cloud and build data centers from scratch
What distinguishes Railway from competitors like Render and Fly.io is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: "People who are really serious about software should make their own hardware."
"We wanted to design hardware in a way where we could build a differentiated experience," Cooper said. "Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at 'agentic speed' while staying 100 percent the smoothest ride in town."
The approach paid dividends during recent widespread outages that affected major cloud providers — Railway remained online throughout.
This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.
"The conventional wisdom is that the big guys have economies of scale to offer better pricing," Cooper noted. "But when they're charging for VMs that usually sit idle in the cloud, and we've purpose-built everything to fit much more density on these machines, you have a big opportunity."
How 30 employees built a platform generating tens of millions in annual revenue
Railway has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.
Cooper emphasized that the fundraise was strategic rather than necessary. "We're default alive; there's no reason for us to raise money," he said. "We raised because we see a massive opportunity to accelerate, not because we needed to survive."
The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway's two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.
"We basically did the standard engineering thing: if you build it, they will come," Cooper recalled. "And to some degree, they came."
From side projects to Fortune 500 deployments: Railway's unlikely corporate expansion
Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.
Notable customers include Bilt, the loyalty program company; Intuit's GoCo subsidiary; TripAdvisor's Cruise Critic; and MGM Resorts. Kernel, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.
"At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS," said Rafael Garcia, Kernel's chief technology officer. "Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012."
For enterprise customers, Railway offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer's existing cloud environment through a "bring your own cloud" configuration.
Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).
The startup's bold strategy to take on Amazon, Google, and a new generation of cloud rivals
Railway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.
Cooper argues that Railway's competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.
"The hyperscalers have two competing systems, and they haven't gone all-in on the new model because their legacy revenue stream is still printing money," he observed. "They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don't really need to?"
Against startup competitors, Railway differentiates by covering the full infrastructure stack. "We're not just containers; we've got VM primitives, stateful storage, virtual private networking, automated load balancing," Cooper said. "And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster."
The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.
Why investors are betting that AI will create a thousand times more software than exists today
Railway's fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like GitHub Copilot, Cursor, and Claude become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.
"The amount of software that's going to come online over the next five years is unfathomable compared to what existed before — we're talking a thousand times more software," Cooper predicted. "All of that has to run somewhere."
The company has already integrated directly with AI systems, building what Cooper calls "loops where Claude can hook in, call deployments, and analyze infrastructure automatically." Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.
"The notion of a developer is melting before our eyes," Cooper said. "You don't have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity."
What Railway plans to do with $100 million and zero marketing experience
Railway plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company's five-year history.
"One of my mentors said you raise money when you can change the trajectory of the business," Cooper explained. "We've built all the required substrate to scale indefinitely; what's been holding us back is simply talking about it. 2026 is the year we play on the world stage."
The company's investor roster reads like a who's who of developer infrastructure. Angel investors include Tom Preston-Werner, co-founder of GitHub; Guillermo Rauch, chief executive of Vercel; Spencer Kimball, chief executive of Cockroach Labs; Olivier Pomel, chief executive of Datadog; and Jori Lallo, co-founder of Linear.
The timing of Railway's expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper's telling, are too wedded to their existing business models to fully capitalize on the moment.
Whether Railway can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at Wolfram Alpha, Bloomberg, and Uber before founding Railway in 2020, seems unfazed by the scale of his ambition.
"In five years, Railway [will be] the place where software gets created and evolved, period," he said. "Deploy instantly, scale infinitely, with zero friction. That's the prize worth playing for, and there's no bigger one on offer."
For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.]]></description>
      <pubDate>Thu, 22 Jan 2026 14:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</guid>
    </item>
    <item>
      <title><![CDATA[Claude Code costs up to $200 a month. Goose does the same thing for free.]]></title>
      <link>https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free</link>
      <description><![CDATA[The artificial intelligence coding revolution comes with a catch: it's expensive.
Claude Code, Anthropic's terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.
Now, a free alternative is gaining traction. Goose, an open-source AI agent developed by Block (the financial technology company formerly known as Square), offers nearly identical functionality to Claude Code but runs entirely on a user's local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.
"Your data stays with you, period," said Parth Sareen, a software engineer who demonstrated the tool during a recent livestream. The captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.
The project has exploded in popularity. Goose now boasts more than 26,100 stars on GitHub, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, 1.20.1, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.
For developers frustrated by Claude Code's pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work. Anthropic's new rate limits spark a developer revolt
To understand why Goose matters, you need to understand the Claude Code pricing controversy.
Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The Pro plan, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.
The Max plans, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic's most powerful model, Claude 4.5 Opus. But even these premium tiers come with restrictions that have inflamed the developer community.
In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.
The problem? Those "hours" are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.
"It's confusing and vague," one developer wrote in a widely shared analysis. "When they say '24-40 hours of Opus 4,' that doesn't really tell you anything useful about what you're actually getting."
The backlash on Reddit and developer forums has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions "a joke" and "unusable for real work."
Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code "continuously in the background, 24/7." But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.
How Block built a free AI coding agent that works offline
Goose takes a radically different approach to the same problem.
Built by Block, the payments company led by Jack Dorsey, Goose is what engineers call an "on-machine AI agent." Unlike Claude Code, which sends your queries to Anthropic's servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.
The project's documentation describes it as going "beyond code suggestions" to "install, execute, edit, and test with any LLM." That last phrase — "any LLM" — is the key differentiator. Goose is model-agnostic by design.
You can connect Goose to Anthropic's Claude models if you have API access. You can use OpenAI's GPT-5 or Google's Gemini. You can route it through services like Groq or OpenRouter. Or — and this is where things get interesting — you can run it entirely locally using tools like Ollama, which let you download and execute open-source models on your own hardware.
The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.
"I use Ollama all the time on planes — it's a lot of fun!" Sareen noted during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.
What Goose can do that traditional code assistants can't
Goose operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.
The architecture relies on what the AI industry calls "tool calling" or "function calling" — the ability for a language model to request specific actions from external systems. When you ask Goose to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn't just generate text describing what should happen. It actually executes those operations.
This capability depends heavily on the underlying language model. Claude 4 models from Anthropic currently perform best at tool calling, according to the Berkeley Function-Calling Leaderboard, which ranks models on their ability to translate natural language requests into executable code and system commands.
But newer open-source models are catching up quickly. Goose's documentation highlights several options with strong tool-calling support: Meta's Llama series, Alibaba's Qwen models, Google's Gemma variants, and DeepSeek's reasoning-focused architectures.
The tool also integrates with the Model Context Protocol, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.
Setting Up Goose with a Local Model
For developers interested in a completely free, privacy-preserving setup, the process involves three main components: Goose itself, Ollama (a tool for running open-source models locally), and a compatible language model.
Step 1: Install Ollama
Ollama is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.
Download and install Ollama from ollama.com. Once installed, you can pull models with a single command. For coding tasks, Qwen 2.5 offers strong tool-calling support:
ollama run qwen2.5
The model downloads automatically and begins running on your machine.
Step 2: Install Goose
Goose is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.
Installation instructions vary by operating system but generally involve downloading from Goose's GitHub releases page or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.
Step 3: Configure the Connection
In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama's default port) and click Submit.
For the command-line version, run goose configure, select "Configure Providers," choose Ollama, and enter the model name when prompted.
That's it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.
The RAM, processing power, and trade-offs you should know about
The obvious question: what kind of computer do you need?
Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.
Block's documentation suggests that 32 gigabytes of RAM provides "a solid baseline for larger models and outputs." For Mac users, this means the computer's unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.
But you don't necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. Qwen 2.5, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.
"You don't need to run the largest models to get excellent results," Sareen emphasized. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.
For context, Apple's entry-level MacBook Air with 8 gigabytes of RAM would struggle with most capable coding models. But a MacBook Pro with 32 gigabytes — increasingly common among professional developers — handles them comfortably.
Why keeping your code off the cloud matters more than ever
Goose with a local LLM is not a perfect substitute for Claude Code. The comparison involves real trade-offs that developers should understand.
Model Quality: Claude 4.5 Opus, Anthropic's flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.
One developer who switched to the $200 Claude Code plan described the difference bluntly: "When I say 'make this look modern,' Opus knows what I mean. Other models give me Bootstrap circa 2015."
Context Window: Claude Sonnet 4.5, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.
Speed: Cloud-based services like Claude Code run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you're making rapid changes and waiting for AI feedback.
Tooling Maturity: Claude Code benefits from Anthropic's dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. Goose, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.
How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market
Goose enters a crowded market of AI coding tools, but occupies a distinctive position.
Cursor, a popular AI-enhanced code editor, charges $20 per month for its Pro tier and $200 for Ultra—pricing that mirrors Claude Code's Max plans. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code's hourly resets.
Cline, Roo Code, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.
Amazon's CodeWhisperer, GitHub Copilot, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.
Goose's combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It's competing on freedom — both financial and architectural.
The $200-a-month era for AI coding tools may be ending]]></description>
      <pubDate>Mon, 19 Jan 2026 14:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free</guid>
    </item>
    <item>
      <title><![CDATA[Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment]]></title>
      <link>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</link>
      <description><![CDATA[Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia's latest B200 graphics processors.
The model, called NousCoder-14B, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: Claude Code, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year's Day, with developers posting breathless testimonials about its capabilities. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.
type: embedded-entry-inline id: 74cSyrq6OUrp9SEQ5zOUSl
NousCoder-14B achieves a 67.87 percent accuracy rate on LiveCodeBench v6, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba's Qwen3-14B, according to Nous Research's technical report published alongside the release.
"I gave Claude Code a description of the problem, it generated what we built last year in an hour," wrote Jaana Dogan, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.
The juxtaposition is instructive: while Anthropic's Claude Code has captured imaginations with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability. How Nous Research built an AI coding model that anyone can replicate
What distinguishes the NousCoder-14B release from many competitor announcements is its radical openness. Nous Research published not just the model weights but the complete reinforcement learning environment, benchmark suite, and training harness — built on the company's Atropos framework — enabling any researcher with sufficient compute to reproduce or extend the work.
"Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research," noted one observer on X, summarizing the significance for the academic and open-source communities.
The model was trained by Joe Li, a researcher in residence at Nous Research and a former competitive programmer himself. Li's technical report reveals an unexpectedly personal dimension: he compared the model's improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.
Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B's improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.
"Watching that final training run unfold was quite a surreal experience," Li wrote in the technical report.
But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners. Inside the reinforcement learning system that trains on 24,000 competitive programming problems
NousCoder-14B's training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.
The approach relies on what researchers call "verifiable rewards" — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.
Nous Research used Modal, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.
The training employed a technique called DAPO (Dynamic Sampling Policy Optimization), which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves "dynamic sampling" — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.
The researchers also adopted "iterative context extension," first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.
Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters. The looming data shortage that could slow AI coding model progress
Buried in Li's technical report is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses "a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format."
In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.
"The total number of competitive programming problems on the Internet is roughly the same order of magnitude," Li wrote, referring to the 24,000 problems used for training. "This suggests that within the competitive programming domain, we have approached the limits of high-quality data."
This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is "increasingly finite," as Li put it.
"It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures," he concluded.
The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn't — making synthetic data generation considerably more difficult.
Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. "Once synthetic problem generation is solved, self-play becomes a very interesting direction," he wrote. A $65 million bet that open-source AI can compete with Big Tech]]></description>
      <pubDate>Wed, 07 Jan 2026 20:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</guid>
    </item>
    <item>
      <title><![CDATA[Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews]]></title>
      <link>https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai</link>
      <description><![CDATA[Alfred Wahlforss was running out of options. His startup, Listen Labs, needed to hire over 100 engineers, but competing against Mark Zuckerberg's $100 million offers seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a billboard in San Francisco displaying what looked like gibberish: five strings of random numbers.
The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.
That unconventional approach has now attracted $69 million in Series B funding, led by Ribbit Capital with participation from Evantic and existing investors Sequoia Capital, Conviction, and Pear VC. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews. "When you obsess over customers, everything else follows," Wahlforss said in an interview with VentureBeat. "Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is."
Why traditional market research is broken, and what Listen Labs is building to fix it
Listen's AI researcher finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.
Wahlforss explained the limitation of existing approaches: "Essentially surveys give you false precision because people end up answering the same question... You can't get the outliers. People are actually not honest on surveys." The alternative, one-on-one human interviews, "gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they're talking about. And the problem is you can't scale that."
The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.
What distinguishes Listen's approach is its use of open-ended video conversations rather than multiple-choice forms. "In a survey, you can kind of guess what you should answer, and you have four options," Wahlforss said. "Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty."
The dirty secret of the $140 billion market research industry: rampant fraud
Listen finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called "one of the most shocking things that we've learned when we entered this industry"—rampant fraud.
"Essentially, there's a financial transaction involved, which means there will be bad players," he explained. "We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud."
The company built what it calls a "quality guard" that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: "People talk three times more. They're much more honest when they talk about sensitive topics like politics and mental health."
Emeritus, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. "We did not have to replace any responses because of fraud or gibberish information," said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.
How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products
The speed advantage has proven central to Listen's pitch. Traditional customer research at Microsoft could take four to six weeks to generate insights. "By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it," said Romani Patel, Senior Research Manager at Microsoft.
With Listen, Microsoft can now get insights in days, and in many cases, within hours.
The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. "We wanted users to share how Copilot is empowering them to bring their best self forward," Patel said, "and we were able to collect those user video stories within a day." Traditionally, that kind of work would have taken six to eight weeks.
Simple Modern, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. "We went from 'Should we even have this product?' to 'How should we launch it?'" said Chris Hoyle, the company's Chief Marketing Officer.
Chubbies, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. "There's school, sports, dinner, and homework," explained Lauren Neville, Director of Insights and Innovation. "I had to find a way to hear from them that fit into their schedules."
The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI "through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed." The redesigned product became "a blockbuster hit."
The Jevons paradox explains why cheaper research creates more demand, not less
Listen Labs is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly $140 billion annually, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.
"There are very much existing budget lines that we are replacing," Wahlforss said. "Why we're replacing them is that one, they're super costly. Two, they're kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with."
But the more intriguing dynamic may be that AI-powered research doesn't just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.
"What I've noticed is that as something gets cheaper, you don't need less of it. You want more of it," Wahlforss explained. "There's infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren't researchers before can now do that as part of their job."
Inside the elite engineering team that built Listen Labs before they had a working toilet
Listen Labs traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. "We built this consumer app that got 20,000 downloads in one day," Wahlforss recalled. "We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today."
The founding team brings an unusual pedigree. Wahlforss's co-founder "was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot." The company claims that 30% of its engineering team are medalists from the International Olympiad in Informatics — the same competition that produced the founders of Cognition, the AI coding startup.
The Berghain billboard stunt generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.
"We had to do these things because some of our, like early employees, joined the company before we had a working toilet," he said. "But now we fixed that situation."
The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.
Synthetic customers and automated decisions: what Listen Labs is building next
Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building "the ability to simulate your customers, so you can take all of those interviews we've done, and then extrapolate based on that and create synthetic users or simulated user voices."
Beyond simulation, Listen aims to enable automated action based on research findings. "Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?"
Wahlforss acknowledged the ethical implications. "Obviously, as you said, there's kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop."
The company already handles sensitive data with care. "We don't train on any of the data," Wahlforss said. "We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that."
How AI could reshape the future of product development
Perhaps the most provocative implication of Listen's model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.
"They're based in Australia, so they're coding during the day, and then in their night, they're releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate."
The vision extends Y Combinator's famous dictum — "write code, talk to users" — into an automated cycle. "Write code is now getting automated. And I think like talk to users will be as well, and you'll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously."
Whether that vision materializes depends on factors beyond Listen's control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A 2024 MIT study found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.
"I'm constantly have to emphasize like, let's make sure the quality is there and the details are right," he said.
But the company's growth suggests appetite for the experiment. Microsoft's Patel said Listen has "removed the drudgery of research and brought the fun and joy back into my work." Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.
"It's a total game changer," said Ali Romero, Sling Money's marketing manager.
Wahlforss has a different phrase for what he's building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.
One of them: "Slow is fake."
It's an aggressive claim for an industry built on methodological caution. But Listen Labs is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.]]></description>
      <pubDate>Fri, 16 Jan 2026 14:01:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai</guid>
    </item>
    <item>
      <title><![CDATA[Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI]]></title>
      <link>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</link>
      <description><![CDATA[Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company's workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.
The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce's most aggressive move yet to position Slack at the center of the emerging "agentic AI" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.
"Slackbot isn't just another copilot or AI assistant," said Parker Harris, Salesforce co-founder and Slack's chief technology officer, in an exclusive interview with Salesforce. "It's the front door to the agentic enterprise, powered by Salesforce."
From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up
Harris was blunt about what distinguishes the new Slackbot from its predecessor: "The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche."
The original Slackbot, which has existed since Slack's early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.
"It's two different things," Harris explained. "The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it's based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data."
Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. "People know what Slackbot is, and so we wanted to carry that forward," Harris said.
Why Anthropic's Claude powers the new Slackbot — and which AI models could come next
The new Slackbot runs on Claude, Anthropic's large language model, a choice driven partly by compliance requirements. Slack's commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was "the only provider that could give us a compliant LLM" when Slack began building the new system.
But that exclusivity won't last. "We are, this year, going to support additional providers," Harris said. "We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we're going to use Gemini for some things." He added that OpenAI remains a possibility as well.
Harris echoed Salesforce CEO Marc Benioff's view that large language models are becoming commoditized: "You've heard Marc talk about LLMs are commodities, that they're democratized. I call them CPUs."
On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. "Models don't have any sort of security," he explained. "If we trained it on some confidential conversation that you and I have, I don't want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn't."
Inside Salesforce's internal experiment: 80,000 employees tested Slackbot with striking results
Salesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack's chief marketing officer, the results have been striking: "It's the fastest adopted product in Salesforce history."
Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.
The adoption happened largely organically. "I think it was about five days, and a Canvas was developed by our employees called 'The Most Stealable Slackbot Prompts,'" Gavin said. "People just started adding to it organically. I think it's up to 250-plus prompts that are in this Canvas right now."
Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. "Everybody is there to help each other learn and communicate hacks," she said.
How Slackbot transforms scattered enterprise data into executive-ready insights
During a product demonstration, Amy Bauer, Slack's product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.
"This is where Slackbot really earns its keep for me," Bauer explained. "What it's doing is not just simply reading the image — it's actually looking at the image and comparing it to the insight it just generated for me."
Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called "a really great justification and plan to move forward." Finally, it can synthesize all that information into a Canvas — Slack's collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.
"Up until this point, we have been working in a one-to-one capacity with Slackbot," Bauer said. "But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team."
Rob Seaman, Slack's chief product officer, said the Canvas creation demonstrates where the product is heading: "This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we're going with Slackbot — we're eventually going to be adding in additional third-party tool calls."
MrBeast's company became a Slackbot guinea pig—and employees say they're saving 90 minutes a day
Among Salesforce's pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company's chief information officer, joined the launch announcement to describe his experience.
"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest," Madrigal said. "The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review."
Madrigal said his security team signed off "rather quickly" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. "Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they're part of—that made my security team sign off rather quickly."
One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving "at bare minimum, 90 minutes a day." Another employee, Spencer, a creative supervisor, described it as "an assistant who's paying attention when I'm not."
Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot "an absolute 'chaos tamer' for our team," estimating it saves her about 30 minutes daily "just by eliminating context switching."
Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance]]></description>
      <pubDate>Tue, 13 Jan 2026 13:00:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and</guid>
    </item>
    <item>
      <title><![CDATA[Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required]]></title>
      <link>https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no</link>
      <description><![CDATA[Anthropic released Cowork on Monday, a new AI agent capability that extends the power of its wildly successful Claude Code tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.
The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with OpenAI and Google in conversational AI, but with Microsoft's Copilot in the burgeoning market for AI-powered productivity tools.
"Cowork lets you complete non-technical tasks much like how developers use Claude Code," the company announced via its official Claude account on X. The feature arrives as a research preview available exclusively to Claude Max subscribers — Anthropic's power-user tier priced between $100 and $200 per month — through the macOS desktop application.
For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With Cowork, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding. How developers using a coding tool for vacation research inspired Anthropic's latest product
The genesis of Cowork lies in Anthropic's recent success with the developer community. In late 2024, the company released Claude Code, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.
According to Boris Cherny, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks. "Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven," Cherny wrote on X. "These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model."
Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, Anthropic explained that developers "quickly began using it for almost everything else," which "prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way."
Inside the folder-based architecture that lets Claude read, edit, and create files on your computer
Unlike a standard chat interface where a user pastes text for analysis, Cowork requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.
Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.
"In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder," the company explained on X. "Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes." The architecture relies on what is known as an "agentic loop." When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling "much less like a back-and-forth and much more like leaving messages for a coworker."
The system is built on Anthropic's Claude Agent SDK, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork "can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks."
The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork
Perhaps the most remarkable detail surrounding Cowork's launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.
During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that the team built Cowork in approximately a week and a half.
Alex Volkov, who covers AI developments, expressed surprise at the timeline: "Holy shit Anthropic built 'Cowork' in the last... week and a half?!" This prompted immediate speculation about how much of Cowork was itself built by Claude Code. Simon Smith, EVP of Generative AI at Klick Health, put it bluntly on X: "Claude Code wrote all of Claude Cowork. Can we all agree that we're in at least somewhat of a recursive improvement loop here?"
The implication is profound: Anthropic's AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.
Connectors, browser automation, and skills extend Cowork's reach beyond the local file system
Cowork doesn't operate in isolation. The feature integrates with Anthropic's existing ecosystem of connectors — tools that link Claude to external information sources and services such as Asana, Notion, PayPal, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.
Additionally, Cowork can pair with Claude in Chrome, Anthropic's browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.
"Cowork includes a number of novel UX and safety features that we think make the product really special," Cherny explained, highlighting "a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it's unsure."
Anthropic has also introduced an initial set of "skills" specifically designed for Cowork that enhance Claude's ability to create documents, presentations, and other files. These build on the Skills for Claude framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.
Why Anthropic is warning users that its own AI agent could delete their files
The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.
In a notable display of transparency, Anthropic devoted considerable space in its announcement to warning users about Cowork's potential dangers — an unusual approach for a product launch.
The company explicitly acknowledges that Claude "can take potentially destructive actions (such as deleting local files) if it's instructed to." Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide "very clear guidance" about sensitive operations.
More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.
"We've built sophisticated defenses against prompt injections," Anthropic wrote, "but agent safety — that is, the task of securing Claude's real-world actions — is still an active area of development in the industry."
The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. "These risks aren't new with Cowork, but it might be the first time you're using a more advanced tool that moves beyond a simple conversation," the announcement notes.
Anthropic's desktop agent strategy sets up a direct challenge to Microsoft Copilot
The launch of Cowork places Anthropic in direct competition with Microsoft, which has spent years attempting to integrate its Copilot AI into the fabric of the Windows operating system with mixed adoption results.
However, Anthropic's approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.
What distinguishes Anthropic's approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — Claude Code — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.
Claude Code has generated significant enthusiasm among developers since its initial launch as a command-line tool in late 2024. The company expanded access with a web interface in October 2025, followed by a Slack integration in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.
Who can access Cowork now, and what's coming next for Windows and other platforms
For now, Cowork remains exclusive to Claude Max subscribers using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.
Anthropic has signaled clear intentions to expand the feature's reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.
Cherny set expectations appropriately, describing the product as "early and raw, similar to what Claude Code felt like when it first launched."
To access Cowork, Max subscribers can download or update the Claude macOS app and click on "Cowork" in the sidebar.
The real question facing enterprise AI adoption
For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.
Anthropic's goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.
But the speed of Cowork's development — a major feature built in ten days, possibly by the company's own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. The chatbot has learned to use a file manager. What it learns to use next is anyone's guess.]]></description>
      <pubDate>Mon, 12 Jan 2026 11:30:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no</guid>
    </item>
    <item>
      <title><![CDATA[Hugging Face and VirusTotal collaborate to strengthen AI security]]></title>
      <link>https://huggingface.co/blog/virustotal</link>
      <description><![CDATA[Back to Articles Why this matters How the collaboration works Benefits for the community Join us We’re excited to announce a new collaboration between Hugging Face and VirusTotal, the world’s leading threat-intelligence and malware analysis platform.
This collaboration enhances the security of files shared across the Hugging Face Hub, helping protect the machine learning community from malicious or compromised assets.
TL;DR - Starting today, every one of the 2.2M+ public model and datasets repositories on the Hugging Face Hub is being continuously scanned with VirusTotal. Why this matters AI models are powerful but they’re also complex digital artifacts that can include large binary files, serialized data, and dependencies that sometimes carry hidden risks.
As of today HF Hub hosts 2.2 Million Public model artifacts. As we continue to grow into the world’s largest open platform for Machine Learning models and datasets, ensuring that shared assets remain safe is essential.
Threats can take many forms: Malicious payloads disguised as model files or archives
Files that have been compromised before upload
Binary assets linked to known malware campaigns
Dependencies or serialized objects that execute unsafe code when loa]]></description>
      <pubDate>Wed, 22 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/virustotal</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face]]></title>
      <link>https://huggingface.co/blog/trackio</link>
      <description><![CDATA[Back to Articles Background Why We Switched to Trackio Using Trackio Installing Usage Visualizing Results Sharing with Spaces Integrated with Transformers and Accelerate Design Principles Next Steps TL;DR: Trackio is a new, open-source, and free experiment tracking Python library that provides a local dashboard and seamless integration with Hugging Face Spaces for easy sharing and collaboration. Since trackio is a drop-in replacement for wandb, you can get started with the syntax you already know! Background If you have trained your own machine learning model, you know how important it is to be able to track metrics, parameters, and hyperparameters during training and visualize them afterwards to better understand your training run.
Most machine learning researchers use specific experiment tracking libraries to do this. However, these libraries can be paid, require complex setup, or lack the flexibility needed for rapid experimentation and sharing. Why We Switched to Trackio At Hugging Face, our science team has started using Trac]]></description>
      <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/trackio</guid>
    </item>
    <item>
      <title><![CDATA[Agentic AI for Modern Deep Learning Experimentation]]></title>
      <link>https://towardsdatascience.com/agentic-ai-for-modern-deep-learning-experimentation/</link>
      <description><![CDATA[Stop babysitting training runs. Start shipping research. Autonomous experiment management built for/by deep learning engineers.]]></description>
      <pubDate>Wed, 18 Feb 2026 18:20:33 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/agentic-ai-for-modern-deep-learning-experimentation/</guid>
    </item>
    <item>
      <title><![CDATA[IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST]]></title>
      <link>https://huggingface.co/blog/ibm-research/itbenchandmast</link>
      <description><![CDATA[Back to Articles The "Black Box" Problem of Agent Benchmarks The Experiment: Diagnosing ITBench Agents Finding 1: Stronger models like Gemini-3-Flash shows surgical (isolated failure modes) per trace whereas open sourced Kimi-K2 and GPT-oss-120b show compounding failure patterns Finding 2: "Non-Fatal" vs. "Fatal" Failures The "Non-Fatal" (Benign) Flaws The "Fatal" Flaws Case Study: Gemini-3-Flash (Decisive but Overconfident) Case Study: GPT-OSS-120B A different (and more useful) way to read the plots: “fatal” vs “non-fatal” Recoverable / structural (show up even in successful traces) Fatal / decisive (strongly associated with failed traces) Conclusion Ayhan Sebin
Saurabh Jha
Rohan Arora
Daby Sow
Mert Cemri
Melissa Pan
Ion Stoica
ITBench HF Space
ITBench HF Dataset
MAST HF Dataset
ITBench Github
MAST Github
IBM Research and UC Berkeley collaborated to study how agentic LLM systems break in real-world IT automation, for tasks involving incident triage, logs/metrics queries, and Kubernetes actions in long-horizon tool loops.
Benchmarks typicall]]></description>
      <pubDate>Wed, 18 Feb 2026 16:15:45 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ibm-research/itbenchandmast</guid>
    </item>
    <item>
      <title><![CDATA[Scaling social science research]]></title>
      <link>https://openai.com/index/scaling-social-science-research</link>
      <description><![CDATA[GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.]]></description>
      <pubDate>Fri, 13 Feb 2026 09:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/scaling-social-science-research</guid>
    </item>
    <item>
      <title><![CDATA[Codex is Open Sourcing AI models]]></title>
      <link>https://huggingface.co/blog/hf-skills-training-codex</link>
      <description><![CDATA[Back to Articles GOAL: End-to-end Machine Learning experiments Setup and Install Install Codex Install the Hugging Face Skills Connect to Hugging Face Your first AI Experiment Instruct Codex to do an end-to-end fine-tuning experiment Updating the Training Report Dataset Validation Review Before Submitting Track Progress using the Training Report Use Your Model Hardware and Cost What's Next Resources Codex Hugging Face Skills Building on our work to get Claude Code to train open source models, we are now getting Codex to go further. We gave Codex access to the Hugging Face Skills repository, which contains skills for Machine Learning and AI tasks such as training or evaluating models. With HF skills, a coding agent can: Fine-tune and apply RL alignment on language models
Review, explain, and act on live training metrics from Trackio
Evaluate checkpoints and act on evaluation results
Create reports from experiments
Export to and q]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hf-skills-training-codex</guid>
    </item>
    <item>
      <title><![CDATA[LeRobot v0.4.0: Supercharging OSS Robot Learning]]></title>
      <link>https://huggingface.co/blog/lerobot-release-v040</link>
      <description><![CDATA[Back to Articles TL;DR Table-of-Contents Datasets: Ready for the Next Wave of Large-Scale Robot Learning What's New in Datasets v3.0? New Feature: Dataset Editing Tools! Simulation Environments: Expanding Your Training Grounds LIBERO Support Meta-World Integration Codebase: Powerful Tools For Everyone The New Pipeline for Data Processing Multi-GPU Training Made Easy Policies: Unleashing Open-World Generalization PI0 and PI0.5 GR00T N1.5 Robots: A New Era of Hardware Integration with the Plugin System Key Benefits Reachy 2 Integration Phone Integration The Hugging Face Robot Learning Course Deep Dive: The Modern Robot Learning Tutorial Final thoughts from the team We're thrilled to announce a series of significant advancements across LeRobot, designed to make open-source]]></description>
      <pubDate>Fri, 24 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/lerobot-release-v040</guid>
    </item>
    <item>
      <title><![CDATA[Google Cloud C4 Brings a 70% TCO improvement on GPT OSS with Intel and Hugging Face]]></title>
      <link>https://huggingface.co/blog/gpt-oss-on-intel-xeon</link>
      <description><![CDATA[Back to Articles Intel and Hugging Face collaborated to demonstrate the real-world value of upgrading to Google’s latest C4 Virtual Machine (VM) running on Intel Xeon 6 processors (codenamed Granite Rapids (GNR)). We specifically wanted to benchmark improvements in the text generation performance of OpenAI GPT OSS Large Language Model(LLM). The results are in, and they are impressive, demonstrating a 1.7x improvement in Total Cost of Ownership(TCO) over the previous-generation Google C3 VM instances. The Google Cloud C4 VM instance further resulted in: 1.4x to 1.7x TPOT throughput/vCPU/dollar
Lower price per hour over C3 VM Introduction GPT OSS is a common name for an open-source Mixture of Experts (MoE) model released by OpenAI. An MoE model is a deep neural network architecture that uses specialized “expert” sub-networks and a “gating network” to decide which experts to use for a given input. MoE models allow you to scale your model capacity efficiently without linearly scaling compute costs. They also allow for specialization, where different “experts” learn different skills, allowing them to adapt to diverse data distributions.
Even with very large parameters, only a small subset of experts is activated per token, making CPU inference viable.
Intel and]]></description>
      <pubDate>Thu, 16 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/gpt-oss-on-intel-xeon</guid>
    </item>
    <item>
      <title><![CDATA[An End-to-End Guide to Beautifying Your Open-Source Repo with Agentic AI]]></title>
      <link>https://towardsdatascience.com/an-end-to-end-guide-to-beautifying-your-open-source-repo-with-agentic-ai/</link>
      <description><![CDATA[The guide to automated improvement of scientific and industrial repositories using open-source AI agents]]></description>
      <pubDate>Fri, 20 Feb 2026 13:30:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/an-end-to-end-guide-to-beautifying-your-open-source-repo-with-agentic-ai/</guid>
    </item>
    <item>
      <title><![CDATA[Snowflake and OpenAI partner to bring frontier intelligence to enterprise data]]></title>
      <link>https://openai.com/index/snowflake-partnership</link>
      <description><![CDATA[OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling AI agents and insights directly in Snowflake.]]></description>
      <pubDate>Mon, 02 Feb 2026 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/snowflake-partnership</guid>
    </item>
    <item>
      <title><![CDATA[One Year Since the “DeepSeek Moment”]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</link>
      <description><![CDATA[Back to Articles The Seeds of China’s Organic Open Source AI Ecosystem DeepSeek R1: A Turning Point From DeepSeek to AI+: Strategic Realignmentt Global Reception and Response This is the first blog in a series that will examine China’s open source community’s historical advancements in the past year and its reverberations in shaping the entire ecosystem. Much of 2025’s progress can be traced back to January’s “DeepSeek Moment”, when Hangzhou-based AI company DeepSeek released their R-1 model. The first blog addresses strategic changes and the explosion of new open models and open source players. The second covers architectural and hardware choices largely by Chinese companies made in the wake of a growing open ecosystem, available here. The third analyzes prominent organizations’ trajectories and the future of the global open source ecosystem, available here.
For AI researchers and developers contributing to and relying on the open source ecosystem and for policymakers understanding the rapidly changing environment, there has never been a better time to build and release open models and artifacts, as proven by the past year’s immense growth catalyzed by DeepSeek. Notably, geopolitics has driven adoption; while models developed in]]></description>
      <pubDate>Tue, 20 Jan 2026 15:02:10 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</guid>
    </item>
    <item>
      <title><![CDATA[A business that scales with the value of intelligence]]></title>
      <link>https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence</link>
      <description><![CDATA[OpenAI’s business model scales with intelligence—spanning subscriptions, API, ads, commerce, and compute—driven by deepening ChatGPT adoption.]]></description>
      <pubDate>Sun, 18 Jan 2026 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture]]></title>
      <link>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</link>
      <description><![CDATA[Back to Articles Discover more in our official blogpost, featuring an interactive experience The journey of building world-class Arabic language models has been one of continuous learning and iteration. Today, we're excited to announce Falcon-H1-Arabic, our most advanced Arabic language model family to date, representing a significant leap forward in both architecture and capabilities. This release embodies months of research, community feedback, and technical innovation, culminating in three powerful models that set new standards for Arabic natural language processing. Building on Success: The Evolution from Falcon-Arabic When we launched Falcon-Arabic a few months ago, the response from the community was both humbling and enlightening. Developers, researchers and students across the Arab world used the model for real use cases, pushing them to its limits and providing invaluable feedback. We learned where the model excelled and, more importantly, where it struggled. Long-context understanding, dialectal variations, mathematical reasoning, and domain-specific knowledge emerged as key areas requiring deeper attention.
We didn't just want to make incremental improvements, we wanted to fundamentally rethink o]]></description>
      <pubDate>Mon, 05 Jan 2026 09:16:51 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</guid>
    </item>
    <item>
      <title><![CDATA[The creator of Claude Code just revealed his workflow, and developers are losing their minds]]></title>
      <link>https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are</link>
      <description><![CDATA[When the creator of the world's most advanced coding agent speaks, Silicon Valley doesn't just listen — it takes notes.
For the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup. "If you're not reading the Claude Code best practices straight from its creator, you're behind as a programmer," wrote Jeff Tang, a prominent voice in the developer community. Kyle McNease, another industry observer, went further, declaring that with Cherny's "game-changing updates," Anthropic is "on fire," potentially facing "their ChatGPT moment."
The excitement stems from a paradox: Cherny's workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny's setup, the experience "feels more like Starcraft" than traditional coding — a shift from typing syntax to commanding autonomous units.
Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. How running five AI agents at once turns coding into a real-time strategy game
The most striking revelation from Cherny's disclosure is that he does not code in a linear fashion. In the traditional "inner loop" of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.
"I run 5 Claudes in parallel in my terminal," Cherny wrote. "I number my tabs 1-5, and use system notifications to know when a Claude needs input."
By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs "5-10 Claudes on claude.ai" in his browser, using a "teleport" command to hand off sessions between the web and his local machine.
This validates the "do more with less" strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.
The counterintuitive case for choosing the slowest, smartest model
In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic's heaviest, slowest model: Opus 4.5.
"I use Opus 4.5 with thinking for everything," Cherny explained. "It's the best coding model I've ever used, and even though it's bigger &amp; slower than Sonnet, since you have to steer it less and it's better at tool use, it is almost always faster than using a smaller model in the end."
For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn't the generation speed of the token; it is the human time spent correcting the AI's mistakes. Cherny's workflow suggests that paying the "compute tax" for a smarter model upfront eliminates the "correction tax" later.
One shared file turns every AI mistake into a permanent lesson
Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not "remember" a company's specific coding style or architectural decisions from one session to the next.
To address this, Cherny's team maintains a single file named CLAUDE.md in their git repository. "Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time," he wrote.]]></description>
      <pubDate>Mon, 05 Jan 2026 07:45:00 GMT</pubDate>
      <source>VentureBeat AI</source>
      <category>ai</category>
      <guid>https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are</guid>
    </item>
    <item>
      <title><![CDATA[The state of enterprise AI]]></title>
      <link>https://openai.com/index/the-state-of-enterprise-ai-2025-report</link>
      <description><![CDATA[Key findings from OpenAI’s enterprise data show accelerating AI adoption, deeper integration, and measurable productivity gains across industries in 2025.]]></description>
      <pubDate>Mon, 08 Dec 2025 04:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/the-state-of-enterprise-ai-2025-report</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption]]></title>
      <link>https://openai.com/index/thrive-holdings</link>
      <description><![CDATA[OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption, embedding frontier research and engineering directly into accounting and IT services to boost speed, accuracy, and efficiency while creating a scalable model for industry-wide transformation.]]></description>
      <pubDate>Mon, 01 Dec 2025 05:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/thrive-holdings</guid>
    </item>
    <item>
      <title><![CDATA[Expanding data residency access to business customers worldwide]]></title>
      <link>https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide</link>
      <description><![CDATA[OpenAI expands data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform, enabling eligible customers to store data at rest in-region.]]></description>
      <pubDate>Tue, 25 Nov 2025 22:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide</guid>
    </item>
    <item>
      <title><![CDATA[Join the AMD Open Robotics Hackathon]]></title>
      <link>https://huggingface.co/blog/amd/openroboticshackathon</link>
      <description><![CDATA[Back to Articles Looking to show off your robotics aptitude? The AMD Open Robotics Hackathon hosted by AMD, Hugging Face, and Data Monsters is the place to do it. Whether you’re a student, hobbyist, startup founder, or seasoned engineer, this event brings together makers, coders, and roboticists for a fast-paced, hands-on competition that turns bold ideas into functioning demos.
The first of two in-person hackathons will take place from December 5-7, 2025 in Tokyo Japan. Our next stop will be in Paris France from December 12-14, 2025.
Preparing for the Hackathon:
Form a team of up to four roboticists (ages 18+) to take on two missions over the course of 3 days.
Mission 1 — An instructor-led exploration and preparation session. Learn how to set up the LeRobot development environment using AMD AI solutions
Mission 2 — Build your own creative solution to a real-world problem. Your team has two days to develop an innovative freestyle project using LeRobot technical proficiency:
•	Strong Linux development skills and experience with Python and related tooling and containerization
•	Machine learning skills, familiarity with PyTorch, and hands-on experience with model training and inference
•	Bonus if your team has experience with ROCm, LeRobot, and embedded development.
Hardware will be provi]]></description>
      <pubDate>Thu, 13 Nov 2025 21:37:26 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/amd/openroboticshackathon</guid>
    </item>
    <item>
      <title><![CDATA[huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning]]></title>
      <link>https://huggingface.co/blog/huggingface-hub-v1</link>
      <description><![CDATA[Back to Articles The Story Behind the Library The Foundation Years (2020-2021) The Great Shift: Git to HTTP (2022) An Expanding API Surface (2022–2024) Ready. Xet. Go! (2024-2025) Measuring Growth and Impact Building for the Next Decade Modern HTTP Infrastructure with httpx and hf_xet Agents Made Simple with MCP and Tiny-Agents A Fully-Featured CLI for Modern Workflows Cleaning House for the Future The Migration Guide Acknowledgments TL;DR: After five years of development, huggingface_hub has reached v1.0 - a milestone that marks the library's maturity as the Python package powering 200,000 dependent libraries and providing core functionality for accessing over 2 million public models, 0.5 million public datasets, and 1 million public Spaces. This release introduces breaking changes designed to support the next decade of open machine learning, driven by a global community of almost 300 contributors and millions of users. We highly recommend upgrading to v1.0 to benefit from major performanc]]></description>
      <pubDate>Mon, 27 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface-hub-v1</guid>
    </item>
    <item>
      <title><![CDATA[Smol2Operator: Post-Training GUI Agents for Computer Use]]></title>
      <link>https://huggingface.co/blog/smol2operator</link>
      <description><![CDATA[Back to Articles TL;DR: This work shows how a lightweight vision–language model can acquire GUI-grounded skills and evolve into an agentic GUI coder. We release all training recipes, data-processing tools, resulting model, demo and datasets to enable full reproducibility and foster further research . Find the collection here. This video demonstrates the model obtained through the recipe described below, executing a task end-to-end. Table of Contents Introduction
1. Data Transformation and Unified Action Space
The Challenge of Inconsistent Action Spaces
Our Unified Approach
Example Data Transformation
Custom Action Space Adaptation with Action Space Converter
Key Features
Usage Example
Transformed and Released Datasets 2. Phase 1: From Zero to Perception
Training Data
Optimization Experiments
Image Resolution and Coordinate System Analysis
Key Findings
Phase 1 Results 3. Phase 2: From Perception to Cognition
Training Data
Phase 2 Results 4. All you need is Open Source
5. Conclusion
What's Next? Introduction Graphical User Interface (GUI) automation is one of the most challenging frontiers in computer vision. Developing models that see and interact with user interfaces enables AI agents to navigate mobil]]></description>
      <pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/smol2operator</guid>
    </item>
    <item>
      <title><![CDATA[Fine-tune Any LLM from the Hugging Face Hub with Together AI]]></title>
      <link>https://huggingface.co/blog/togethercomputer/together-ft</link>
      <description><![CDATA[Back to Articles Getting Started in 5 Minutes How It Works: What This Means for Developers How Teams Are Using This Feature? Show Us What You Build! The pace of AI development today is breathtaking. Every single day, hundreds of new models appear on the Hugging Face Hub, some are specialized variants of popular base models like Llama or Qwen, others feature novel architectures or have been trained from scratch for specific domains. Whether it's a medical AI trained on clinical data, a coding assistant optimized for a particular programming language, or a multilingual model fine-tuned for specific cultural contexts, the Hugging Face Hub has become the beating heart of open-source AI innovation.
But here's the challenge: finding an amazing model is just the beginning. What happens when you discover a model that's 90% perfect for your use case, but you need that extra 10% of customization? Traditional fine-tuning infrastructure is complex, expensive, and often requires significant DevOps expertise to set up and maintain.
This is exactly the gap that Together AI and Hugging Face are bridging today. We're announcing a powerful new capability that makes the entire Hugging Face Hub available]]></description>
      <pubDate>Wed, 10 Sep 2025 17:04:36 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/togethercomputer/together-ft</guid>
    </item>
    <item>
      <title><![CDATA[Introducing AI Sheets: a tool to work with datasets using open AI models!]]></title>
      <link>https://huggingface.co/blog/aisheets</link>
      <description><![CDATA[The Wayback Machine is an initiative of the Internet Archive, a 501(c)(3) non-profit, building a digital library of Internet sites and other cultural artifacts in digital form. Other projects include Open Library &amp; archive-it.org. Your use of the Wayback Machine is subject to the Internet Archive's Terms of Use.]]></description>
      <pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/aisheets</guid>
    </item>
    <item>
      <title><![CDATA[Measuring Open-Source Llama Nemotron Models on DeepResearch Bench]]></title>
      <link>https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent</link>
      <description><![CDATA[Measuring Open-Source Llama Nemotron Models on DeepResearch Bench]]></description>
      <pubDate>Mon, 04 Aug 2025 19:51:50 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent</guid>
    </item>
    <item>
      <title><![CDATA[Use OpenClaw to Make a Personal AI Assistant]]></title>
      <link>https://towardsdatascience.com/use-openclaw-to-make-a-personal-ai-assistant/</link>
      <description><![CDATA[Learn how to set up OpenClaw as a personalized AI agent]]></description>
      <pubDate>Wed, 18 Feb 2026 00:25:14 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/use-openclaw-to-make-a-personal-ai-assistant/</guid>
    </item>
    <item>
      <title><![CDATA[Architecting GPUaaS for Enterprise AI On-Prem]]></title>
      <link>https://towardsdatascience.com/architecting-gpuaas-for-enterprise-ai-on-prem/</link>
      <description><![CDATA[Multi-tenancy, scheduling, and cost modeling on Kubernetes]]></description>
      <pubDate>Sat, 21 Feb 2026 15:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/architecting-gpuaas-for-enterprise-ai-on-prem/</guid>
    </item>
    <item>
      <title><![CDATA[From Monolith to Contract-Driven Data Mesh]]></title>
      <link>https://towardsdatascience.com/from-monolith-to-contract-driven-data-mesh/</link>
      <description><![CDATA[A pragmatic journey using website analytics as a real-world example]]></description>
      <pubDate>Fri, 20 Feb 2026 12:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/from-monolith-to-contract-driven-data-mesh/</guid>
    </item>
    <item>
      <title><![CDATA[AI in Multiple GPUs: How GPUs Communicate]]></title>
      <link>https://towardsdatascience.com/how-gpus-communicate/</link>
      <description><![CDATA[A deep dive into the hardware infrastructure that enables multi-GPU communication for AI workloads]]></description>
      <pubDate>Thu, 19 Feb 2026 12:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/how-gpus-communicate/</guid>
    </item>
    <item>
      <title><![CDATA[Why Every Analytics Engineer Needs to Understand Data Architecture]]></title>
      <link>https://towardsdatascience.com/why-every-analytics-engineer-needs-to-understand-data-architecture/</link>
      <description><![CDATA[Get the data architecture right, and everything else becomes easier.
I know it sounds simple, but in reality, little nuances in designing your data architecture may have costly implications.]]></description>
      <pubDate>Wed, 18 Feb 2026 19:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/why-every-analytics-engineer-needs-to-understand-data-architecture/</guid>
    </item>
    <item>
      <title><![CDATA[A beginner’s guide to Tmux: a multitasking superpower for your terminal]]></title>
      <link>https://towardsdatascience.com/a-beginners-guide-to-tmux-a-multitasking-superpower-for-your-terminal/</link>
      <description><![CDATA[One of the new things I’ve come across recently, while researching command-line-based coding assistants, is the mention and use of a tool I hadn’t heard of before. That tool is called Tmux, which stands for Terminal Multiplexer. In the simplest possible terms, Tmux allows you to split up a single terminal window into a number […]]]></description>
      <pubDate>Sun, 15 Feb 2026 11:50:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/a-beginners-guide-to-tmux-a-multitasking-superpower-for-your-terminal/</guid>
    </item>
    <item>
      <title><![CDATA[Your First 90 Days as a Data Scientist]]></title>
      <link>https://towardsdatascience.com/your-first-90-days-as-a-data-scientist/</link>
      <description><![CDATA[A practical onboarding checklist for building trust, business fluency, and data intuition]]></description>
      <pubDate>Sat, 14 Feb 2026 11:25:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/your-first-90-days-as-a-data-scientist/</guid>
    </item>
    <item>
      <title><![CDATA[OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments]]></title>
      <link>https://huggingface.co/blog/openenv-turing</link>
      <description><![CDATA[Back to Articles What Is OpenEnv? The Calendar Gym: A Production-Grade Benchmark What We Learned Looking Ahead Appendix: Common error cases in tool use Specific error cases found in the wild AI agents often perform impressively in controlled research settings, yet struggle when deployed in real-world systems where they must reason across multiple steps, interact with real tools and APIs, operate under partial information, and recover from errors in stateful, permissioned environments—highlighting a persistent gap between research success and production reliability.
OpenEnv is an open-source framework from Meta and Hugging Face designed to address this challenge by standardizing how agents interact with real environments. As part of this collaboration, Turing contributed a production-grade calendar management environment to study tool-using agents under realistic constraints such as access control, temporal reasoning, and multi-agent coordination.
In this post, we explore how OpenEnv works in practice, why calendars serve as a powerful benchmark for real-world agent evaluation, and what our findings reveal about the current limitations of tool-using age]]></description>
      <pubDate>Thu, 12 Feb 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openenv-turing</guid>
    </item>
    <item>
      <title><![CDATA[Introducing SyGra Studio]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link>
      <description><![CDATA[Back to Articles Step 1: Configure the data source Step 2: Build the flow visually Step 3: Review and run See it in action! Running Existing Workflows Run the Glaive Code Assistant workflow Get started SyGra 2.0.0 introduces Studio, an interactive environment that turns synthetic data generation into a transparent, visual craft. Instead of juggling YAML files and terminals, you compose flows directly on the canvas, preview datasets before committing, tune prompts with inline variable hints, and watch executions stream live—all from a single pane. Under the hood it’s the same platform, so everything you do visually generates the corresponding SyGra compatible graph config and task executor scripts. What Studio lets you do Configure and validate models with guided forms (OpenAI, Azure OpenAI, Ollama, Vertex, Bedrock, vLLM, custom endpoints).
Connect Hugging Face, file-system, or ServiceNow data sources and preview rows before execution.
Configure nodes by selecting models, writing prompts (with auto-suggested variables), and defining outputs or structured schemas.
Design downstream outputs using shared state variables a]]></description>
      <pubDate>Thu, 05 Feb 2026 16:52:28 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</guid>
    </item>
    <item>
      <title><![CDATA[The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+]]></title>
      <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</link>
      <description><![CDATA[The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+]]></description>
      <pubDate>Tue, 03 Feb 2026 15:03:19 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</guid>
    </item>
    <item>
      <title><![CDATA[Taisei Corporation shapes the next generation of talent with ChatGPT]]></title>
      <link>https://openai.com/index/taisei</link>
      <description><![CDATA[Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across its global construction business.]]></description>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/taisei</guid>
    </item>
    <item>
      <title><![CDATA[We Got Claude to Build CUDA Kernels and teach open models!]]></title>
      <link>https://huggingface.co/blog/upskill</link>
      <description><![CDATA[Back to Articles What are agent skills? 1. Get the teacher (Claude Opus 4.5) to build a kernel 2. Make an agent skill from the trace 3. Take your skill to an open source, smaller, or cheaper model Deep dive tutorial into building kernels with agent skills Setup and Install Skill Generation Generate the Skill Evaluate on a Different Model How the evaluation in upskill works What's Next Resources The best thing about agent skills is upskilling your agents on hard problems. There are two ways to look at that: You can take Opus 4.5 or other SOTA models and tackle the hardest problems out there. You can take models that run on your laptop and upskill them to harder problems. In this blog post, we’ll show you how to take on the latter. This blog post walks through the process of using a new tool, upskill, to generate and evaluate agent skills with large models and use them with smaller models. We will benchmark upskill on the task of writing CUDA kernels for diffusers models, but the process is generally useful for cutting costs, or using smaller models]]></description>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/upskill</guid>
    </item>
    <item>
      <title><![CDATA[Inside GPT-5 for Work: How Businesses Use GPT-5]]></title>
      <link>https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work</link>
      <description><![CDATA[A data-driven report on how workers across industries use ChatGPT—covering adoption trends, top tasks, departmental patterns, and the future of AI at work.]]></description>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work</guid>
    </item>
    <item>
      <title><![CDATA[Investing in Merge Labs]]></title>
      <link>https://openai.com/index/investing-in-merge-labs</link>
      <description><![CDATA[OpenAI is investing in Merge Labs to support new brain computer interfaces that bridge biological and artificial intelligence to maximize human ability, agency, and experience.]]></description>
      <pubDate>Thu, 15 Jan 2026 07:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/investing-in-merge-labs</guid>
    </item>
    <item>
      <title><![CDATA[Deepening our collaboration with the U.S. Department of Energy]]></title>
      <link>https://openai.com/index/us-department-of-energy-collaboration</link>
      <description><![CDATA[OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to deepen collaboration on AI and advanced computing in support of scientific discovery. The agreement builds on ongoing work with national laboratories and helps establish a framework for applying AI to high-impact research across the DOE ecosystem.]]></description>
      <pubDate>Thu, 18 Dec 2025 11:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/us-department-of-energy-collaboration</guid>
    </item>
    <item>
      <title><![CDATA[The Open Evaluation Standard: Benchmarking NVIDIA Nemotron 3 Nano with NeMo Evaluator]]></title>
      <link>https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe</link>
      <description><![CDATA[Back to Articles It has become increasingly challenging to assess whether a model’s
reported improvements reflect genuine advances or variations in
evaluation conditions, dataset composition, or training data that
mirrors benchmark tasks. The NVIDIA Nemotron approach to openness
addresses this by publishing transparent and reproducible evaluation
recipes that make results independently verifiable.
NVIDIA released Nemotron 3 Nano 30B
A3B
with an explicitly open evaluation approach to make that distinction
clear. Alongside the model card, we are publishing the complete
evaluation recipe used to generate the results, built with the
NVIDIA NeMo
Evaluator library, so
anyone can rerun the evaluation pipeline, inspect the artifacts, and
analyze the outcomes independently.
We believe that open innovation is the foundation of AI progress. This
level of transparency matters because most model evaluations omit
critical details. Configs, prompts, harness versions, runtime settings,
and logs are often missing or underspecified, and even small differences
in these parameters can materially change results. Without a complete
recipe, it’s nearly impossible to tell whether a model is genuinely
more intelligent or si]]></description>
      <pubDate>Wed, 17 Dec 2025 13:22:18 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe</guid>
    </item>
    <item>
      <title><![CDATA[Evaluating AI’s ability to perform scientific research tasks]]></title>
      <link>https://openai.com/index/frontierscience</link>
      <description><![CDATA[OpenAI introduces FrontierScience, a benchmark testing AI reasoning in physics, chemistry, and biology to measure progress toward real scientific research.]]></description>
      <pubDate>Tue, 16 Dec 2025 09:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/frontierscience</guid>
    </item>
    <item>
      <title><![CDATA[CUGA on Hugging Face: Democratizing Configurable AI Agents]]></title>
      <link>https://huggingface.co/blog/ibm-research/cuga-on-hugging-face</link>
      <description><![CDATA[Back to Articles Introduction Introduction What is CUGA? Open Source and Open Models Integration with Langflow: Visual Agent Design Made Simple Try the Hugging Face Demo: A Hands-On Preview Conclusion and Call to Action AI agents are rapidly becoming essential for building intelligent applications, but creating robust, adaptable agents that scale across domains remains a challenge. Many existing frameworks struggle with brittleness, tool misuse, and failures when faced with complex workflows.
CUGA (Configurable Generalist Agent) was designed to overcome these limitations. It's an open-source, AI Agent that combines flexibility, reliability, and ease of use for enterprise use cases. By abstracting orchestration complexity, CUGA empowers developers to focus on domain requirements rather than the internals of agent building. And now, with its integration into Hugging Face Spaces, experimenting with CUGA and open models has never been easier. What is CUGA? CUGA is a configurable, general-purpose AI agent that supports complex, multi-step tasks across web and API environments. It has achieved state-of-the-art performance on leadin]]></description>
      <pubDate>Mon, 15 Dec 2025 16:01:04 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ibm-research/cuga-on-hugging-face</guid>
    </item>
    <item>
      <title><![CDATA[Advancing science and math with GPT-5.2]]></title>
      <link>https://openai.com/index/gpt-5-2-for-science-and-math</link>
      <description><![CDATA[GPT-5.2 is OpenAI’s strongest model yet for math and science, setting new state-of-the-art results on benchmarks like GPQA Diamond and FrontierMath. This post shows how those gains translate into real research progress, including solving an open theoretical problem and generating reliable mathematical proofs.]]></description>
      <pubDate>Thu, 11 Dec 2025 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/gpt-5-2-for-science-and-math</guid>
    </item>
    <item>
      <title><![CDATA[Update to GPT-5 System Card: GPT-5.2]]></title>
      <link>https://openai.com/index/gpt-5-system-card-update-gpt-5-2</link>
      <description><![CDATA[GPT-5.2 is the latest model family in the GPT-5 series. The comprehensive safety mitigation approach for these models is largely the same as that described in the GPT-5 System Card and GPT-5.1 System Card. Like OpenAI’s other models, the GPT-5.2 models were trained on diverse datasets, including information that is publicly available on the internet, information that we partner with third parties to access, and information that our users or human trainers and researchers provide or generate.]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/gpt-5-system-card-update-gpt-5-2</guid>
    </item>
    <item>
      <title><![CDATA[Bringing powerful AI to millions across Europe with Deutsche Telekom]]></title>
      <link>https://openai.com/index/deutsche-telekom-collaboration</link>
      <description><![CDATA[OpenAI is collaborating with Deutsche Telekom to bring advanced, multilingual AI experiences to millions of people across Europe. ChatGPT Enterprise will also be deployed to help employees at Deutsche Telekom improve workflows and accelerate innovation.]]></description>
      <pubDate>Tue, 09 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/deutsche-telekom-collaboration</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI appoints Denise Dresser as Chief Revenue Officer]]></title>
      <link>https://openai.com/index/openai-appoints-denise-dresser</link>
      <description><![CDATA[Denise Dresser is joining as Chief Revenue Officer, overseeing OpenAI’s global revenue strategy across enterprise and customer success. She will help more businesses put AI to work in their day-to-day operations as OpenAI continues to scale.]]></description>
      <pubDate>Tue, 09 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/openai-appoints-denise-dresser</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI to acquire Neptune]]></title>
      <link>https://openai.com/index/openai-to-acquire-neptune</link>
      <description><![CDATA[OpenAI is acquiring Neptune to deepen visibility into model behavior and strengthen the tools researchers use to track experiments and monitor training.]]></description>
      <pubDate>Wed, 03 Dec 2025 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/openai-to-acquire-neptune</guid>
    </item>
    <item>
      <title><![CDATA[Accenture and OpenAI accelerate enterprise AI success]]></title>
      <link>https://openai.com/index/accenture-partnership</link>
      <description><![CDATA[Accenture and OpenAI are collaborating to help enterprises bring agentic AI capabilities into the core of their business and unlock new levels of growth.]]></description>
      <pubDate>Mon, 01 Dec 2025 05:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/accenture-partnership</guid>
    </item>
    <item>
      <title><![CDATA[Mixpanel security incident: what OpenAI users need to know]]></title>
      <link>https://openai.com/index/mixpanel-incident</link>
      <description><![CDATA[OpenAI shares details about a Mixpanel security incident involving limited API analytics data. No API content, credentials, or payment details were exposed. Learn what happened and how we’re protecting users.]]></description>
      <pubDate>Wed, 26 Nov 2025 19:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/mixpanel-incident</guid>
    </item>
    <item>
      <title><![CDATA[Early experiments in accelerating science with GPT-5]]></title>
      <link>https://openai.com/index/accelerating-science-gpt-5</link>
      <description><![CDATA[OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.]]></description>
      <pubDate>Thu, 20 Nov 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/accelerating-science-gpt-5</guid>
    </item>
    <item>
      <title><![CDATA[How Scania is accelerating work with AI across its global workforce]]></title>
      <link>https://openai.com/index/scania</link>
      <description><![CDATA[Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.]]></description>
      <pubDate>Wed, 19 Nov 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/scania</guid>
    </item>
    <item>
      <title><![CDATA[How to Build a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac for Healthcare]]></title>
      <link>https://huggingface.co/blog/nvidia/nvidia-isaac-for-healthcare</link>
      <description><![CDATA[Back to Articles A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware SO-ARM Starter Workflow; Building an Embodied Surgical Assistant Technical Implementation Sim-to-Real Mixed Training Approach Hardware Requirements Data Collection Implementation Simulation Teleoperation Controls Model Training Pipeline End-to-End Sim Collect–Train–Eval Pipelines Generate Synthetic Data in Simulation Train and Evaluate Policies Convert Models to TensorRT Getting Started Resources A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware Simulation has been a cornerstone in medical imaging to address the data gap. However, in healthcare robotics until now, it's often been too slow, siloed, or difficult to translate into real-world systems. That’s now changing. With new advances in GPU-accelerated simulation and digital twins, developers can design, test, and validate robotic w]]></description>
      <pubDate>Tue, 28 Oct 2025 20:42:35 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nvidia-isaac-for-healthcare</guid>
    </item>
    <item>
      <title><![CDATA[Streaming datasets: 100x More Efficient]]></title>
      <link>https://huggingface.co/blog/streaming-datasets</link>
      <description><![CDATA[Back to Articles TLDR Streaming: The Same Easy API The Challenge: Streaming at Scale Under the Hood: What We Improved How are we faster than plain S3: Xet Need a custom streaming pipeline ? Push streaming to the limit Get Started and See the Difference TLDR We boosted load_dataset('dataset', streaming=True), streaming datasets without downloading them with one line of code!
Start training on multi-TB datasets immediately, without complex setups, downloading, no "disk out of space", or 429 “stop requesting!” errors.It's super fast! Outrunning our local SSDs when training on 64xH100 with 256 workers downloading data.
We've improved streaming to have 100x fewer requests, → 10× faster data resolution → 2x sample/sec, → 0 worker crashes at 256 concurrent workers. Loading data, especially at the terabyte scale, is a major pain in any machine learning workflow. We suffered this while training SmolLM3, at one point we had to wait 3 hours before each run to download enough data. Streaming has always been possible in the datasets library, but large scale training with massive datasets remained a challenge. That]]></description>
      <pubDate>Mon, 27 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/streaming-datasets</guid>
    </item>
    <item>
      <title><![CDATA[Sentence Transformers is joining Hugging Face!]]></title>
      <link>https://huggingface.co/blog/sentence-transformers-joins-hf</link>
      <description><![CDATA[Back to Articles Project History Acknowledgements Getting Started Today, we are announcing that Sentence Transformers is transitioning from Iryna Gurevych’s Ubiquitous Knowledge Processing (UKP) Lab at the TU Darmstadt to Hugging Face. Hugging Face's Tom Aarsen has already been maintaining the library since late 2023 and will continue to lead the project. At its new home, Sentence Transformers will benefit from Hugging Face's robust infrastructure, including continuous integration and testing, ensuring that it stays up-to-date with the latest advancements in Information Retrieval and Natural Language Processing.
Sentence Transformers (a.k.a. SentenceBERT or SBERT) is a popular open-source library for generating high-quality embeddings that capture semantic meaning. Since its inception by Nils Reimers in 2019, Sentence Transformers has been widely adopted by researchers and practitioners for various natural language processing (NLP) tasks, including semantic search, semantic textual similarity, clustering, and paraphrase mining. After years of development and training by and for the community, over 16,000 Sentence Transformers models are publicly available on the Hugging Face Hub, serving more than a million monthly unique users.
"Sentence Transformers has been]]></description>
      <pubDate>Wed, 22 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/sentence-transformers-joins-hf</guid>
    </item>
    <item>
      <title><![CDATA[AI for Food Allergies]]></title>
      <link>https://huggingface.co/blog/hugging-science/ai-for-food-allergies</link>
      <description><![CDATA[Back to Articles Current State of The Art: Where AI Meets Food Allergy Research The need for data Collection release The Protein and Molecular Allergenicity Layer The Clinical, Immunological, and Therapeutic Layer The Food, Ingredient, and Regulatory Layer Accessing the collection What’s coming next? Final remarks Appendix SDAP 2.0: Structural Database of Allergenic Proteins DAVIS: Kinase inhibitor binding affinities QsarDB: repository for (Q)SAR models e-Drug3D Database Stanford Drug Data: Offsides/Twosides DrugCentral: open drug information repository MedKG: medical knowledge graph PDBBind+: protein-ligand binding database Human Metabolome Database (HMDB) Therapeutic Target Database Therapeutic Data Commons (TDC) STITCH: Chemical–Protein Interaction Database M3-20M Multi-Modal Molecule Dataset]]></description>
      <pubDate>Thu, 16 Oct 2025 22:38:11 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hugging-science/ai-for-food-allergies</guid>
    </item>
    <item>
      <title><![CDATA[Jupyter Agents: training LLMs to reason with notebooks]]></title>
      <link>https://huggingface.co/blog/jupyter-agent-2</link>
      <description><![CDATA[Back to Articles The past year has been all about giving LLMs more tools and autonomy to solve more complex and open ended tasks. The goal of the Jupyter Agent is to give the model the ultimate tool: code execution. A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can execute code directly inside a Jupyter notebook and use this environment to solve data analysis and data science tasks. Think of it like Cursor, but living natively inside your data science workflow.We built a demo of this vision with Qwen-3 Coder, currently one of the strongest coding models. This is a follow-up to our earlier work on jupyter-agent (v1).
While large models are starting to show useful behavior, the key question is how we can continue improving them. To this end, we focus on strengthening smaller models to perform well on agentic data science tasks as they currently struggle to compete with the large models.
The goal of this project is to build a pipeline to first generate high-quality training data, then fine-tune an existing small model, and finally evaluate whether the model's performance improves on relevant benchmarks.
Let’s begin with the last step: select]]></description>
      <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/jupyter-agent-2</guid>
    </item>
    <item>
      <title><![CDATA[mmBERT: ModernBERT goes Multilingual]]></title>
      <link>https://huggingface.co/blog/mmbert</link>
      <description><![CDATA[Back to Articles TL;DR Training Data Training Recipe and Novel Components Architecture Three-Phase Training Approach Novel Training Techniques Results Natural Language Understanding (NLU) Retrieval Performance Learning Languages in the Decay Phase Efficiency Improvements Usage Examples Fine-tuning Examples Encoders Model Family and Links TL;DR This blog post introduces mmBERT, a state-of-the-art massively multilingual encoder model trained on 3T+ tokens of text in over 1800 languages. It shows significant performance and speed improvements over previous multilingual models, being the first to improve upon XLM-R, while also developing new strategies for effectively learning low-resource languages. mmBERT builds upon ModernBERT for a blazingly fast architecture, and adds novel components to enable efficient multilingual learning.
If you are interested in trying out the models yourself, some example boilerplate is available at the end o]]></description>
      <pubDate>Tue, 09 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/mmbert</guid>
    </item>
    <item>
      <title><![CDATA[MCP for Research: How to Connect AI to Research Tools]]></title>
      <link>https://huggingface.co/blog/mcp-for-research</link>
      <description><![CDATA[Back to Articles Research Discovery: Three Layers of Abstraction 1. Manual Research 2. Scripted Tools 3. MCP Integration Setup and Usage Quick Setup Learn More Academic research involves frequent research discovery: finding papers, code, related models and datasets. This typically means switching between platforms like arXiv, GitHub, and Hugging Face, manually piecing together connections.
The Model Context Protocol (MCP) is a standard that allows agentic models to communicate with external tools and data sources. For research discovery, this means AI can use research tools through natural language requests, automating platform switching and cross-referencing. Research Discovery: Three Layers of Abstraction Much like software development, research discovery can be framed in terms of layers of abstraction. 1. Manual Research At the lowest level of abstraction, researchers search manually and cross-reference by hand.
# Typical workflow:
1. Find paper on arXiv
2. Search GitHub for implementations
3. Check Hugging Face for models/datasets
4. Cross-reference authors and citations
5. Organize findings manually This manual approach becomes in]]></description>
      <pubDate>Mon, 18 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/mcp-for-research</guid>
    </item>
    <item>
      <title><![CDATA[Simple farce ou vrai signal d’alarme ? OpenClaw s’est invité de force chez 4 000 développeurs]]></title>
      <link>https://www.numerama.com/cyberguerre/2184985-simple-farce-ou-vrai-signal-dalarme-openclaw-sest-invite-de-force-chez-4-000-developpeurs.html</link>
      <description><![CDATA[Le 17 février 2026, l'assistant de code IA Cline a annoncé qu'une de ses mises à jour, publiée en son nom, avait en réalité été compromise par des hackers. Si cette version aurait pu intégrer des malwares ou causer de gros dégâts, elle a au contraire discrètement installé OpenClaw sur les machines infectées.]]></description>
      <pubDate>Fri, 20 Feb 2026 16:57:37 GMT</pubDate>
      <source>Numerama Tech</source>
      <category>ai</category>
      <guid>https://www.numerama.com/cyberguerre/2184985-simple-farce-ou-vrai-signal-dalarme-openclaw-sest-invite-de-force-chez-4-000-developpeurs.html</guid>
    </item>
    <item>
      <title><![CDATA[The creator economy’s ad revenue problem and India’s AI ambitions]]></title>
      <link>https://techcrunch.com/video/the-creator-economys-ad-revenue-problem-and-indias-ai-ambitions/</link>
      <description><![CDATA[The creator economy is evolving fast, and ad revenue alone isn’t cutting it anymore. YouTubers are launching product lines, acquiring startups, and building actual business empires. In fact, MrBeast’s company bought fintech startup Step, and his chocolate business is outearning his media arm. This isn’t just one creator’s strategy. For many, it’s the new playbook. On this episode of TechCrunch’s Equity podcast, hosts Kirsten Korosec, Anthony Ha, and Rebecca Bellan unpack how creators are diversifying beyond ads, […]]]></description>
      <pubDate>Fri, 20 Feb 2026 23:00:00 GMT</pubDate>
      <source>TechCrunch AI</source>
      <category>ai</category>
      <guid>https://techcrunch.com/video/the-creator-economys-ad-revenue-problem-and-indias-ai-ambitions/</guid>
    </item>
    <item>
      <title><![CDATA[Donkeys, Not Unicorns]]></title>
      <link>https://towardsdatascience.com/donkeys-not-unicorns-the-new-rules-of-commoditized-magic/</link>
      <description><![CDATA[The New Rules of Entrepreneurship in the Era of Commoditized Magic]]></description>
      <pubDate>Fri, 20 Feb 2026 18:21:56 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/donkeys-not-unicorns-the-new-rules-of-commoditized-magic/</guid>
    </item>
    <item>
      <title><![CDATA[AI’s promise to indie filmmakers: Faster, cheaper, lonelier]]></title>
      <link>https://techcrunch.com/2026/02/20/ais-promise-to-indie-filmmakers-faster-cheaper-lonelier/</link>
      <description><![CDATA[AI expands access to filmmaking for resource-constrained creators. But as efficiency becomes the industry’s north star, creativity risks being overwhelmed by a deluge of low-effort, AI-generated content.]]></description>
      <pubDate>Fri, 20 Feb 2026 15:30:00 GMT</pubDate>
      <source>TechCrunch AI</source>
      <category>ai</category>
      <guid>https://techcrunch.com/2026/02/20/ais-promise-to-indie-filmmakers-faster-cheaper-lonelier/</guid>
    </item>
    <item>
      <title><![CDATA[Derrière le rêve de l’école 100 % IA, un cauchemar de surveillance pour les élèves]]></title>
      <link>https://www.numerama.com/politique/2184361-derriere-le-reve-de-lecole-100-ia-un-cauchemar-de-surveillance-pour-les-eleves.html</link>
      <description><![CDATA[Derrière la promesse d'une éducation dopée à l'intelligence artificielle, le réseau scolaire américain Alpha School cache une réalité brutale : celle de cours incohérents, d’un plagiat industriel et d’une surveillance constante des élèves.]]></description>
      <pubDate>Fri, 20 Feb 2026 14:41:53 GMT</pubDate>
      <source>Numerama Tech</source>
      <category>ai</category>
      <guid>https://www.numerama.com/politique/2184361-derriere-le-reve-de-lecole-100-ia-un-cauchemar-de-surveillance-pour-les-eleves.html</guid>
    </item>
    <item>
      <title><![CDATA[Our First Proof submissions]]></title>
      <link>https://openai.com/index/first-proof-submissions</link>
      <description><![CDATA[We share our AI model’s proof attempts for the First Proof math challenge, testing research-grade reasoning on expert-level problems.]]></description>
      <pubDate>Fri, 20 Feb 2026 14:30:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/first-proof-submissions</guid>
    </item>
    <item>
      <title><![CDATA[Job titles of the future: Breast biomechanic]]></title>
      <link>https://www.technologyreview.com/2026/02/20/1132629/job-titles-future-breast-biomechanic/</link>
      <description><![CDATA[Twenty years ago, Joanna Wakefield-Scurr was having persistent pain in her breasts. Her doctor couldn’t diagnose the cause but said a good, supportive bra could help. A professor of biomechanics, Wakefield-Scurr thought she could do a little research and find a science-backed option. Two decades later, she’s still looking. Wakefield-Scurr now leads an 18-person team…]]></description>
      <pubDate>Fri, 20 Feb 2026 11:00:00 GMT</pubDate>
      <source>MIT Technology Review</source>
      <category>ai</category>
      <guid>https://www.technologyreview.com/2026/02/20/1132629/job-titles-future-breast-biomechanic/</guid>
    </item>
    <item>
      <title><![CDATA[GGML and llama.cpp join HF to ensure the long-term progress of Local AI]]></title>
      <link>https://huggingface.co/blog/ggml-joins-hf</link>
      <description><![CDATA[Back to Articles What will change for llama.cpp, the open source project and the community? Technical focus Our long term vision We are super happy to announce that GGML, creators of Llama.cpp, are joining HF in order to keep future AI open. Georgi Gerganov and team are joining HF with the goal of scaling and supporting the community behind ggml and llama.cpp as Local AI continues to make exponential progress in the coming years.
We've been working with Georgi and team for quite some time (we even have awesome core contributors to llama.cpp like Son and Alek in the team already) so this has been a very natural process.
llama.cpp is the fundamental building block for local inference, and transformers is the fundamental building block for model definition, so this is basically a match made in heaven. What will change for llama.cpp, the open source project and the community? Not much – Georgi and team still dedicate 100% of their time maintaining llama.cpp and have full autonomy and leadership on the technical directions and the community.
HF is providing the project with long-term sustainable resources, improving the chances of the project to grow and thrive. The project w]]></description>
      <pubDate>Fri, 20 Feb 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ggml-joins-hf</guid>
    </item>
    <item>
      <title><![CDATA[Code Smells: Essential Concepts For Data Scientists in the Age of AI Coding Agents]]></title>
      <link>https://towardsdatascience.com/the-missing-curriculum-essential-concepts-for-data-scientists-in-the-age-of-ai-coding-agents/</link>
      <description><![CDATA[AI can write the code, but you have to steer the ship. Master the knowledge to keep you relevant in the age of AI.]]></description>
      <pubDate>Thu, 19 Feb 2026 20:16:51 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/the-missing-curriculum-essential-concepts-for-data-scientists-in-the-age-of-ai-coding-agents/</guid>
    </item>
    <item>
      <title><![CDATA[Understanding the Chi-Square Test Beyond the Formula]]></title>
      <link>https://towardsdatascience.com/understanding-the-chi-square-test-beyond-the-formula/</link>
      <description><![CDATA[How categorical data becomes statistical evidence.]]></description>
      <pubDate>Thu, 19 Feb 2026 18:28:26 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/understanding-the-chi-square-test-beyond-the-formula/</guid>
    </item>
    <item>
      <title><![CDATA[AlpamayoR1: Large Causal Reasoning Models for Autonomous Driving]]></title>
      <link>https://towardsdatascience.com/alpamayor1-large-causal-reasoning-models-for-autonomous-driving/</link>
      <description><![CDATA[All you need to know about Chain of Causation reasoning and the current state of Autonomous Driving!]]></description>
      <pubDate>Thu, 19 Feb 2026 13:30:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/alpamayor1-large-causal-reasoning-models-for-autonomous-driving/</guid>
    </item>
    <item>
      <title><![CDATA[Perplexity renonce à la publicité pour préserver la confiance face à OpenAI]]></title>
      <link>https://siecledigital.fr/2026/02/19/perplexity-renonce-a-la-publicite-pour-preserver-la-confiance-face-a-openai/</link>
      <description><![CDATA[Alors qu’OpenAI commence à intégrer des s dans ChatGPT aux États-Unis, certains concurrents choisissent de se différencier. A l’heure où les modèles économiques des IA génératives cherchent encore leur équilibre, la question de la é devient un marqueur stratégique. Après l’annonce d’Anthropic ces derniers jours, c’est désormais Perplexity qui affiche clairement sa position : pas […]]]></description>
      <pubDate>Thu, 19 Feb 2026 10:32:32 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/19/perplexity-renonce-a-la-publicite-pour-preserver-la-confiance-face-a-openai/</guid>
    </item>
    <item>
      <title><![CDATA[Vous pouvez désormais créer de la musique avec l’IA de Google]]></title>
      <link>https://siecledigital.fr/2026/02/19/gemini-se-met-a-la-musique-avec-lyria-3/</link>
      <description><![CDATA[Après le texte, l’image et la vidéo, Google ajoute une nouvelle corde à l’arc de son assistant. Avec Lyria 3, son dernier modèle issu de Google DeepMind, Google Gemini peut désormais générer des morceaux de musique à partir d’une simple description. Une évolution qui confirme l’ambition de Google de transformer son chatbot en véritable studio […]]]></description>
      <pubDate>Thu, 19 Feb 2026 10:29:07 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/19/gemini-se-met-a-la-musique-avec-lyria-3/</guid>
    </item>
    <item>
      <title><![CDATA[Advancing independent research on AI alignment]]></title>
      <link>https://openai.com/index/advancing-independent-research-ai-alignment</link>
      <description><![CDATA[OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment research, strengthening global efforts to address AGI safety and security risks.]]></description>
      <pubDate>Thu, 19 Feb 2026 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/advancing-independent-research-ai-alignment</guid>
    </item>
    <item>
      <title><![CDATA[Introducing OpenAI for India]]></title>
      <link>https://openai.com/index/openai-for-india</link>
      <description><![CDATA[OpenAI for India expands AI access across the country—building local infrastructure, powering enterprises, and advancing workforce skills.]]></description>
      <pubDate>Wed, 18 Feb 2026 21:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/openai-for-india</guid>
    </item>
    <item>
      <title><![CDATA[Can AI Solve Failures in Your Supply Chain?]]></title>
      <link>https://towardsdatascience.com/can-ai-solve-failures-in-your-supply-chain/</link>
      <description><![CDATA[When your warehouse and transportation teams blame each other for late deliveries, who's right? We can ask an agent connected to the data settle the debate.]]></description>
      <pubDate>Wed, 18 Feb 2026 21:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/can-ai-solve-failures-in-your-supply-chain/</guid>
    </item>
    <item>
      <title><![CDATA[Building Cost-Efficient Agentic RAG on Long-Text Documents in SQL Tables]]></title>
      <link>https://towardsdatascience.com/building-cost-efficient-agentic-rag-on-long-text-documents-in-sql-tables/</link>
      <description><![CDATA[Designing a hybrid SQL + vector retrieval system without schema changes, data migration, or performance trade-offs]]></description>
      <pubDate>Wed, 18 Feb 2026 20:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/building-cost-efficient-agentic-rag-on-long-text-documents-in-sql-tables/</guid>
    </item>
    <item>
      <title><![CDATA[LinkedIn veut restaurer l’authenticité des échanges en sanctionnant les commentaires automatiques]]></title>
      <link>https://siecledigital.fr/2026/02/17/linkedin-serre-la-vis-contre-les-faux-commentaires/</link>
      <description><![CDATA[Alors que les créateurs de contenu et les entreprises rivalisent pour capter l’attention, l’authenticité est devenue l’un des principaux enjeux des réseaux sociaux comme LinkedIn. Malheureusement, certaines pratiques sont venues fausser les règles du jeu, comme les « engagement pods« , ces groupes coordonnés qui s’organisent pour gonfler artificiellement la portée de leurs publications. Face à la […]]]></description>
      <pubDate>Wed, 18 Feb 2026 10:22:12 GMT</pubDate>
      <source>Siecle Digital</source>
      <category>ai</category>
      <guid>https://siecledigital.fr/2026/02/17/linkedin-serre-la-vis-contre-les-faux-commentaires/</guid>
    </item>
    <item>
      <title><![CDATA[Advance Planning for AI Project Evaluation]]></title>
      <link>https://towardsdatascience.com/advance-planning-for-ai-project-evaluation/</link>
      <description><![CDATA[The work to do before the work begins]]></description>
      <pubDate>Wed, 18 Feb 2026 00:31:16 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/advance-planning-for-ai-project-evaluation/</guid>
    </item>
    <item>
      <title><![CDATA[Building a LangGraph Agent from Scratch]]></title>
      <link>https://towardsdatascience.com/building-a-langgraph-agent-from-scratch/</link>
      <description><![CDATA[Everything you need to know to get started]]></description>
      <pubDate>Tue, 17 Feb 2026 20:22:34 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/building-a-langgraph-agent-from-scratch/</guid>
    </item>
    <item>
      <title><![CDATA[Iron Triangles: Powerful Tools for Analyzing Trade-Offs in AI Product Development]]></title>
      <link>https://towardsdatascience.com/iron-triangles-powerful-tools-for-analyzing-trade-offs-in-ai-product-development/</link>
      <description><![CDATA[Conceptual overview and practical guidance]]></description>
      <pubDate>Tue, 17 Feb 2026 19:49:40 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/iron-triangles-powerful-tools-for-analyzing-trade-offs-in-ai-product-development/</guid>
    </item>
    <item>
      <title><![CDATA[The Strangest Bottleneck in Modern LLMs]]></title>
      <link>https://towardsdatascience.com/the-strangest-bottleneck-in-modern-llms/</link>
      <description><![CDATA[Why insanely fast GPUs still can’t make LLMs feel instant]]></description>
      <pubDate>Mon, 16 Feb 2026 11:14:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/the-strangest-bottleneck-in-modern-llms/</guid>
    </item>
    <item>
      <title><![CDATA[The Evolving Role of the ML Engineer]]></title>
      <link>https://towardsdatascience.com/the-evolving-role-of-the-ml-engineer/</link>
      <description><![CDATA[Stephanie Kirmer on the $200 billion investment bubble, how AI companies can rebuild trust, and how her day-to-day work changed with the rise of LLMs.]]></description>
      <pubDate>Fri, 13 Feb 2026 15:00:00 GMT</pubDate>
      <source>Towards Data Science</source>
      <category>ai</category>
      <guid>https://towardsdatascience.com/the-evolving-role-of-the-ml-engineer/</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Lockdown Mode and Elevated Risk labels in ChatGPT]]></title>
      <link>https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt</link>
      <description><![CDATA[Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.]]></description>
      <pubDate>Fri, 13 Feb 2026 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt</guid>
    </item>
    <item>
      <title><![CDATA[Introducing GPT-5.3-Codex-Spark]]></title>
      <link>https://openai.com/index/introducing-gpt-5-3-codex-spark</link>
      <description><![CDATA[Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.]]></description>
      <pubDate>Thu, 12 Feb 2026 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/introducing-gpt-5-3-codex-spark</guid>
    </item>
    <item>
      <title><![CDATA[Introducing OpenAI Frontier]]></title>
      <link>https://openai.com/index/introducing-openai-frontier</link>
      <description><![CDATA[OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context, onboarding, permissions, and governance.]]></description>
      <pubDate>Thu, 05 Feb 2026 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/introducing-openai-frontier</guid>
    </item>
    <item>
      <title><![CDATA[Community Evals: Because we're done trusting black-box leaderboards over the community]]></title>
      <link>https://huggingface.co/blog/community-evals</link>
      <description><![CDATA[Back to Articles Evaluation is broken What We're Shipping Why This Matters Get Started TL;DR: Benchmark datasets on Hugging Face can now host leaderboards. Models store their own eval scores. Everything links together. The community can submit results via PR. Verified badges prove that the results can be reproduced. Evaluation is broken Let's be real about where we are with evals in 2026. MMLU is saturated above 91%. GSM8K hit 94%+. HumanEval is conquered. Yet some models that ace benchmarks still can't reliably browse the web, write production code, or handle multi-step tasks without hallucinating, based on usage reports. There is a clear gap between benchmark scores and real-world performance.
Furthermore, there is another gap within reported benchmark scores. Multiple sources report different results. From Model Cards, to papers, to evaluation platforms, there is no alignment in reported scores. The result is that the community lacks a single source of truth. What We're Shipping Decentralized and transparent evaluation reporting.
We are going to take evaluations on the Hugging Face Hub in a new direction by decentralizing reporting]]></description>
      <pubDate>Wed, 04 Feb 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/community-evals</guid>
    </item>
    <item>
      <title><![CDATA[Inside OpenAI’s in-house data agent]]></title>
      <link>https://openai.com/index/inside-our-in-house-data-agent</link>
      <description><![CDATA[How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes.]]></description>
      <pubDate>Thu, 29 Jan 2026 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/inside-our-in-house-data-agent</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Daggr: Chain apps programmatically, inspect visually]]></title>
      <link>https://huggingface.co/blog/daggr</link>
      <description><![CDATA[Back to Articles Table of Contents Background Getting Started Node Types Sharing Your Workflows End-to-End Example with Different Nodes Next Steps TL;DR: Daggr is a new, open-source Python library for building AI workflows that connect Gradio apps, ML models, and custom functions. It automatically generates a visual canvas where you can inspect intermediate outputs, rerun individual steps, and manage state for complex pipelines, all in a few lines of Python code! Table of Contents Background
Getting Started
Sharing Your Workflows
End-to-End Example with Different Nodes
Next Steps Background If you've built AI applications that combine multiple models or processing steps, you know the pain: chaining API calls, debugging pipelines, and losing track of intermediate results. When something goes wrong in step 5 of a 10-step workflow, you often have to re-run everything just to see what happened.
Most developers either build fragile scripts that are hard to debug or turn to heavy orchestration platforms designed for production pipelines—not rapid experimentation.
We've been working on Daggr to solve p]]></description>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/daggr</guid>
    </item>
    <item>
      <title><![CDATA[EMEA Youth &amp; Wellbeing Grant]]></title>
      <link>https://openai.com/index/emea-youth-and-wellbeing-grant</link>
      <description><![CDATA[Apply for the EMEA Youth &amp; Wellbeing Grant, a €500,000 program funding NGOs and researchers advancing youth safety and wellbeing in the age of AI.]]></description>
      <pubDate>Wed, 28 Jan 2026 01:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/emea-youth-and-wellbeing-grant</guid>
    </item>
    <item>
      <title><![CDATA[The next chapter for AI in the EU]]></title>
      <link>https://openai.com/index/the-next-chapter-for-ai-in-the-eu</link>
      <description><![CDATA[OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe.]]></description>
      <pubDate>Wed, 28 Jan 2026 01:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/the-next-chapter-for-ai-in-the-eu</guid>
    </item>
    <item>
      <title><![CDATA[Keeping your data safe when an AI agent clicks a link]]></title>
      <link>https://openai.com/index/ai-agent-link-safety</link>
      <description><![CDATA[Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and prompt injection with built-in safeguards.]]></description>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/ai-agent-link-safety</guid>
    </item>
    <item>
      <title><![CDATA[PVH reimagines the future of fashion with OpenAI]]></title>
      <link>https://openai.com/index/pvh-future-of-fashion</link>
      <description><![CDATA[PVH Corp., parent company of Calvin Klein and Tommy Hilfiger, is adopting ChatGPT Enterprise to bring AI into fashion design, supply chain, and consumer engagement.]]></description>
      <pubDate>Tue, 27 Jan 2026 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/pvh-future-of-fashion</guid>
    </item>
    <item>
      <title><![CDATA[Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective]]></title>
      <link>https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl</link>
      <description><![CDATA[Back to Articles Agentic reinforcement learning (RL) extends traditional LLM training by optimizing not just a single-turn response, but an entire decision-making process learned through direct interaction with an environment during training. Unlike traditional single-turn reinforcement learning or offline preference-based methods that rely on static datasets, agentic RL trains policies by actively collecting on-policy data as the agent plans actions, invokes tools, observes outcomes, and adapts its behavior over multi-step trajectories in either simulated or real environments. This interaction-driven optimization assigns credit across long-horizon decisions, where intermediate choices such as query reformulation, tool selection, and execution order directly influence downstream success. Training follows an iterative closed loop in which the agent interacts with the environment to collect rollout trajectories, computes rewards over these trajectories, updates the policy based on observed outcomes, and then uses the updated policy to drive the next round of interaction and data collection such as GRPO or PPO algorithms..
LinkedIn is an AI-first company that's built agents to help professionals be more successful. In this setting, models must reason over incomplete]]></description>
      <pubDate>Tue, 27 Jan 2026 01:53:15 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl</guid>
    </item>
    <item>
      <title><![CDATA[Introducing Prism]]></title>
      <link>https://openai.com/index/introducing-prism</link>
      <description><![CDATA[Prism is a free LaTeX-native workspace with GPT-5.2 built in, helping researchers write, collaborate, and reason in one place.]]></description>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/introducing-prism</guid>
    </item>
    <item>
      <title><![CDATA[Unrolling the Codex agent loop]]></title>
      <link>https://openai.com/index/unrolling-the-codex-agent-loop</link>
      <description><![CDATA[A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API.]]></description>
      <pubDate>Fri, 23 Jan 2026 12:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/unrolling-the-codex-agent-loop</guid>
    </item>
    <item>
      <title><![CDATA[Inside Praktika's conversational approach to language learning]]></title>
      <link>https://openai.com/index/praktika</link>
      <description><![CDATA[How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and help learners achieve real-world language fluency]]></description>
      <pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/praktika</guid>
    </item>
    <item>
      <title><![CDATA[Cisco and OpenAI redefine enterprise engineering with AI agents]]></title>
      <link>https://openai.com/index/cisco</link>
      <description><![CDATA[Cisco and OpenAI redefine enterprise engineering with Codex, an AI software agent embedded in workflows to speed builds, automate defect fixes, and enable AI-native development.]]></description>
      <pubDate>Tue, 20 Jan 2026 11:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/cisco</guid>
    </item>
    <item>
      <title><![CDATA[ServiceNow powers actionable enterprise AI with OpenAI]]></title>
      <link>https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai</link>
      <description><![CDATA[ServiceNow expands access to OpenAI frontier models to power AI-driven enterprise workflows, summarization, search, and voice across the ServiceNow Platform.]]></description>
      <pubDate>Tue, 20 Jan 2026 05:45:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai</guid>
    </item>
    <item>
      <title><![CDATA[AI for self empowerment]]></title>
      <link>https://openai.com/index/ai-for-self-empowerment</link>
      <description><![CDATA[How AI can expand human agency by closing the capability overhang—helping people, businesses, and countries unlock real productivity, growth, and opportunity.]]></description>
      <pubDate>Sun, 18 Jan 2026 12:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/ai-for-self-empowerment</guid>
    </item>
    <item>
      <title><![CDATA[Open Responses: What you need to know]]></title>
      <link>https://huggingface.co/blog/open-responses</link>
      <description><![CDATA[Back to Articles What is Open Responses? What do we need to know to build with Open Responses? Client Requests to Open Responses Changes for Inference Clients and Providers Open Responses for Routing Tools Sub Agent Loops Next Steps Open Responses is a new and open inference standard. Initiated by OpenAI, built by the open source AI community, and backed by the Hugging Face ecosystem, Open Responses is based on the Responses API and is designed for the future of Agents. In this blog post, we’ll look at how Open Responses works and why the open source community should use Open Responses.
The era of the chatbot is long gone, and agents dominate inference workloads. Developers are shifting toward autonomous systems that reason, plan, and act over long-time horizons. Despite this shift, much of the ecosystem still uses the Chat Completion format, which was designed for turn-based conversations and falls short for agentic use cases. The Responses format was designed to address these limitations, but it is closed and not as widely adopted. The Chat Completion format is still the de facto standard despite the alt]]></description>
      <pubDate>Thu, 15 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/open-responses</guid>
    </item>
    <item>
      <title><![CDATA[Zenken boosts a lean sales team with ChatGPT Enterprise]]></title>
      <link>https://openai.com/index/zenken</link>
      <description><![CDATA[By rolling out ChatGPT Enterprise company-wide, Zenken has boosted sales performance, cut preparation time, and increased proposal success rates. AI-supported workflows are helping a lean team deliver more personalized, effective customer engagement.]]></description>
      <pubDate>Tue, 13 Jan 2026 16:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/zenken</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI and SoftBank Group partner with SB Energy]]></title>
      <link>https://openai.com/index/stargate-sb-energy-partnership</link>
      <description><![CDATA[OpenAI and SoftBank Group partner with SB Energy to develop multi-gigawatt AI data center campuses, including a 1.2 GW Texas facility supporting the Stargate initiative.]]></description>
      <pubDate>Fri, 09 Jan 2026 11:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/stargate-sb-energy-partnership</guid>
    </item>
    <item>
      <title><![CDATA[Datadog uses Codex for system-level code review]]></title>
      <link>https://openai.com/index/datadog</link>
      <description><![CDATA[OpenAI and Datadog brand graphic with the OpenAI wordmark on the left, the Datadog logo on the right, and a central abstract brown fur-like texture panel on a white background.]]></description>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/datadog</guid>
    </item>
    <item>
      <title><![CDATA[Netomi’s lessons for scaling agentic systems into the enterprise]]></title>
      <link>https://openai.com/index/netomi</link>
      <description><![CDATA[How Netomi scales enterprise AI agents using GPT-4.1 and GPT-5.2—combining concurrency, governance, and multi-step reasoning for reliable production workflows.]]></description>
      <pubDate>Thu, 08 Jan 2026 13:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/netomi</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI for Healthcare]]></title>
      <link>https://openai.com/index/openai-for-healthcare</link>
      <description><![CDATA[OpenAI for Healthcare enables secure, enterprise-grade AI that supports HIPAA compliance—reducing administrative burden and supporting clinical workflows.]]></description>
      <pubDate>Thu, 08 Jan 2026 12:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/openai-for-healthcare</guid>
    </item>
    <item>
      <title><![CDATA[Introducing ChatGPT Health]]></title>
      <link>https://openai.com/index/introducing-chatgpt-health</link>
      <description><![CDATA[ChatGPT Health is a dedicated experience that securely connects your health data and apps, with privacy protections and a physician-informed design.]]></description>
      <pubDate>Wed, 07 Jan 2026 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/introducing-chatgpt-health</guid>
    </item>
    <item>
      <title><![CDATA[NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI]]></title>
      <link>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</link>
      <description><![CDATA[Back to Articles NVIDIA Cosmos Reason 2: Reasoning Vision Language Model for Physical AI Key Highlights Popular Use Cases Other Models From The Cosmos Family: Cosmos Predict 2.5 Resources NVIDIA today released Cosmos Reason 2, the latest advancement in open, reasoning vision language models for physical AI. Cosmos Reason 2 surpasses its previous version in accuracy and tops the Physical AI Bench and Physical Reasoning leaderboards as the #1 open model for visual understanding. NVIDIA Cosmos Reason 2: Reasoning Vision Language Model for Physical AI Since their introduction, vision-language models have rapidly improved at tasks like object and pattern recognition in images. But they still struggle with tasks humans find natural, like planning several steps ahead, dealing with uncertainty or adapting to new situations. Cosmos Reason is designed to close this gap by giving robots and AI agents stronger common sense and reasoning to solve complex problems step by step.
Cosmos Reason 2 is a state-of-the-art, open reasoning vision-language model (VLM) that enables robots and AI agents to see, understand, plan, and act in the physical world like humans. It uses]]></description>
      <pubDate>Mon, 05 Jan 2026 22:56:51 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</guid>
    </item>
    <item>
      <title><![CDATA[NVIDIA brings agents to life with DGX Spark and Reachy Mini]]></title>
      <link>https://huggingface.co/blog/nvidia-reachy-mini</link>
      <description><![CDATA[Back to Articles Ingredients Giving agentic powers to Reachy Building the agent Step 0: Set up and get access to models and services Step 1: Build a chat interface Step 2: Add NeMo Agent Toolkit’s built-in ReAct agent for tool calling Step 3: Add a router to direct queries to different models Step 4: Add a Pipecat bot for real-time voice + vision Step 5: Hook everything up to Reachy (hardware or simulation) Run the full system Try these example prompts Where to go next Today at CES 2026, NVIDIA unveiled a world of new open models to enable the future of agents, online and in the real world. From the recently released NVIDIA Nemotron reasoning LLMs to the new NVIDIA Isaac GR00T N1.6 open reasoning VLA and NVIDIA Cosmos world foundation models, all the building blocks are here today for AI Builders to build their own agents.
But what if you could bring your own agent to life, right at your desk? An AI buddy that can be useful to you and process your data privately?
In the CES keynote today, Jensen Huang showed us how we can do exactly that, using the pr]]></description>
      <pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/nvidia-reachy-mini</guid>
    </item>
    <item>
      <title><![CDATA[Continuously hardening ChatGPT Atlas against prompt injection]]></title>
      <link>https://openai.com/index/hardening-atlas-against-prompt-injection</link>
      <description><![CDATA[OpenAI is strengthening ChatGPT Atlas against prompt injection attacks using automated red teaming trained with reinforcement learning. This proactive discover-and-patch loop helps identify novel exploits early and harden the browser agent’s defenses as AI becomes more agentic.]]></description>
      <pubDate>Mon, 22 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/hardening-atlas-against-prompt-injection</guid>
    </item>
    <item>
      <title><![CDATA[AI literacy resources for teens and parents]]></title>
      <link>https://openai.com/index/ai-literacy-resources-for-teens-and-parents</link>
      <description><![CDATA[OpenAI shares new AI literacy resources to help teens and parents use ChatGPT thoughtfully, safely, and with confidence. The guides include expert-vetted tips for responsible use, critical thinking, healthy boundaries, and supporting teens through emotional or sensitive topics.]]></description>
      <pubDate>Thu, 18 Dec 2025 11:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/ai-literacy-resources-for-teens-and-parents</guid>
    </item>
    <item>
      <title><![CDATA[Updating our Model Spec with teen protections]]></title>
      <link>https://openai.com/index/updating-model-spec-with-teen-protections</link>
      <description><![CDATA[OpenAI is updating its Model Spec with new Under-18 Principles that define how ChatGPT should support teens with safe, age-appropriate guidance grounded in developmental science. The update strengthens guardrails, clarifies expected model behavior in higher-risk situations, and builds on our broader work to improve teen safety across ChatGPT.]]></description>
      <pubDate>Thu, 18 Dec 2025 11:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/updating-model-spec-with-teen-protections</guid>
    </item>
    <item>
      <title><![CDATA[Introducing OpenAI Academy for News Organizations]]></title>
      <link>https://openai.com/index/openai-academy-for-news-organizations</link>
      <description><![CDATA[OpenAI is launching the OpenAI Academy for News Organizations, a new learning hub built with the American Journalism Project and The Lenfest Institute to help newsrooms use AI effectively. The Academy offers training, practical use cases, and responsible-use guidance to support journalists, editors, and publishers as they adopt AI in their reporting and operations.]]></description>
      <pubDate>Wed, 17 Dec 2025 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/openai-academy-for-news-organizations</guid>
    </item>
    <item>
      <title><![CDATA[Measuring AI’s capability to accelerate biological research]]></title>
      <link>https://openai.com/index/accelerating-biological-research-in-the-wet-lab</link>
      <description><![CDATA[OpenAI introduces a real-world evaluation framework to measure how AI can accelerate biological research in the wet lab. Using GPT-5 to optimize a molecular cloning protocol, the work explores both the promise and risks of AI-assisted experimentation.]]></description>
      <pubDate>Tue, 16 Dec 2025 08:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/accelerating-biological-research-in-the-wet-lab</guid>
    </item>
    <item>
      <title><![CDATA[BNY builds “AI for everyone, everywhere” with OpenAI]]></title>
      <link>https://openai.com/index/bny</link>
      <description><![CDATA[BNY is using OpenAI technology to expand AI adoption enterprise-wide. Through its Eliza platform, 20,000+ employees are building AI agents that enhance efficiency and improve client outcomes.]]></description>
      <pubDate>Fri, 12 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/bny</guid>
    </item>
    <item>
      <title><![CDATA[BBVA and OpenAI collaborate to transform global banking]]></title>
      <link>https://openai.com/index/bbva-collaboration-expansion</link>
      <description><![CDATA[BBVA is expanding its work with OpenAI through a multi-year AI transformation program, rolling out ChatGPT Enterprise to all 120,000 employees. Together, the companies will develop AI solutions that enhance customer interactions, streamline operations, and help build an AI-native banking experience.]]></description>
      <pubDate>Fri, 12 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/bbva-collaboration-expansion</guid>
    </item>
    <item>
      <title><![CDATA[The Walt Disney Company and OpenAI reach landmark agreement to bring beloved characters to Sora]]></title>
      <link>https://openai.com/index/disney-sora-agreement</link>
      <description><![CDATA[Disney and OpenAI have reached an agreement to bring more than 200 Disney, Marvel, Pixar and Star Wars characters to Sora for fan-inspired short videos. The agreement emphasizes responsible AI in entertainment and includes Disney’s company-wide use of ChatGPT Enterprise and the OpenAI API.]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/disney-sora-agreement</guid>
    </item>
    <item>
      <title><![CDATA[Ten years]]></title>
      <link>https://openai.com/index/ten-years</link>
      <description><![CDATA[OpenAI reflects on ten years of progress, from early research breakthroughs to widely used AI systems that reshaped what’s possible. We share lessons from the past decade and why we remain optimistic about building AGI that benefits all of humanity.]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/ten-years</guid>
    </item>
    <item>
      <title><![CDATA[Increasing revenue 300% by bringing AI to SMBs]]></title>
      <link>https://openai.com/index/podium</link>
      <description><![CDATA[Discover how Podium used OpenAI’s GPT-5 to build “Jerry,” an AI teammate driving 300% growth and transforming how Main Street businesses serve customers.]]></description>
      <pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/podium</guid>
    </item>
    <item>
      <title><![CDATA[Building AI fluency at scale with ChatGPT Enterprise]]></title>
      <link>https://openai.com/index/commonwealth-bank-of-australia</link>
      <description><![CDATA[Commonwealth Bank of Australia partners with OpenAI to roll out ChatGPT Enterprise to 50,000 employees, building AI fluency at scale to improve customer service and fraud response.]]></description>
      <pubDate>Tue, 09 Dec 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/commonwealth-bank-of-australia</guid>
    </item>
    <item>
      <title><![CDATA[Instacart and OpenAI partner on AI shopping experiences]]></title>
      <link>https://openai.com/index/instacart-partnership</link>
      <description><![CDATA[OpenAI and Instacart are deepening their longstanding partnership by bringing the first fully integrated grocery shopping and Instant Checkout payment app to ChatGPT.]]></description>
      <pubDate>Mon, 08 Dec 2025 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/instacart-partnership</guid>
    </item>
    <item>
      <title><![CDATA[Introducing OpenAI for Australia]]></title>
      <link>https://openai.com/global-affairs/openai-for-australia</link>
      <description><![CDATA[OpenAI is launching OpenAI for Australia to build sovereign AI infrastructure, upskill more than 1.5 million workers, and accelerate innovation across the country’s growing AI ecosystem.]]></description>
      <pubDate>Thu, 04 Dec 2025 19:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/global-affairs/openai-for-australia</guid>
    </item>
    <item>
      <title><![CDATA[DeepMath: A lightweight math reasoning Agent with smolagents]]></title>
      <link>https://huggingface.co/blog/intel-deepmath</link>
      <description><![CDATA[Back to Articles Why DeepMath? How It Works Training with GRPO Evaluation Why It Matters Conclusion Try It Yourself Citation Limitations &amp; Future Work References By Intel AI Software Group
DeepMath is an aligned math reasoning agent built on Qwen3-4B Thinking and fine-tuned with GRPO (Group Relative Policy Optimization). Instead of verbose text, the model emits tiny Python snippets for intermediate steps, runs them in a secure sandbox, and folds the results back into its reasoning, reducing errors and output length. The agent is implemented using the smolagents library.
We evaluate DeepMath on four math datasets: MATH500, AIME, HMMT, and HLE, and show that: The math agent alone reduces output lengths by up to 66%, while often improving accuracy. GRPO training improves the agent performance even further, in almost all benchmarks. Code and evaluation scripts: https://github.com/IntelLabs/DeepMath Model: https://huggingface.co/Intel/deepmath-v1 Why DeepMath? Large language models (LLMs) have advanced reasoning capabilities, but mathematical problem-solving remains challenging; chai]]></description>
      <pubDate>Thu, 04 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/intel-deepmath</guid>
    </item>
    <item>
      <title><![CDATA[We Got Claude to Fine-Tune an Open Source LLM]]></title>
      <link>https://huggingface.co/blog/hf-skills-training</link>
      <description><![CDATA[We Got Claude to Fine-Tune an Open Source LLM]]></description>
      <pubDate>Thu, 04 Dec 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/hf-skills-training</guid>
    </item>
    <item>
      <title><![CDATA[How confessions can keep language models honest]]></title>
      <link>https://openai.com/index/how-confessions-can-keep-language-models-honest</link>
      <description><![CDATA[OpenAI researchers are testing “confessions,” a method that trains models to admit when they make mistakes or act undesirably, helping improve AI honesty, transparency, and trust in model outputs.]]></description>
      <pubDate>Wed, 03 Dec 2025 10:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/how-confessions-can-keep-language-models-honest</guid>
    </item>
    <item>
      <title><![CDATA[Announcing the initial People-First AI Fund grantees]]></title>
      <link>https://openai.com/index/people-first-ai-fund-grantees</link>
      <description><![CDATA[The OpenAI Foundation announces the initial recipients of the People-First AI Fund, awarding $40.5M in unrestricted grants to 208 nonprofits supporting community innovation and opportunity.]]></description>
      <pubDate>Wed, 03 Dec 2025 08:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/people-first-ai-fund-grantees</guid>
    </item>
    <item>
      <title><![CDATA[Inside Mirakl's agentic commerce vision]]></title>
      <link>https://openai.com/index/mirakl</link>
      <description><![CDATA[Mirakl is redefining commerce through AI agents and ChatGPT Enterprise—achieving faster documentation, smarter customer support, and building toward agent-native commerce with Mirakl Nexus.]]></description>
      <pubDate>Mon, 01 Dec 2025 22:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/mirakl</guid>
    </item>
    <item>
      <title><![CDATA[Funding grants for new research into AI and mental health]]></title>
      <link>https://openai.com/index/ai-mental-health-research-grants</link>
      <description><![CDATA[OpenAI is awarding up to $2 million in grants for research at the intersection of AI and mental health. The program supports projects that study real-world risks, benefits, and applications to improve safety and well-being.]]></description>
      <pubDate>Mon, 01 Dec 2025 12:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/ai-mental-health-research-grants</guid>
    </item>
    <item>
      <title><![CDATA[Building Deep Research: How we Achieved State of the Art]]></title>
      <link>https://huggingface.co/blog/Tavily/tavily-deep-research</link>
      <description><![CDATA[Back to Articles Building for the Future Agent Harness Models Tools Takeaways Context Engineering — An Exercise in Curation Context-Managed Web Retrieval Modeling the Human-Web Interaction Doing More with Less Productionizing Agents — an Ongoing Challenge Engineering with Non-Determinism Optimal Tooling — Less is More Evals Research agents are rapidly becoming one of the most important applications of AI. Research is a foundational knowledge-work task: collecting, reading, and synthesizing information underpins everything from writing and decision-making to coding itself. Yet human-driven research is constrained by memory, reading speed, and time. AI research agents, by contrast, can process vast amounts of information, synthesize insights instantly, and scale effortlessly. Because of this, research agents are emerging as a top use case for AI today and will soon become a core subcomponent of broader agentic workflows across content generation, coding, sales, and more. In this post, we share the tech]]></description>
      <pubDate>Mon, 24 Nov 2025 17:40:14 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Tavily/tavily-deep-research</guid>
    </item>
    <item>
      <title><![CDATA[Introducing shopping research in ChatGPT]]></title>
      <link>https://openai.com/index/chatgpt-shopping-research</link>
      <description><![CDATA[Shopping research in ChatGPT helps you explore, compare, and discover products with personalized buyer’s guides that simplify decision-making]]></description>
      <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/chatgpt-shopping-research</guid>
    </item>
    <item>
      <title><![CDATA[Open ASR Leaderboard: Trends and Insights with New Multilingual &amp; Long-Form Tracks]]></title>
      <link>https://huggingface.co/blog/open-asr-leaderboard</link>
      <description><![CDATA[Back to Articles 1. Conformer encoder LLM decoder tops the charts 2. Speed–accuracy tradeoffs 3. Multilingual 4. Long-form transcription is a different game While everyone (and their grandma ) is spinning up new ASR models, picking the right one for your use case can feel more overwhelming than choosing your next Netflix show. As of 21 Nov 2025, there are 150 Audio-Text-to-Text and 27K ASR models on the Hub Most benchmarks focus on short-form English transcription (&lt;30s), and overlook other important tasks, such as (1) multilingual performance and (2) model throughput, which can a be deciding factor for long-form audio like meetings and podcasts.
Over the past two years, the Open ASR Leaderboard has become a standard for comparing open and closed-source models on both accuracy and efficiency. Recently, multilingual and long-form transcription tracks have been added to the leaderboard TL;DR - Open ASR Leaderboard New preprint on ASR trends from the leaderboard: https://hf.co/papers/2510.06961 Best accuracy: Conformer encoder + LLM decoders (open-source ftw ) Fastest: CTC / TDT decoders Multilingual: Comes at the cost of single-language performance Long-f]]></description>
      <pubDate>Fri, 21 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/open-asr-leaderboard</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI and Foxconn collaborate to strengthen U.S. manufacturing across the AI supply chain]]></title>
      <link>https://openai.com/index/openai-and-foxconn-collaborate</link>
      <description><![CDATA[OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.]]></description>
      <pubDate>Thu, 20 Nov 2025 14:50:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/openai-and-foxconn-collaborate</guid>
    </item>
    <item>
      <title><![CDATA[Helping 1,000 small businesses build with AI]]></title>
      <link>https://openai.com/index/small-business-ai-jam</link>
      <description><![CDATA[OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.]]></description>
      <pubDate>Thu, 20 Nov 2025 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/small-business-ai-jam</guid>
    </item>
    <item>
      <title><![CDATA[Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms]]></title>
      <link>https://huggingface.co/blog/anylanguagemodel</link>
      <description><![CDATA[Back to Articles The Solution Why Foundation Models as the Base API Package Traits: Include Only What You Need Image Support (and API Design Trade-offs) Try It Out: chat-ui-swift What's Next Get Involved Links LLMs have become essential tools for building software.
But for Apple developers, integrating them remains unnecessarily painful.
Developers building AI-powered apps typically take a hybrid approach,
adopting some combination of: Local models using Core ML or MLX for privacy and offline capability
Cloud providers like OpenAI or Anthropic for frontier capabilities
Apple's Foundation Models as a system-level fallback Each comes with different APIs, different requirements, different integration patterns.
It's a lot, and it adds up quickly.
When I interviewed developers about building AI-powered apps,
friction with model integration came up immediately.
One developer put it bluntly: I thought I'd quickly use the demo for a test and maybe a quick and dirty build
but instead wasted so much time.
Drove me nuts. The cost to experiment is high,
which discourages developers from discovering that
local, open-source models might actually work great for their use case.
Today w]]></description>
      <pubDate>Thu, 20 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/anylanguagemodel</guid>
    </item>
    <item>
      <title><![CDATA[How evals drive the next chapter in AI for businesses]]></title>
      <link>https://openai.com/index/evals-drive-next-chapter-of-ai</link>
      <description><![CDATA[Learn how evals help businesses define, measure, and improve AI performance—reducing risk, boosting productivity, and driving strategic advantage.]]></description>
      <pubDate>Wed, 19 Nov 2025 11:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/evals-drive-next-chapter-of-ai</guid>
    </item>
    <item>
      <title><![CDATA[OpenAI and Target team up on new AI-powered experiences]]></title>
      <link>https://openai.com/index/target-partnership</link>
      <description><![CDATA[OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.]]></description>
      <pubDate>Wed, 19 Nov 2025 06:00:00 GMT</pubDate>
      <source>OpenAI Blog</source>
      <category>ai</category>
      <guid>https://openai.com/index/target-partnership</guid>
    </item>
    <item>
      <title><![CDATA[Easily Build and Share ROCm Kernels with Hugging Face]]></title>
      <link>https://huggingface.co/blog/build-rocm-kernels</link>
      <description><![CDATA[Back to Articles Intoduction Build Steps About the kernel Step 1: Project Structure Step 2: Configuration Files Setup Step 3: Building the Kernel Step 4: Uploading the kernel to the Hub Step 5: Let's use it :) Conclusion Related Libraries &amp; Hub Intoduction Custom kernels are the backbone of high-performance deep learning, enabling GPU operations tailored precisely to your workload; whether that’s image processing, tensor transformations, or other compute-heavy tasks. But compiling these kernels for the right architectures, wiring all the build flags, and integrating them cleanly into PyTorch extensions can quickly become a mess of CMake/Nix, compiler errors, and ABI issues, which is not fun. Hugging Face’s kernels library makes it easy to build (with kernel-builder) and share these kernels with the kernels-community, with support for multiple GPU and accelerator backends, including CUDA, ROCm, Metal, and XPU. This ensures your kernels are fast, portable, and seamlessly integrated with PyTorch.
In this guide, we focus exclusively on ROCm-compatible k]]></description>
      <pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/build-rocm-kernels</guid>
    </item>
    <item>
      <title><![CDATA[Building for an Open Future - our new partnership with Google Cloud]]></title>
      <link>https://huggingface.co/blog/google-cloud</link>
      <description><![CDATA[Back to Articles A Partnership for Google Cloud customers The Gateway to Open Models - A Fast Lane for Google Cloud Customers A partnership for Hugging Face customers Building the open future of AI together Today, we are happy to announce a new and deeper partnership with Google Cloud, to enable companies to build their own AI with open models.
“Google has made some of the most impactful contributions to open AI, from the OG transformer to the Gemma models. I believe in a future where all companies will build and customize their own AI. With this new strategic partnership, we’re making it easy to do on Google Cloud.” says Jeff Boudier, at Hugging Face.
“Hugging Face has been the driving force enabling companies large and small all over the world to access, use and customize now more than 2 million open models, and we’ve been proud to contribute over 1,000 of our models to the community”, says Ryan J. Salva, Senior Director of Product Management at Google Cloud. “Together we will make Google Cloud the best place to build with open models.” A Partnership for Google Cloud customers Google Cloud customers use open models from Hugging Face in many of its leading AI services. In Vertex AI, the most popular open models are]]></description>
      <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/google-cloud</guid>
    </item>
    <item>
      <title><![CDATA[Aligning to What? Rethinking Agent Generalization in MiniMax M2]]></title>
      <link>https://huggingface.co/blog/MiniMax-AI/aligning-to-what</link>
      <description><![CDATA[Back to Articles The Real Agent Alignment Problem: Benchmarks or Reality? The Need for Interleaved Thinking True Generalization is About Perturbation What's Next? Getting Involved It's been fantastic to see the community dive into our new MiniMax M2, with many highlighting its impressive skills in complex agentic tasks. This is particularly exciting for me, as my work was centered on the agent alignment part of its post-training. In this post, I'd like to share some of the key insights and lessons we learned during that process. The Real Agent Alignment Problem: Benchmarks or Reality? If you've worked with LLM Agents, you've felt this pain: the same model can feel brilliant in one framework and useless in another. An agent might crush a tool-use leaderboard but fail spectacularly at a simple, real-world task. This gap between benchmark performance and practical usability is one of the biggest challenges in the field.
When we designed M2, we knew we had to tackle this problem head-on. This led us to two core, and sometimes conflicting, objectives: Excel on Open-Source Benchmarks. Benchmarks are essential for measuring "pure" capabilities. A benchmark like BrowseComp, for instance, tests for sophisticated search]]></description>
      <pubDate>Thu, 30 Oct 2025 10:03:45 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/MiniMax-AI/aligning-to-what</guid>
    </item>
    <item>
      <title><![CDATA[On the Shifting Global Compute Landscape]]></title>
      <link>https://huggingface.co/blog/huggingface/shifting-compute-landscape</link>
      <description><![CDATA[Back to Articles Summary The State of Global Compute The Beginning of a Rewiring The Reaction: Powering Chinese AI How China’s Compute Landscape Catalyzed the Cambrian Explosion of Open Models Advances in Compute-Constrained Environments Pushing the Technical Frontier The Aftermath: Hardware, Software and Soft Power From Sufficient to Demanded Domestic Synergy A New Software Landscape Looking Ahead Acknowledgements Appendix: A Timeline of Chip Usage and Controls Summary The status quo of AI chip usage, that was once almost entirely U.S.-based, is changing. China’s immense progress in open-weight AI development is now being met with rapid domestic AI chip development. In the past few months, highly performant open-weight AI models’ inference in China has started to be powered by chips such as Huawei’s Ascend and Cambricon, with some models starting to be trained using domestic chips. There are two large implications for policymakers and AI researchers and developers respectively: U.S. export controls correlates with expedi]]></description>
      <pubDate>Wed, 29 Oct 2025 13:56:45 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/huggingface/shifting-compute-landscape</guid>
    </item>
    <item>
      <title><![CDATA[Building the Open Agent Ecosystem Together: Introducing OpenEnv]]></title>
      <link>https://huggingface.co/blog/openenv</link>
      <description><![CDATA[Back to Articles The Problem The Solution The RFCs Use cases What’s Next With tools like TRL, TorchForge and verl, the open-source community has shown how to scale AI across complex compute infrastructure. But compute is only one side of the coin. The other side is the developer community; the people and tools that make agentic systems possible. That’s why Meta and Hugging Face are partnering to launch the OpenEnv Hub: a shared and open community hub for agentic environments.
Agentic environments define everything an agent needs to perform a task: the tools, APIs, credentials, execution context, and nothing else. They bring clarity, safety, and sandboxed control to agent behavior.
These environments can be used for both training and deployment, and serve as the foundation for scalable agentic development. The Problem Modern AI agents can act autonomously across thousands of tasks. However, a large language model isn’t enough to get those tasks to actually run — it needs access to the right tools. Exposing millions of tools directly to a model isn’t reasonable (or safe). Instead, we need agentic e]]></description>
      <pubDate>Thu, 23 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/openenv</guid>
    </item>
    <item>
      <title><![CDATA[Arm will be @ PyTorch Conference, Join Us!]]></title>
      <link>https://huggingface.co/blog/Arm/arm-at-pytorch-conference</link>
      <description><![CDATA[Back to Articles Co-Authored by Michelle Yung @ Arm
Join us on site October 22-23 to see how Arm empowers developers to build and deploy AI applications with ease using PyTorch and ExecuTorch. Learn about the latest AI technologies from Arm and our ecosystem while expanding your professional network alongside like-minded AI engineers. Connect, Chat, Chill Fuel up ahead of the conference with an evening of food, drinks, and good conversation . Whether you’re looking to relax or network, you’ll be in good company with fellow AI engineers. This pre-conference gathering, offers a relaxed setting where participants can meet Arm experts and fellow professionals in artificial intelligence, share experiences, and make valuable connections before the formal sessions begin. The event will include a variety of delicious refreshments to enjoy, creating a welcoming atmosphere for both casual mingling and engaging discussions. This evening promises a memorable and enjoyable start to the conference experience. Join our Meetup Strengthen Your AI Product We’re offering one-on-one workshop sessions with design experts to help improve the usability of your product, while enabling a focus on responsible AI development with best practices like Yellow Teaming to help avoid unintended issues before]]></description>
      <pubDate>Fri, 10 Oct 2025 17:35:04 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Arm/arm-at-pytorch-conference</guid>
    </item>
    <item>
      <title><![CDATA[BigCodeArena: Judging code generations end to end with code executions]]></title>
      <link>https://huggingface.co/blog/bigcode/arena</link>
      <description><![CDATA[Back to Articles Motivation The BigCodeArena Platform Real-Time Execution Multi-Language &amp; Framework Support Interactive Testing Multi-Turn Conversations What We've Learned: 5 Months of Community Evaluation Programming Topics in the Wild Language and Framework Popularity User Interaction Patterns Model Rankings from Community Votes Two New Benchmarks: BigCodeReward and AutoCodeArena BigCodeReward: Evaluating Reward Models for Code AutoCodeArena: Automated Code Generation Benchmarks Try It Yourself Open Source Everything What's Next? Conclusion Acknowledgements Citation Evaluating the quality of AI-generated code is notoriously difficult. While humans can easily spot whether a piece of code "looks right," determining if it actually works correctly, handles edge cases properly, and produces the intended result requires running and testing it. This is why today, we're thrilled to announce BigCodeArena --]]></description>
      <pubDate>Tue, 07 Oct 2025 09:37:25 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/bigcode/arena</guid>
    </item>
    <item>
      <title><![CDATA[Introducing RTEB: A New Standard for Retrieval Evaluation]]></title>
      <link>https://huggingface.co/blog/rteb</link>
      <description><![CDATA[Back to Articles TL;DR – We’re excited to introduce the beta version of the Retrieval Embedding Benchmark (RTEB), a new benchmark designed to reliably evaluate the retrieval accuracy of embedding models for real-world applications. Existing benchmarks struggle to measure true generalization, while RTEB addresses this with a hybrid strategy of open and private datasets. Its goal is simple: to create a fair, transparent, and application-focused standard for measuring how models perform on data they haven’t seen before.
The performance of many AI applications, from RAG and agents to recommendation systems, is fundamentally limited by the quality of search and retrieval. As such, accurately measuring the retrieval quality of embedding models is a common pain point for developers. How do you really know how well a model will perform in the wild?
This is where things get tricky. The current standard for evaluation often relies on a model's "zero-shot" performance on public benchmarks. However, this is, at best, an approximation of a model's true generalization capabilities. When models are repeatedly evaluated against the same public datasets, a gap emerges between their reported scores and their actual performance on new, unseen data. Performance Di]]></description>
      <pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/rteb</guid>
    </item>
    <item>
      <title><![CDATA[SyGra: The One-Stop Framework for Building Data for LLMs and SLMs]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework</link>
      <description><![CDATA[Back to Articles Enter SyGra: One Framework for Every Data Challenge Why SyGra Matters SyGra Architecture Final Thoughts References When we think about building a model - be it a Large Language Model (LLM) or a Small Language Model (SLM) - the first thing we need is data. While a vast amount of open data is available, it rarely comes in the exact format required to train or align models.
In practice, we often face scenarios where the raw data isn't enough. We need data that is more structured, domain-specific, complex, or aligned with the task at hand. Let's look at some common situations: Complex Scenarios Missing You start with a simple dataset, but the model fails on advanced reasoning tasks. How do you generate more complex datasets to strengthen performance? Knowledge Base to Q&amp;A You already have a knowledge base, but it's not in Q&amp;A format. How can you transform it into a usable question-answering dataset? From SFT to DPO You've prepared a supervised fine-tuning (SFT) dataset. But now you want to align your model using Direct Preference Optimization (DPO). How can you generate preference pairs? Depth of Questions You h]]></description>
      <pubDate>Mon, 22 Sep 2025 06:45:05 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework</guid>
    </item>
    <item>
      <title><![CDATA[Gaia2 and ARE: Empowering the community to study agents]]></title>
      <link>https://huggingface.co/blog/gaia2</link>
      <description><![CDATA[Back to Articles Gaia2: Agentic Evaluation on Real Life Assistant Tasks How does Gaia2 run? Results Compare with your favorite models! Evaluating on Gaia2 Beyond Gaia2: study your agents with ARE 1) Testing an agent on a simple task: event organisation 2) Understanding agents: deep diving the traces 3) Playing around and extending the demo: Connecting the agent to your own MCPs Conclusion In an ideal world, AI agents would be reliable assistants. When given a query, they would easily manage ambiguity in instructions, construct step-by-step plans, correctly identify necessary resources, execute those plans without getting sidetracked, and adapt to unexpected events, all while maintaining accuracy and avoiding hallucinations.
However, developing agents and testing these behaviors is no small feat: if you have ever tried to debug your own agent, you’ve probably observed how tedious and frustrating this can be. Existing evaluation environments are tightly coupled with the tasks they evaluate, lac]]></description>
      <pubDate>Mon, 22 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/gaia2</guid>
    </item>
    <item>
      <title><![CDATA[Democratizing AI Safety with RiskRubric.ai]]></title>
      <link>https://huggingface.co/blog/riskrubric</link>
      <description><![CDATA[Back to Articles Risk Rubric, a new Standardized Assessment of Risk for models What we found (as of September 2025) Conclusion Building trust in the open model ecosystem through standardized risk assessment
More than 500,000 models can be found on the Hugging Face hub, but it’s not always clear to users how to choose the best model for them, notably on the security aspects. Developers might find a model that perfectly fits their use case, but have no systematic way to evaluate its security posture, privacy implications, or potential failure modes. As models become more powerful and adoption accelerates, we need equally rapid progress in AI safety and security reporting. We're therefore excited to announce RiskRubric.ai, a novel initiative led by Cloud Security Alliance and Noma Security, with contributions by Haize Labs and Harmonic Security, for standardized and transparent risk assessment in the AI model ecosystem. Risk Rubric, a new Standardized Assessment of Risk for models RiskRubric.ai provides consistent, comparable risk scores across the entire model landscape, by evaluating models across six pillars: transparency, reliability, security, privacy, safety, and reputation. The platform's approach aligns perfectly with open-source values: r]]></description>
      <pubDate>Thu, 18 Sep 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/riskrubric</guid>
    </item>
    <item>
      <title><![CDATA[Neural Super Sampling is here!]]></title>
      <link>https://huggingface.co/blog/Arm/neural-super-sampling</link>
      <description><![CDATA[Back to Articles Elevated by machine learning Learn about our NSS Model How we trained the model Get started experimenting with NSS today! Neural Super Sampling (NSS), a next-generation AI-powered upscaling solution from Arm is released for graphics and gaming developers to start experimenting today! Elevated by machine learning NSS is designed for real-time performance on future mobile devices with Arm Neural Technology. However, latency depends on implementation factors such as GPU configuration, resolution, and use case. In our Enchanted Castle demo video below, NSS reduced GPU workload by 50 percent. The model rendered at 540p and upscaled to 1080p in just 4ms in sustained performance setup. Your browser does not support the video tag. Learn about our NSS Model Neural Super Sampling (NSS) is a parameter prediction model for real-time temporal super sampling developed by Arm, optimized for execution on Neural Accelerators (NX) in mobile GPUs. It enables high-resolution rendering at a lower compute cost by reconstructing high-quality output frames from low-resolution temporal inputs. NSS is particularly suited for mobile gaming, XR, and other power-constrained graphics use cases.
Get starte]]></description>
      <pubDate>Tue, 12 Aug 2025 14:52:08 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/Arm/neural-super-sampling</guid>
    </item>
    <item>
      <title><![CDATA[Welcome GPT OSS, the new open-source model family from OpenAI!]]></title>
      <link>https://huggingface.co/blog/welcome-openai-gpt-oss</link>
      <description><![CDATA[Back to Articles GPT OSS is a hugely anticipated open-weights release by OpenAI, designed for powerful reasoning, agentic tasks, and versatile developer use cases. It comprises two models: a big one with 117B parameters (gpt-oss-120b), and a smaller one with 21B parameters (gpt-oss-20b). Both are mixture-of-experts (MoEs) and use a 4-bit quantization scheme (MXFP4), enabling fast inference (thanks to fewer active parameters, see details below) while keeping resource usage low. The large model fits on a single H100 GPU, while the small one runs within 16GB of memory and is perfect for consumer hardware and on-device applications.
To make it even better and more impactful for the community, the models are licensed under the Apache 2.0 license, along with a minimal usage policy: We aim for our tools to be used safely, responsibly, and democratically, while maximizing your control over how you use them. By using gpt-oss, you agree to comply with all applicable law. According to OpenAI, this release is a meaningful step in their commitment to the open-source ecosystem, in line with their stated mission to make the benefits of AI broadly accessible. Many use cases rely on pri]]></description>
      <pubDate>Tue, 05 Aug 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/welcome-openai-gpt-oss</guid>
    </item>
    <item>
      <title><![CDATA[Consilium: When Multiple LLMs Collaborate]]></title>
      <link>https://huggingface.co/blog/consilium-multi-llm</link>
      <description><![CDATA[Back to Articles From Concept to Architecture Building the Visual Foundation Session State Management Making LLMs Actually Discuss LLM Selection and Research Integration Discovering the Open Floor Protocol Lessons Learned and Future Implications Picture this: four AI experts sitting around a poker table, debating your toughest decisions in real-time. That's exactly what Consilium, the multi-LLM platform I built during the Gradio Agents &amp; MCP Hackathon, does. It lets AI models discuss complex questions and reach consensus through structured debate.
The platform works both as a visual Gradio interface and as an MCP (Model Context Protocol) server that integrates directly with applications like Cline (Claude Desktop had issues as the timeout could not be adjusted). The core idea was always about LLMs reaching consensus through discussion; that's where the name Consilium came from. Later, other decision modes like majority voting and ranked choice were added to make the collaboration more sophisticated. From Concept to Architecture This wasn't my original hackathon idea. I initially wanted to build a simple MCP server to talk to my projects in RevenueCat. But I reconsidered when]]></description>
      <pubDate>Thu, 17 Jul 2025 00:00:00 GMT</pubDate>
      <source>Hugging Face Blog</source>
      <category>ai</category>
      <guid>https://huggingface.co/blog/consilium-multi-llm</guid>
    </item>
  </channel>
</rss>