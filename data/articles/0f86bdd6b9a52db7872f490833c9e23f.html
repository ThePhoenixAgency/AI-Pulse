<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>The era of the Small Giant with Damien Tanner (Changelog Interviews #673)</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.8; color: #e2e8f0; max-width: 800px; margin: 40px auto; padding: 0 20px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.5em; }
  .metadata { color: #94a3b8; font-size: 0.9em; margin-bottom: 2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 1em; }
  img { max-width: 100%; height: auto; border-radius: 8px; }
  a { color: #00d9ff; }
  p { margin-bottom: 1em; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 15px; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 15px; border-radius: 6px; overflow-x: auto; }
</style>
</head>
<body>
  <h1>The era of the Small Giant with Damien Tanner (Changelog Interviews #673)</h1>
  <div class="metadata">
    Source: The Changelog | Date: 1/22/2026 | Lang: EN |
    <a href="https://changelog.com/podcast/673" target="_blank">Original Article</a>
  </div>
  <div class="content">
    <div><div>

      <section>
        <a></a>
        <header>
          <h3>Featuring</h3>
        </header>
        
      </section>


      <section>
        <a></a>
        <header>
          <h3>Sponsors</h3>
        </header>
        <div>

            <p>
              <strong><a href="https://depot.dev/">Depot</a></strong> ‚Äì <strong>10x faster builds? Yes please.</strong> Build faster. Waste less time. Accelerate Docker image builds, and GitHub Actions workflows. Easily integrate with your existing CI provider and dev workflows to save hours of build time.
            </p>

            <p>
              <strong><a href="https://www.tigerdata.com/">Tiger Data</a></strong> ‚Äì Postgres for Developers, devices, and agents The data platform trusted by hundreds of thousands from IoT to Web3 to AI and more.
            </p>

            <p>
              <strong><a href="http://notion.com/changelog">Notion</a></strong> ‚Äì Notion is a place where any team can write, plan, organize, and rediscover the joy of play. It‚Äôs a workspace designed not just for making progress, but getting inspired. Notion is for everyone ‚Äî whether you‚Äôre a Fortune 500 company or freelance designer, starting a new startup or a student juggling classes and clubs.
            </p>

            <p>
              <strong><a href="https://fly.io/">Fly.io</a></strong> ‚Äì <strong>The home of Changelog.com</strong> ‚Äî Deploy your apps close to your users ‚Äî global Anycast load-balancing, zero-configuration private networking, hardware isolation, and instant WireGuard VPN connections. Push-button deployments that scale to thousands of instances. <a href="https://fly.io/speedrun/">Check out the speedrun</a> to get started in minutes.
            </p>

        </div>
      </section>


      <section>
        <a></a>
        <header>
          <h3>Notes &amp; Links</h3>
          <p><a href="https://github.com/thechangelog/show-notes/blob/master/podcast/the-changelog-673.md">üìù Edit Notes</a></p>
        </header>
        
      </section>


      <section>
        <a></a>
        <header>
          <h3>Chapters</h3>
        </header>
        <div>
          <table>
            
            <tbody>

                <tr>
                <td>1</td>
                <td>
                  <a href="#t=0">00:00</a>
                </td>
                <td>

This week on The Changelog


                </td>
                <td>01:26</td>
              </tr>

                <tr>
                <td>2</td>
                <td>
                  <a href="#t=86">01:26</a>
                </td>
                <td>

<a href="https://depot.dev/">Sponsor: Depot</a>


                </td>
                <td>02:18</td>
              </tr>

                <tr>
                <td>3</td>
                <td>
                  <a href="#t=224">03:44</a>
                </td>
                <td>

Start the show!


                </td>
                <td>01:47</td>
              </tr>

                <tr>
                <td>4</td>
                <td>
                  <a href="#t=331">05:31</a>
                </td>
                <td>

AI Engineer (AIE) Code Summit 2025


                </td>
                <td>03:58</td>
              </tr>

                <tr>
                <td>5</td>
                <td>
                  <a href="#t=569">09:29</a>
                </td>
                <td>

What is/was Pusher?


                </td>
                <td>03:34</td>
              </tr>

                <tr>
                <td>6</td>
                <td>
                  <a href="#t=783">13:03</a>
                </td>
                <td>

How are today's days different?


                </td>
                <td>02:17</td>
              </tr>

                <tr>
                <td>7</td>
                <td>
                  <a href="#t=920">15:20</a>
                </td>
                <td>

SaaS is dead!?


                </td>
                <td>13:52</td>
              </tr>

                <tr>
                <td>8</td>
                <td>
                  <a href="#t=1752">29:12</a>
                </td>
                <td>

<a href="https://www.tigerdata.com/">Sponsor: Tiger Data</a>


                </td>
                <td>02:30</td>
              </tr>

                <tr>
                <td>9</td>
                <td>
                  <a href="#t=1901">31:41</a>
                </td>
                <td>

No code review? What's replacing it?


                </td>
                <td>02:52</td>
              </tr>

                <tr>
                <td>10</td>
                <td>
                  <a href="#t=2073">34:33</a>
                </td>
                <td>

Opus 4.5 changed things (really Sonnet 4.5 first)


                </td>
                <td>03:16</td>
              </tr>

                <tr>
                <td>11</td>
                <td>
                  <a href="#t=2269">37:49</a>
                </td>
                <td>

Is Saas REALLY dead? Hmm...


                </td>
                <td>04:38</td>
              </tr>

                <tr>
                <td>12</td>
                <td>
                  <a href="#t=2547">42:27</a>
                </td>
                <td>

Inviting non-technical folks to Terminal


                </td>
                <td>05:18</td>
              </tr>

                <tr>
                <td>13</td>
                <td>
                  <a href="#t=2864">47:44</a>
                </td>
                <td>

What if everything was JIT?


                </td>
                <td>03:40</td>
              </tr>

                <tr>
                <td>14</td>
                <td>
                  <a href="#t=3084">51:24</a>
                </td>
                <td>

It's Layercode time


                </td>
                <td>12:31</td>
              </tr>

                <tr>
                <td>15</td>
                <td>
                  <a href="#t=3835">1:03:55</a>
                </td>
                <td>

<a href="http://notion.com/changelog">Sponsor: Notion</a>


                </td>
                <td>02:09</td>
              </tr>

                <tr>
                <td>16</td>
                <td>
                  <a href="#t=3964">1:06:04</a>
                </td>
                <td>

Set on Cloudflare workers (and TypeScript)


                </td>
                <td>04:00</td>
              </tr>

                <tr>
                <td>17</td>
                <td>
                  <a href="#t=4204">1:10:04</a>
                </td>
                <td>

Why not Go (or...)?


                </td>
                <td>03:53</td>
              </tr>

                <tr>
                <td>18</td>
                <td>
                  <a href="#t=4438">1:13:58</a>
                </td>
                <td>

Directing the interupt


                </td>
                <td>02:41</td>
              </tr>

                <tr>
                <td>19</td>
                <td>
                  <a href="#t=4599">1:16:39</a>
                </td>
                <td>

API vs local models - latency and reliability


                </td>
                <td>10:09</td>
              </tr>

                <tr>
                <td>20</td>
                <td>
                  <a href="#t=5207">1:26:47</a>
                </td>
                <td>

The era of the small giant


                </td>
                <td>07:09</td>
              </tr>

                <tr>
                <td>21</td>
                <td>
                  <a href="#t=5636">1:33:56</a>
                </td>
                <td>

What's next? What's over the horizon?


                </td>
                <td>02:23</td>
              </tr>

                <tr>
                <td>22</td>
                <td>
                  <a href="#t=5779">1:36:19</a>
                </td>
                <td>

Bye friends!


                </td>
                <td>00:38</td>
              </tr>

                <tr>
                <td>23</td>
                <td>
                  <a href="#t=5817">1:36:57</a>
                </td>
                <td>

Closing thoughts and stuff


                </td>
                <td>01:15</td>
              </tr>

            </tbody>
          </table>
        </div>
      </section>

      <section>
        <a></a>
        <header>
          <h3>Transcript</h3>
          <p>

<a href="https://github.com/thechangelog/transcripts/blob/master/podcast/the-changelog-673.md">üìù Edit Transcript</a>

          </p>
        </header>

        <div>

          <div>
            <div>
<a href="https://changelog.com/about">
                
</a>
              <p>Changelog</p>
            </div>
            <p><a href="https://op3.dev/e/https://cdn.changelog.com/uploads/podcast/673/the-changelog-673.mp3">Play the audio</a> to listen along while you enjoy the transcript. üéß</p>
          </div>


            <div>
              
              <p>[<a href="#t=00:00">00:00</a>] Well, friends, I‚Äôm here with a long time friend, first time sponsor of this podcast, Damien Tanner. Damien, this has been a journey, man. Like, this is the 18th year of producing The Changelog. As you know, when Wynn Netherland and I started this show back in 2009, I corrected myself recently. I thought it was November 19th. It was actually November 9th was the very first, the birthday of The Changelog. November 9th, 2009. And back then you ran Pusher, Pusher.app. And that‚Äôs kind of when sponsoring a podcast was kind of like almost charity. Like, you didn‚Äôt get a ton of value because there wasn‚Äôt a huge audience, but you wanted to support the makers of the podcast. And, you know, we were learning, and obviously open source is moving fast and we were trying to keep up, and GitHub was one year old. I mean, like, this is a different world. But I want to start off by saying, you were our first sponsor of this podcast. I appreciate that, man. Welcome to the show.</p>
            </div>


            <div>
              
              <p>So kind of you. I, you know, reflecting on Pusher, we kind of just ended up creating a lot of great community, especially around London and also around the world with Pusher. And I really love everything we did. And we started an event series. And in fact, another kind of like coming back around, Alex MacCaw, who works at Mastra, he‚Äôs coming to speak at the AI Engineer London meetup branch that I run. And he started and ran the Pusher Sessions, which became a really well known talk series in London.</p>
            </div>


            <div>
              
              <p>Okay. Were you at the most recent AI conference? I was in SF.</p>
            </div>


            <div>
              
              <p>Yeah.</p>
            </div>


            <div>
              
              <p>What was that like? I can always kind of jump in the shark a little bit because I kind of want to talk. I want to juxtapose like Pusher then timeframe developer to like now, which is drastically different. So don‚Äôt, let‚Äôs not go too far there, but how was AI in SF recently?</p>
            </div>


            <div>
              
              <p>It was a good experience, always a good injection of energy going to SF. I live just outside London. But, you know what, the venue was quite big and it didn‚Äôt have that like, together feel as much as some competitors. But it was the first time though I sat and, you know, huge conference hall. And I think it was like Windsurf or something‚Äôs chatting and I was like, this is, this is really like, we‚Äôre all miners at a conference about mining automation. And we‚Äôre like, we‚Äôre engineers. So we‚Äôre super excited about it, but, right, it‚Äôs kind of weird. Like, it‚Äôs going to change all of our jobs. All right. It‚Äôs like, I‚Äôm working right now to change everything I‚Äôm doing tomorrow, right? I mean, that‚Äôs kind of how I viewed it.</p>
            </div>


            <div>
              
              <p>I was watching a lot of the playback. I wasn‚Äôt there personally, this time around, but I would want to make it the next time around. But, you know, just the Swyx, the content coming out of there, everybody‚Äôs speaking, I know a lot of great people are there. Obviously pushing the boundaries of what‚Äôs next for us, the frontier, so to speak. But a lot of the content, I mean, almost all the content was like, top, top notch. And I feel like I was just watching the tip of humanity, right? Like just experiencing what‚Äôs to come because in tech, you know this as being a veteran in tech, we shape, we‚Äôre shaping the future of humanity. In a lot of cases, technology drives that. Technology is a major driver of everything. And here we are at the precipice of the next, the next, next thing. And it‚Äôs just wild to see what people are doing with it, how it‚Äôs changing everything we know. Everything. I feel like it‚Äôs like a flip. It‚Äôs a complete, not even a one eighty, like a 720, you know what I mean? Like it‚Äôs three spins or four spins, it‚Äôs not just one spin around to change things. I feel like it‚Äôs a dramatic forever. Don‚Äôt even know how it‚Äôs going to change things, changing things thing.</p>
            </div>


            <div>
              
              <p>[<a href="#t=04:05">04:05</a>] I mean, you know, bringing it back to the Pusher days, it‚Äôs the vibe we had then. You know, there was this period around just before Pusher and the first half of Pusher, I felt like where we were going through this. Maybe it‚Äôs called like the Web 2.0, but there was a lot of great software being built. And a lot of, you know, the community. And I think the craft that went into, especially like the Rails community. And we were just able to build incredible web-based software. And then, you know, we‚Äôve gone through like the commercialization, industrialization of SaaS. And what gets me really excited is now when we‚Äôre, you know, we run this AI Engineer London branch. And incredible communities come together. And it‚Äôs got that energy again. And I guess the energy is very exciting. There‚Äôs new stuff. Everyone can play a part in it. And we‚Äôre also just all completely working it out. And it‚Äôs like, you‚Äôve got the, you know, folks on the main stage of the conference. And then you‚Äôve got, we‚Äôll chat about it later, maybe like, Geoffrey Huntley, posting his meme, blog post. It‚Äôs like that the crazy ideas and innovation is kind of coming from anywhere, which is brilliant.</p>
            </div>


            <div>
<p>Yeah, there‚Äôs some satire happened too. I think there was a talk that was quite comedic. I can‚Äôt remember who the talk was from, but I was really just enjoying just the fun nature of what‚Äôs happening and having fun with it, not just being completely serious all the time with it.</p>
<p>For those who are uninitiated, and I kind of am to some degree, because this has been a long time, remind me and our listeners what exactly was Pusher. And I suppose the tail end of that, how are things different today than they were then?</p>

              </div>


            <div>
              
              <p>Pusher was basically a WebSockets push API. So you could push anything to your web app in real time. So just things like notifications into your application. We ended up having a bunch of customers, maybe in finance or crypto or any kind of area where you need to live updating pricing. In the early days at one point, Uber was using Pusher to update the cars in real time before they built their own infrastructure. And it was funny. I remember the standout because we ran a consultancy where we were chatting about the WebSockets in browsers and we‚Äôre like, oh, this is cool. How can we use this? And the problem is, you know, we were all building Rails apps. So like, okay, we need like a separate thing, which manages all the WebSocket connections to the client. And then we can just post an API request and say, push this message to all the clients. It was a simple idea and we took it seriously and built it into pretty formidable dev tool used by millions of developers. And still used a lot today. And we eventually exited the company to MessageBird who are kind of European Twilio competitor. Actually, at one point, we nearly sold the company to Twilio. That would have been a very different timeline.</p>
            </div>


            <div>
              
              <p>According to my notes, you raised $9.2 million, which is a lot of money back then. I mean, it‚Äôs a lot of money now, but like, that was tremendous. That was probably 2010, right? 2011?</p>
            </div>


            <div>
              
              <p>The bulk of that we raised later on from Balderton. Okay. The first round was maybe half a million. Very, very small. And it started out the agency. So we built the first version in the agency. Just for fun, I suppose.</p>
            </div>


            <div>
              
              <p>And maybe some tears on your part. Juxtapose the timeline, right? You got an acquisition ultimately, but you mentioned Twilio as an opportunity. How would have that been different, if you can like branch the timeline?</p>
            </div>


            <div>
              
              <p>[<a href="#t=08:09">08:09</a>] It would have been a great experience to work with the team. There‚Äôs incredible people who watched Twilio and move through Twilio. I don‚Äôt know. I haven‚Äôt calculated it, but we didn‚Äôt sell, because the offer wasn‚Äôt good enough in our minds. It was a bit of a local, and it was stock. In hindsight, the stock hasn‚Äôt gone very well. Turns out it was a good financial decision, but would have loved that experience. I think Twilio became the kind of OG of DevRel, right? And dev community. And we‚Äôve run, you know, how we got to know them is we did a lot of combined events with them and hackathons with them. That was a fun time.</p>
            </div>


            <div>
              
              <p>Yeah, they were like the origination. Jeff Lawson was, you know, very much quintessential in that process of a whole new way to market to developers. And I think that might have been the beginning of what we call DevRel today. Would you agree with that? I mean, it‚Äôs like, if there was a seed, that was one of many, probably, but I think one of the earliest seeds to plant of what DevRel is today.</p>
            </div>


            <div>
              
              <p>Crazy times, man.</p>
            </div>


            <div>
              
              <p>So how do you think about those times of Pusher and the web and building APIs and building SaaS services, et cetera, and, you know, pushing messages to Rails apps. How are today‚Äôs days different for you?</p>
            </div>


            <div>
              
              <p>It‚Äôs exciting, because the web and software is just completely changing again. Like, I feel like we had that with Web 2.0, right? That was the birth of software on the internet, hosted software on the internet. And it‚Äôs such an embedded thing in our culture, in our business, as developers, a lot of us work on that kind of software. But most businesses run on SaaS software now. And I have to remind myself, like, there was a time before SaaS. And therefore, there can be a time after SaaS, and there can be a thing that comes after SaaS. And it‚Äôs not a given that SaaS sticks around. I mean, like any technology, we tend to kind of go in layers, right? We still have a bunch of copper phone lines around the place, and we use them for other things, and we‚Äôre slowly replacing them. Like, these changes, you know, in the aggregate take a lot of time. But I guess, you know, the thing that can shift more quickly is the direction things are going. And really in the last few months, I think I‚Äôve been more and more convinced by my own experiences and things I‚Äôve seen playing with stuff, that it‚Äôs entirely possible, and probably pretty likely that there is a post SaaS. And I think I don‚Äôt know if everyone realizes, but like the, or everyone is with that intention, but like all of us playing with agents and LLMs, whether it‚Äôs to build the software or to do things, we are doing that. You know, when we‚Äôre probably doing that instead of building a SaaS, we‚Äôre using it to build a SaaS, right? It‚Äôs already playing out amongst the developers.</p>
            </div>


            <div>
              
              <p>Yeah, it‚Äôs an interesting thought experiment to think about the time before SaaS and the potential, as you may say, the potential time after SaaS. I‚Äôm curious because I hold that opinion to some degree. I think there‚Äôs, you know, what SaaS stays and what SaaS goes if it dies. And you said in the pre-call, burst the bubble a little bit here, you did say, and I quote, all SaaS is dead. Can you explain your homework? All SaaS is dead.</p>
            </div>


            <div>
              
              <p>I think I should probably go through my journey to here, to kind of illustrate it, because‚Ä¶</p>
            </div>


            <div>
              
              <p>Give us the TLDR first, though. Give us the, the clip, and then go into the journey.</p>
            </div>


            <div>
              
              <p>Okay, okay. The TLDR is SaaS. So there‚Äôs a few layers as like the building of software or parts to software. There‚Äôs a building of software. And then there‚Äôs the operating of software to get something done. And I think most developers are very familiar with like the building of software as changing now. But the operating software, the operating of work, the doing of work in all industries and all knowledge work, can change like we‚Äôve changed software. And SaaS is made for humans, slow humans to use. The SaaS UI is made for a puny human to go in, you know, understand, you know, work at this complex thing and it has to be in a nice UI. If it‚Äôs not a human actually doing the work that they do in the SaaS, if it‚Äôs an AI doing that work, why is there a, why is there a SaaS tool? The AI doesn‚Äôt need a SaaS tool to get the work done. It might need a little UI for you to tell you what it‚Äôs done. But the whole idea of humans using software, I think, is going to change. It can.</p>
            </div>


            <div>
              
              <p>Yeah. Well, you‚Äôve been steeped in, and I still want to hear your journey, but I‚Äôm going to step in one second. You‚Äôve been steeped in APIs and SaaS for a while. So I hold that opinion that you have that I agree that the, if the SaaS exists for a UI for humans, that‚Äôs definitely changing. So I agree with that. Where I‚Äôm not sure of, and I‚Äôm still questioning myself is like, what is the true solution here? There are SaaS services that can simply be an API. You know this, you built them. I don‚Äôt really need the web UI. Actually, I kind of just prefer the CLI, I kind of prefer just JSON from my agents. I kind of prefer Markdown for me because I‚Äôm the human. I want those good prose. I want all of it local. So my agents can, you know, mine it and create sentiment analysis and, you know, all this fun stuff you could do with DuckDB and Parquet and just super, super fast stuff across embeddings and, you know, vector, you know, PG vector, all those fun things you could do in your own data. But that‚Äôs where I stop is I do agree that the web UI will go where some version of it. Maybe it‚Äôs just there‚Äôs like a dashboard for those who don‚Äôt want to play in the dev world with CLIs and APIs and MCP and whatnot. But I feel like SaaS shifts. Like my take is CLI is the new app. That‚Äôs my take is that SaaS will shift. But I think it will shift into CLI for a human to instruct an agent and an agent to do. And it‚Äôs largely based on API, JSON, you know, clear defined endpoints, great specifications, things that get more and more mature as a result of that.</p>
            </div>


            <div>
              
              <p>Yeah, I guess we should probably kind of tease apart SaaS the business and SaaS the software. Okay. Because yeah, I agree that the interface is changing. The interface that we use, whether it‚Äôs visually CLI or a chat conversation or something. But the way we communicate with the software is changing, right? It‚Äôs a much more natural language thing. We don‚Äôt have to dig in the UI to find the thing to click. But also so much of the software we use that we call SaaS that we access remotely. If you can just magic that SaaS locally or within your company, right? There‚Äôs no need to access that SaaS anymore, right? You just have that functionality. You just ask for that functionality and it‚Äôs being built. But yeah, SaaS, the business, I guess this is the challenge for companies today is they‚Äôre going to have to, if they want to stay in business, they‚Äôre going to have to shift somehow. Because yeah, I mean, there‚Äôs still got to be some harness, harness is the wrong word because you use that in coding agents, but like some infrastructure, some cloud, some coordination, authentication, data storage, there‚Äôs still a lot to do. And I think there‚Äôs going to be some great opportunities for companies to do that. And maybe a CRM, a Salesforce or something, manages to say, hey, we are, people like Salesforce trying to do that. We are the place to run your sales agents, right? You‚Äôre magically instantiated CRM code that you want just for your business. Maybe there‚Äôll be some winners there. But the idea that I think the thing that‚Äôs going to change SaaS‚Äôs business, SaaS Software is the idea that like everyone has to go and buy the same version, you know, of some software which they remotely accessing can‚Äôt really change.</p>
            </div>


            <div>
              
              <p>Okay, I‚Äôm feeling that for sure. Take us back into the journey then because I feel like I cut you off and I don‚Äôt want to disappoint you, but not let you go and give the context, the key word for most people these days, the context for that blanket statement that SaaS is dead or dying.</p>
            </div>


            <div>
              
              <p>Yeah, okay, I‚Äôll give you a bit of the story. So my company Layercode, I‚Äôll just give you a little short on that. We provide a voice agents platform. So anyone can add voice to their agent. It‚Äôs developer tool, developer API platform for that. And we‚Äôre now ramping up our sales and marketing. And we kind of started doing it the normal ways. We kind of got a CRM. We got some marketing tools. And I was just finding, we went through a CRM too. And I was just finding them like, these are like the new CRMs that are supposed to be good. They were just really, really slow. And then I just couldn‚Äôt work out how to do stuff. It was like, I had to go and set up a workflow. And it was like, I needed training to use this CRM tool. And I‚Äôd been having a lot of fun with Claude Code and Codex, kind of both flipping between them, kind of getting a feel for them. And so I just said, build me a, I just voice dictated, you know, a brain dump for like 10, 15 minutes. Here‚Äôs the CRM I need. And also it wasn‚Äôt just like a boring CRM, it was like, I need a CRM, I need you to make a CRM that kind of engages me as a developer who doesn‚Äôt wake up and go, let‚Äôs do sales, you know, gamify it for me. And then here are the ways I want you to do that. And it just did it. That was my kind of like coding agents moment. And I think you have that moment when you do a new project. You use an LLM and a completely greenfield project. And there‚Äôs no kind of existing code it‚Äôs going to kind of mess up or get wrong and the project‚Äôs not too big. It just built the whole freaking CRM. And it was really good. It was a good CRM and it worked really well. And so that was like my kind of like level one awakening, which was like this idea that you can just have the SaaS you want instantly. It suddenly felt true. It felt, because I had done it. And I have canceled the old CRM system now. And there‚Äôs a bunch of other tools I plan to cancel. You know, because they‚Äôre all crap, but because it‚Äôs harder to use them than it is to just say what I want. Because I kind of have to learn how to use those tools. Whereas I can just say, make me the thing, make me the website I want instead of using a website builder tool or make me the CRM that I want to use. And then there‚Äôs this like different cycle that you have, the loop that you have of improvement, where it‚Äôs not a once, it‚Äôs not build and then use the software. It‚Äôs like as you‚Äôre using the software, you can improve the software at any time. And we‚Äôve still got to work out how this works. Like who has the power to change the software? And how do you share that amongst a team, right? And do I have a branch of the software that I, or do I have different, like my own views or something in the CRM that I can mess around with? But just as a within our team of three doing this stuff in the company, it was like, oh, you‚Äôre annoyed with this part of the software. Just change it. Just change it.</p>
            </div>


            <div>
              
              <p>Yeah. When it annoys you, it‚Äôs the exact point of time and then continue with the work. Right. And I assume you‚Äôre probably still doing like a GitHub or some sort of like primary GitHub, not literally like GitHub, but git repository as a hub for your work, right? And you probably have pull requests or merge requests. So even if your teammate is frustrated, improves the software, pushes it back, you‚Äôre still using the same software and you‚Äôre still using the same traditional developer tooling, which is pull requests, code review, merging.</p>
            </div>


            <div>
              
              <p>Yeah. That‚Äôs going to have to change as well.</p>
            </div>


            <div>
              
              <p>Okay. Take me there. I woke up this morning with that feeling.</p>
            </div>


            <div>
              
              <p>Okay. That‚Äôs changing too.</p>
            </div>


            <div>
              
              <p>How‚Äôs it changing?</p>
            </div>


            <div>
              
              <p>With the CRM and with something we‚Äôve been building this week, there were new pieces of software. There weren‚Äôt existing code bases. I didn‚Äôt have any prior ideas and taste and requirements about what the code should look like. I think this is the thing that slows people down with coding agents. You use it on existing repo and LLMs have bad taste. They just give you kind of the most common denominator, kind of bad taste version of anything, whether it‚Äôs like writing a blog post or coding, right? And so when you use it on an existing project and then you review the code, you just find all these things wrong with it, right? It‚Äôs like, you know, right now they love doing all this like really defensive try-catch in JavaScript or really verbose stuff or right now a utility function that exists in a library already. But when you start on a new project and you just use YOLO mode and you‚Äôre just, you know, you‚Äôre building something for yourself as well, right? And it works. Like, where‚Äôs the code? Why review the code? I think we‚Äôre only in this temporary, weird thing where we‚Äôre like trying to jam, like we have these existing software processes that ensure we deliver high quality software, secure software, good software. I think it‚Äôs hard, we can‚Äôt throw it, we‚Äôve got SOC 2, we can‚Äôt throw those out the window for everything that exists today. But for everything new that you‚Äôre building, you‚Äôve got an opportunity to kind of pull apart, question and collapse down all of these kind of processes we built for ourselves, processes that were built to ensure humans don‚Äôt make mistakes, right? And help humans collaborate and help humans manage change in the repository and everything. It‚Äôs like if the humans aren‚Äôt writing the code anymore, we need to question these things.</p>
            </div>


            <div>
              
              <p>Are you moving into the land of agent first then? It sounds like that‚Äôs what you‚Äôre going.</p>
            </div>


            <div>
              
              <p>I feel like I‚Äôm being pulled into it by, yeah, I‚Äôm slight, I‚Äôm kind of like, there is a tide. I can‚Äôt resist. I‚Äôm falling in the hole. And we‚Äôre kind of like, we‚Äôre dipping our toes in, right? Trying to try out Cursor and Tab. And then we‚Äôre kind of in there and we‚Äôre swimming, trying to swim the way we normally swim the way we want to go. And suddenly I‚Äôve just gone, just like relax and just let the tide, let the river take you. Just let it go, man. Just let it go.</p>
            </div>


            <div>
              
              <p>It‚Äôs scary.</p>
            </div>


            <div>
              
              <p>It feels kind of terrifying and there are going to, and I don‚Äôt have the answers to how we do code review. But you know, if you look at like a lot of, you know, teams talking about using AI coding agents and the resisting project, everyone‚Äôs big problem now is code reviews, right? Because everyone using coding agents is producing so many PRs, it‚Äôs like it‚Äôs piling up in this review process that has to be done. The new teams that don‚Äôt have that process in place, they are going multiple times faster right now.</p>
            </div>


            <div>
              
              <p>Okay. What is replacing code review if there‚Äôs no code review? Is it just nothing?</p>
            </div>


            <div>
              
              <p>To these teams that you‚Äôre explaining about, like us as developers, we need to think more like, we need to put ourselves in the shoes of PMs, designers, managers. Because they don‚Äôt, they don‚Äôt look at the code, right? They say we need this functionality. We build it. We do our code reviews. We ensure it works. And the PM, whoever, goes, oh yeah, great. I‚Äôve used it and it‚Äôs a requirement. It‚Äôs great, right? They‚Äôre comfortable not looking at the code. They‚Äôre a long way from the code. They‚Äôre closing the deal. They‚Äôre with the customer. They‚Äôre integrating. They‚Äôre like, I am confident that the intelligent being that created this code did a good job. Now, I think the only reason we‚Äôre kind of stuck in this old process is because many of them are set in stone. But also because LLMs aren‚Äôt quite smart enough yet. They still make stupid mistakes. Right. You still need a human in the loop and on the loop.</p>
            </div>


            <div>
              
              <p>Yeah, I mean, they‚Äôre still a bit dumb and they get done with silly things and they do. Oh, look, they‚Äôre going the wrong direction for a while. And I‚Äôm like, no, hang on a second. That‚Äôs a great thought here. But let‚Äôs get back on track. This is the problem we‚Äôre solving. And you‚Äôve sidequested us. It‚Äôs a fun sidequest, that was the point, but that‚Äôs not the point.</p>
            </div>


            <div>
              
              <p>But this is going to change. Right. And this is one of the hard things is trying to put ourselves in the mindset of what it‚Äôs going to be like in a year. And I think I‚Äôve only been, you know, after us being able to play with LLMs for several years, it feels like I can feel the velocity of it now. Right. Because I‚Äôve felt GPT-3, 4, 5, Claude, Codex. And now I can go, oh, okay, that‚Äôs what it feels like for it to get better. And it‚Äôs going to keep getting better for a few more years. So it‚Äôs kind of like self-driving cars, right? They‚Äôre like not very useful while they‚Äôre worse than humans. But suddenly when they‚Äôre safer than a human, like, why would you have a human?</p>
            </div>


            <div>
              
              <p>Yeah.</p>
            </div>


            <div>
              
              <p>And I think it‚Äôs the same with coding. Like all this process is to stop humans making mistakes. We make mistakes. Like our mistakes are not special, better mistakes. They‚Äôre still like, we stuff up code. We cause security incidents. And so I think as soon as the LLMs are twice as good, five times as good, 10 times better at outputting good code that doesn‚Äôt cause these issues. We‚Äôre going to start to let go of this concern, like these things, right? We‚Äôre going to start to trust them more.</p>
            </div>


            <div>
              
              <p>Something I leaned on recently, and it was really with Opus 4.5. I feel like that‚Äôs when things sort of changed because I‚Äôm with you on the trend from GPT-3 on to now and feeling the incremental change. I feel like Opus 4.5 really changed things. And I think I heard it in an AI talk or at least in the intention of it, if it wasn‚Äôt verbatim, was trust the model. Just trust the model. As a matter of fact, I think it was one of the guys, man, they were building an agent. And in the process was maybe as an agent layer, layer agent, something like that. Maybe borrowed something from your name, Layercode. I have to look it up. I‚Äôll get the talk. I‚Äôll put in the show notes. But I think it was that talk. And I was like, okay, the next time I play, I‚Äôm going to trust the model. And I will sometimes like stop it from doing something because I think I‚Äôm trying to direct it in a certain direction. And now I‚Äôve been like, wait a second. And like, this code‚Äôs free basically. It‚Äôs just going to generate anyways. Let‚Äôs see what it does. Worst case, I‚Äôm like, you know, roll back or worst case is like just generate better. I mean, like ultra think. Right. You know, what‚Äôs the worst that could happen because it‚Äôs going faster than I can. Anyways, let‚Äôs see. Even if it‚Äôs a mistake, let‚Äôs see the mistake. Let‚Äôs learn from the mistake because that‚Äôs how we learn even as humans. I‚Äôm sure LLMs the same. And so I‚Äôve come back to this philosophy or this thought, almost to the way you describe it, like falling into this hole, slipping in via gravity. Not excited at first, but then kind of like excited because like, well, it‚Äôs good in there. Let‚Äôs just go. Just trust the model, man. Just</p>
            </div>


            <div>
<p>[<a href="#t=30:03">30:03</a>] Trust the model. And it can surprise you. And I think that still gives me that dopamine hit that I would have coding, right? When I was coding manually, you‚Äôd get a function right and you‚Äôd be like, ‚ÄúAh, it works.‚Äù And now it‚Äôs like, you‚Äôve got the whole application and you‚Äôre like, ‚ÄúAh, I just did a problem for the whole thing works.‚Äù That‚Äôs right.</p>
<p>Yeah, it‚Äôs really exciting. And yeah, it‚Äôs fun right now. I mean, it‚Äôs going to keep changing. This is just a bit of a temporary phase here and now. But I think for many of us building software, we love the craft of it, which you can still do. But also the making a thing is also one of the exciting bits of it. And the world is full of software still. Like, you think about so many interactions you have with like government service or whatever. Not saying that they‚Äôre going to adopt coding agents, particularly, but there is a lot of bad software in the web. And software has been expensive to build. And that‚Äôs because it‚Äôs been in high demand. And so I don‚Äôt think we‚Äôre going to run out of stuff to build. I think even if we get 10 times faster, 100 times faster, there‚Äôs so much useful software and products and things and jobs to be done.</p>

              </div>


            <div>
              
              <p>Close this loop for me then. You said SaaS is dead or dying. I‚Äôm paraphrasing because you didn‚Äôt say ‚Äúor dying.‚Äù I‚Äôm just going to say we‚Äôre dying. I‚Äôll parenthesis. That‚Äôs my parenthesis. I‚Äôll add it to your thing. How is it going to change then? So if we‚Äôre making software, there‚Äôs still tons of software to write, but SaaS is dead. What exactly are we making then? If it‚Äôs not SaaS. I know that not all software is SaaS, but you do build something, a platform, and people buy the platform. Is that SaaS? What changes? You mentioned interfaces like, where do you say that?</p>
            </div>


            <div>
<p>I think we‚Äôre moving. And so this is the next level. The next kind of revelation I had was I started using the CRM. I was like, this is cool. This is super fast. This is better than the other CRM. And I can change it. Cool. I‚Äôm doing some important sales work. I‚Äôm enriching leads. And then I kind of woke up a few days later. I was like, why am I doing the work? What‚Äôs going on here? I create an interface for me to use, right? Why can‚Äôt Claude Code just do the work that I need to do for me? I know it‚Äôs not going to be with the same taste that I have. And I know it‚Äôs going to make mistakes. But I can have 10 of them do it at the same time.</p>
<p>And it‚Äôs not a particularly fun idea, fully automated sales. And what that means for the world in general, but it‚Äôs the particular vertical where I had this kind of revelation, right? Well, the enriching certainly makes sense for the LLM to do, right? The enriching is like, come on, that‚Äôs under the API, I‚Äôm copying things. And a lot of it is so manual still. And so the revelation was just waking up and then going, okay, Claude Code‚Äôs going to do the work for me today. Like it does for software. It builds the software for me. I‚Äôm going to give it a Chrome browser connection. That‚Äôs still a non-solved problem. There‚Äôs a lot of pain in LLM chatting to the browser. But there‚Äôs a few good ones. And I‚Äôm going to let it use my LinkedIn. I‚Äôm going to let it use my X. And I‚Äôm going to connect it to the APIs that I need that aren‚Äôt pieces of software, but like data sources, right? I can get enriched and search things. And then I just started getting it to just do it.</p>
<p>And it was really quite, it was slow. But it was really quite good. And that was a kind of, that was like that moment where we typed in, build this feature in Claude Code, build this. But it was suddenly like this thing can just do anything a human can do on a computer. The only thing holding it back right now is the access to tools and good integrations with the interfaces, like the old software it still needs to use to do what a human does. And a bigger context window and it‚Äôd be great if it was faster. But I can run them in parallel so that the speed‚Äôs not a massive problem.</p>
<p>And in the space of a week, I built the CRM. And then I got Claude Code to just do the work, but I didn‚Äôt tell it to use the CRM. I just told it to use the database. And I just ended up throwing away the CRM. And now we have this little Claude Code harness that overrides the Claude Code system prompt, sets up all the tools and gives it a Postgres database. And I‚Äôve just got like, I need to vibe code a new CRM UI. But I‚Äôve just got like a database viewer that the non-technical team used to kind of look at the leads and stuff like that. It‚Äôs just a kind of Beekeeper kind of database viewer. And now Claude Code is just doing the work. We‚Äôve only applied it there, but this is just like Claude Code is like this kind of little innovation in an agent that can do work for a long time. And we already know people use ChatGPT for all sorts of different things beyond coding, right? And so suddenly I think these coding agents are a glimpse of all knowledge work can be sped up or replaced.</p>
<p>Administration can be replaced with these things now.</p>

              </div>


            <div>
              
              <p>Yeah, these non-technical folks, why not just invite them to the terminal and give them CLI outputs that they can easily run and just up arrow to repeat or just teach them certain things that maybe they weren‚Äôt really comfortable with doing before. And now they‚Äôre also one step from being a developer or a builder because they‚Äôre already in the terminal. And that‚Äôs where Claude‚Äôs at.</p>
            </div>


            <div>
              
              <p>Yeah, I mean, that‚Äôs what we‚Äôve done now. I‚Äôve seen some unexpected kind of teething issues with that. I think there‚Äôs just a terminal feels a bit scary to non-technical people. Even if you explain how to use it, like when they quit Claude Code or something, they‚Äôre just kind of like lost. They‚Äôre like, ‚ÄúOh my gosh, where did Claude Code go?‚Äù</p>
            </div>


            <div>
              
              <p>Yeah. And I was onboarding whatever team, it was like open the terminal. And then I‚Äôm like, okay, we‚Äôve got a CD. What if the terminal was just Claude Code? What if you built your own terminal that was just‚Äî</p>
            </div>


            <div>
              
              <p>I think when I actually think about specific UI, whether it‚Äôs terminal or web UI, it‚Äôs kind of not the handle there, but there is the magic is a thing that can access everything on your computer, right. And they‚Äôre doing that with, I think it‚Äôs called Co-Work. Have you seen Co-Work yet?</p>
            </div>


            <div>
              
              <p>So it‚Äôs like, I haven‚Äôt played with it enough to know what it can and can‚Äôt do. I think I unleashed it on a directory with some PDFs that I had collected that was around business structure. And it was like an idea I had like four months ago with just a different business structure that would just make more sense primarily around tax purposes, you know. And I was like, hey, revisit this idea I haven‚Äôt touched it in forever. And it was a directory. And I think it went and it just did a bunch of stuff. But then it was like, come on with ideas. I‚Äôm like, nah, there‚Äôs not good ideas. I don‚Äôt know like if it‚Äôs like less smart than Claude Code is in intent or whatever, but it‚Äôs kind of, I think that‚Äôs what you‚Äôre trying to do with Co-Work. But you know, you could just drop them into essentially a directory, which is what Claude Code lives. And it lives in a directory of maybe files that is an application or knows how to talk to the database as you said your CRM does. And they can just be in the Claude Code instance, just asking questions. Show me the latest leads.</p>
            </div>


            <div>
              
              <p>Yeah. That could use a skill if you want to go that route or it can just be smart enough to be like, well, I have a Neon database here. The Neon CTL CLI is installed. I‚Äôm just going to query it directly. You have to be able to write some Python to make it faster. Maybe I‚Äôll store some of this stuff locally and it‚Äôll do it all behind the scenes. But then it gives this non-technical person a list of leads. All I had to do was be like, give me the leads, man. You know. And then you mentioned enabling them as builders. I think it then is a window into that because then when they want something, oh, they get curious, right? They‚Äôll be like us. They‚Äôre just going to be like, hey, build me a report for this. Build me a web app for this. Help me make this easier.</p>
            </div>


            <div>
              
              <p>Yeah. You‚Äôd be surprised how easy that is, like, help me make it easier is one of those weird ones. And Claude Code will also auto complete and just let you tab and enter. And I‚Äôve noticed that those things got more terse. Like, maybe I think if the last one I did was like, that‚Äôs interesting. It was like super short. It was like, ‚ÄúI like it, implement it.‚Äù What was the completion for them?</p>
            </div>


            <div>
              
              <p>‚ÄúI like it, implement it.‚Äù I was like, okay, is that how easy it‚Äôs gotten now to like just spit out a feature that we were just riffing on that you know the problem. You understand the bug we just got over. And now your response to me to tell you what to say because you need me the human to get you back in the loop. At least in today‚Äôs REPL is ‚ÄúI like it, implement it.‚Äù You know what I mean?</p>
            </div>


            <div>
              
              <p>I found myself just responding with the letter Y. I know a lot of the time it just knows what to do, right? Even if it kind of like is a bit ambiguous, you‚Äôre kind of like you‚Äôll work it out.</p>
            </div>


            <div>
<p>So I think it‚Äôs very exciting that Anthropic released this Co-Work thing because they‚Äôve obviously seen that inside Anthropic. All sorts of people using Claude Code. And you know, when we think about, okay, someone starts there for non-coding purposes, but stuff is done with code and CLI tools and some MCPs or whatever, APIs. And then the user says, well, make me a UI to make this easier. So for instance, I had to review a bunch of draft messages that I wrote. I was like, okay, this is kind of janky in the terminal. Make me a UI to do the review. It just did it.</p>
<p>And I think this is where software is changing because when the LLM is 10 times faster, I mean, if you use the Groq with a Qwen 10 points, right, they‚Äôre insanely fast. It‚Äôs going to be fast. Then if you can have any interface you want within a second, why have static interfaces, right?</p>

              </div>


            <div>
              
              <p>Yeah, I‚Äôm camping out there with you. What if everything was just in time? I think that interface. What if I didn‚Äôt need to share it with you? Because you‚Äôre my teammate, but what if you could do the same thing for you and it solves your problem? And you‚Äôre in your own branch and what you do in your branch, it‚Äôs like Vegas and it stays there. It doesn‚Äôt have to be saved anywhere else, right? Like just leave it in Vegas, right? What if in your own branch, in your own little world, as a sales development representative, for example, an SDR who‚Äôs trying to help the team, help the organization grow and all they need is an interface. What if it was just in time for them only? And it didn‚Äôt matter if it was maintainable. It didn‚Äôt matter how good the code was. All it mattered was that it solved their problem, get the opportunity and enable them to do what they got to do either to do the job. And you just take that and multiply or copy and paste it on all the roles that make sense for that just in time. What? It completely changes the idea of what software. It also completely changes how we interact with the computer and what a computer does and what it is for. I just love this notion that every user can change the computer, can change the software as they‚Äôre using it as they like it.</p>
            </div>


            <div>
<p>I think that‚Äôs very essentially everyone‚Äôs a developer. Yeah, I mean, it‚Äôs the ultimate way to use a computer like all the gates are down, right? There‚Äôs no geeky prerequisite anymore. If I want software the way I want software so long as I have authentication and authorization, I got the keys to my kingdom I want to make.</p>
<p>And I think also the agents can preempt, right? I haven‚Äôt tried this yet, but I was thinking of giving it the little sales thing. We have a little prompt where it says, like, either if a web UI is going to be better for the user to do this, review this, then just do it. So then instead of you asking it, you ask it to do some work and then it comes back and be like, oh, I‚Äôve made you this UI where I‚Äôve like displayed it all for you. Have a look at it. Let me know if you‚Äôre happy with it.</p>
<p>I mean, this is getting kind of wild this idea, but you, it‚Äôs kind of how we can think about how we communicate with each other as humans, as employees, right? We have back and forth conversations. We have email, which is a bit more asynchronous. You know, we put up a preview URL or something. Like I think all those communication channels can be enabled in the agent you‚Äôre chatting to and like I haven‚Äôt like this kind of like product companies have sell, you know, the initial messaging where people solve like digital employees, right? But something like that‚Äôs going to happen.</p>
<p>And I don‚Äôt think it‚Äôs the exciting bit for me is the human computer interaction, right. It‚Äôs like and this is how it‚Äôs kind of exciting in the context of Layercode and why we love voice is like voice is this OG communication method. Whereas humans we‚Äôve been speaking, we started speaking before we were writing. And it‚Äôs kind of quite a rich communication medium. And it‚Äôs a terrific way, like if your agents can be really multi-medium, whether it‚Äôs you‚Äôre doing voice with them, text with them, they create a web UI for you, you interact with the UI with them. Like there doesn‚Äôt have to be these strict modes or delineations between those things.</p>

              </div>


            <div>
<p>Well, let‚Äôs go there. I didn‚Äôt take us there yet, but I do want to talk to you about what you‚Äôre doing with Layercode. I obviously produce a podcast. So I‚Äôm kind of interested in speech to text to some degree because transcripts, right. And then you have the obvious version, which is like you start out with speech, you get something or even a voice prompt. What exactly is Layercode? And I suppose we‚Äôve been 51 minutes deep on nerding out on AI essentially. And not at all on your startup and what you‚Äôre doing, which was sort of the impetus of even getting back in touch. That‚Äôs all you had something new you were doing. And I‚Äôm like, well, I haven‚Äôt talked to Damien since he‚Äôs sponsored the show almost 17 years ago. It‚Äôs probably a good time to talk, right? So there you go. That‚Äôs how it works out.</p>
<p>Has your excitement and your dopamine hits on the daily or even by minute by minute changed how you feel about your ability with Layercode. And what exactly are you trying to do with it?</p>

              </div>


            <div>
<p>[<a href="#t=46:29">46:29</a>] Well, there‚Äôs, and we‚Äôve talked a lot about the building of a company and the building of software now. And I think founders today have that, it is as important as the thing that they‚Äôre building, right? Because if you just head into your company and operate it like you did a few years ago, using no AI, using all your kind of slow development practices, using our slow sales and marketing practices, you‚Äôre going to really get left behind.</p>
<p>And so there is a lot to be done in working out and exploring what the company of the future looks like. What the software company of the future looks like. I‚Äôm very excited about the idea that we can build large companies with small teams. I think a lot of developers, well, I mean, there is a lot of HR and politics and culture change that happens when teams get truly large and companies get truly large. And this is one of the kind of founding principles when we started our startup was let‚Äôs see how big we can make this. Yeah. We‚Äôre the small team. And that‚Äôs very exciting because I think you can move fast and you can keep culture and keep a great culture.</p>
<p>And so that‚Äôs why we invest a lot of our energy into the building of the company. And what we build and what we provide right now is, and our first product is a voice infrastructure, voice API for real-time building real-time voice AI agents. And this is currently a pretty hard problem. We focus a lot on the real-time conversational aspect. And there‚Äôs a lot of kind of weird problems in that, right? Conversations are dynamic things. And there‚Äôs a lot of state changes and interruptions and back channeling and everything that happens.</p>
<p>And if you‚Äôre a developer building an agent, it could be your sales agent, it could be a developer of a coding agent. And you want to add voice AI, there‚Äôs a bunch of stuff you‚Äôre going to bump into when you start building that. And it‚Äôs a pretty, it‚Äôs interesting, we kind of see our customers, we can kind of predict where they are in that journey, right, because there‚Äôs a bunch of problems that you don‚Äôt kind of preempt and then you just quickly slam into them.</p>
<p>And so we‚Äôve solved a lot of those problems. And so with Layercode you can then just take our API, plug it into your existing agent backend, so you can use any backend you want. And you can use any agent LLM library you want and any LLM you want. So the basic example is a Next.js application that uses the Vercel AI SDK. We‚Äôve got Python examples as well. And you connect up to the Layercode voice layer and put in our browser SDK and then you get a little voice agent microphone button and everything in the web app. We also connect to phone over to layer.</p>
<p>And then for every turn of the conversation, whenever the user‚Äôs finished speaking, we ship your backend that transcript. You call the LLM of your choice, you do your tool calls, everything you need to do to generate a response like you normally do for a text agent. Then you start streaming the response tokens back to us. And then as soon as we get that first word, we start converting that text to speech and start streaming back to the user.</p>
<p>And so there‚Äôs a bunch of stuff you have to do to make that really low latency, make that a real time conversation where you‚Äôre not waiting more than a second or two for the agent to respond. So we put a lot of work into refining that. And there‚Äôs also a lot of exciting innovation happening in the model space for voice models, whether it‚Äôs transcription or the text to speech.</p>
<p>And so we give you the freedom to switch between those models, right, so you can try out some of the different voice models, some that are really really cheap and really you know got really casual voices and some like ElevenLabs, they‚Äôre a much more expensive but they‚Äôre very professional clean voices and you can find the right fit for your kind of experience that you want, trade off. There‚Äôs a lot of trade-offs, right, in voice between latency, price, quality, so we let users explore that and find the right fit for their voice agent.</p>

              </div>


            <div>
              
              <p>That is interesting. So Next.js SDK, streaming, latency, is it, you‚Äôre meant to be the middleware between implementation and feedback to user.</p>
            </div>


            <div>
              
              <p>Yeah, we handle everything related to the voice basically and we let you just handle text like a text chatbot basically.</p>
            </div>


            <div>
              
              <p>No heavy MP3 or wave file coming down, just‚Äî</p>
            </div>


            <div>
<p>Yeah, and everything‚Äôs streaming. And so it‚Äôs a very interesting problem to solve because the whole system has to be in real time. So the whole thing, we call it a pipeline. I don‚Äôt know if that‚Äôs a great name for it because it‚Äôs not like an ETL loading pipeline, but the real time agent system, our backend, when you start a new session, it runs on Cloudflare Workers. So it‚Äôs running right near the user who clicked to chat with your agent with voice.</p>
<p>And then from that point on everything is streaming. So the microphone input from the user‚Äôs browser streaming in, that is then getting streamed to the transcription model in real time. The transcription model is spitting out partial transcripts. We send that partial transcript back to you so you can show what you‚Äôre saying if you want to show them that.</p>
<p>And then the hardest bit in this whole thing is working out when the user is finished speaking. It‚Äôs so difficult because we pause, we make sounds, we pause and then we start again and conversation is such a dynamic kind of, it‚Äôs like a game almost, right?</p>

              </div>


            <div>
              
              <p>Yeah.</p>
            </div>


            <div>
<p>So we have to do some clever things, use some other AI models to help you detect when the user ends speaking. And when we have enough confidence, like there‚Äôs no certainty here, but we have enough confidence, I think the user finished their thought, then we finalize that transcript, you know, finish transcribing that last word and ship you that whole user utterance, like whether it‚Äôs a word, a sentence, paragraph the user has spoken.</p>
<p>The reason we have to kind of like, we can‚Äôt stream at that point, right, we have to like bundle up this user utterance and choose an end, is because LLMs don‚Äôt take a streaming input. I mean, you can stream the input but like you need the complete thing, the complete question to send to the LLM to then make a request to the LLM to then generate any response, right? There is no duplex LLM that like takes input and generates output at the same time.</p>

              </div>


            <div>
              
              <p>Technically, what if you constantly wrote to a file locally or wherever the system is and then at some point it just ends and you send a call that sends the end versus packaging it up and sending the whole thing once it‚Äôs done. Like you incrementally, yeah just line by line, it‚Äôs like maybe even like, I don‚Äôt know, I‚Äôm not sure how to describe but that‚Äôs how I think about like what if you constantly wrote to something and you just said okay it‚Äôs done and what was there was the done thing.</p>
            </div>


            <div>
<p>Yeah, so we can do that in terms of like, because we have to, partial transcripts, yeah, so we can, you can stream the partial transcripts and then say okay now it‚Äôs done, now make the LLM call, then you make the LLM call.</p>
<p>But interesting, text, sending text is actually super fast in the context of, very fast. And actually the default example, this is crazy, I didn‚Äôt think this was, this would work until we tried it but it just uses a webhook. When the user finishes speaking, the basic example sends your Next.js API route a webhook with the user text. And turns out the webhook sending, sending webhook with a few sentences in it, that‚Äôs like, that‚Äôs fine, that‚Äôs fast. It‚Äôs all the other stuff, like then waiting for the LLM to respond.</p>

              </div>


            <div>
              
              <p>Yeah, that‚Äôs actually not the hard part. I mean, you have to be a millisecond or somewhat a few milliseconds but it‚Äôs not going to be a dramatic shift the way I described it versus how you do it.</p>
            </div>


            <div>
<p>Yeah, and we‚Äôve got a WebSocket endpoint now so we can kind of shave off that HTTP connection and everything but yeah, then the big heavy latency items come in. So generating an LLM response, most LLMs we use right now, they‚Äôre optimized, the ones we use in coding agents, they‚Äôre optimized for intelligence, not really speed. Then when people optimize for speed, the LLM labs, they tend to optimize for just token throughput. Very few people optimize for time to first token. And that‚Äôs all that matters in voice is I give you the user utterance, how long is the user going to have to wait before I can start playing back an agent response to them?</p>
<p>And time to first token is that, right, how long before I get the first kind of word or two that I can turn into voice and they can start hearing. The only major LLM lab that actually optimizes for this or maintains a low latency of TTFT is Google and Gemini Flash. OpenAI, most voice agents now doing it this way, we‚Äôre using GPT-4o or Gemini Flash. GPT-4o has got some annoying, the OpenAI endpoints have some annoying inconsistencies in latency. And that‚Äôs kind of the killer in voice, right, it‚Äôs a bad user experience if it works you know the first few turns of the conversation are fast and then suddenly the next turn the agent takes three seconds to respond to you. Like is the agent wrong? Is the agent broken?</p>
<p>But then once you get that first token back then you‚Äôre good because then you can, you send that text to us, you start streaming the text to us and then we can start turning into full sentences. And then again we get to this batching problem. The voice models that do text to voice, again they don‚Äôt stream in the input. They require a full sentence of input before they can start generating any output because again how you speak, how things are pronounced depends on what comes later.</p>
<p>And so you have to then buffer the LLM output into sentences, ship the buffered sentence by sentence to the voice model, and then as soon as we get that first chunk of 20 millisecond audio, we chunk it up into, we stream that straight back down WebSockets from the Cloudflare worker straight into the user‚Äôs browser, we can start playing the agent response.</p>

              </div>


            <div>
              
              <p>You chose TypeScript to do all this? Understand we‚Äôre pretty set on Cloudflare Workers from day one, okay.</p>
            </div>


            <div>
<p>And it just solves so many infrastructure problems that you‚Äôre going to run into later on. I don‚Äôt think we‚Äôll need a DevOps person ever. Yeah, it‚Äôs such a, it‚Äôs interesting, it‚Äôs such a wonderful platform. There are constraints you have to build to, right, you‚Äôre using V8 JavaScript, browser JavaScript in a Cloudflare worker. Tons of Node APIs don‚Äôt work. There is a bit of a compatibility layer. You do have to do things a bit differently. But what do you get in return? Your application runs everywhere at 330 locations around the world. There is essentially zero cold start. Cloudflare workers start up in the time while the SSL negotiations are happening, the worker has already started. And you have very few limitations to your scaling, extremely high concurrency. Every instance is very kind of isolated, that‚Äôs really important voice as well. There‚Äôs often quite big spikes, like 9 a.m. everyone‚Äôs calling up somewhere that‚Äôs got a voice agent and asking to kind of book an appointment or something. You get these big spikes. You want to be able to scale and you need to scale very quickly because you don‚Äôt want people waiting around.</p>
<p>And if you throw, well if you throw tons of users on the same system and you start kind of overloading it then suddenly people get this problem where the agent starts responding in three seconds instead of one second. And it sounds weird but yeah, Cloudflare gives you an incredible amount of that for no effort. And I think compared to kind of Lambda and stuff it‚Äôs also pretty, like the interface, it‚Äôs just a HTTP interface to your worker. There‚Äôs nothing in front and you can do WebSockets very nicely. And there‚Äôs this crazy thing called Durable Objects which I think is a bad name‚Äî</p>

              </div>


            <div>
<p>[<a href="#t=60:08">60:08</a>] And it‚Äôs also kind of a weird piece of technology, but it‚Äôs a little JavaScript runtime that is persistent basically and has a little SQLite database attached to it. And it is ‚Äî I don‚Äôt know what the right word is, it‚Äôs kind of like, it‚Äôs not the right word for JavaScript, but it‚Äôs basically think of it like thread safe. So you can have it take a bunch of WebSocket connections and do a bunch of SQL writes to its SQLite database it has attached, and you don‚Äôt have to do any kind of special stuff dealing with concurrency and atomic operations.</p>
<p>So you know, the simple example is just implement a rate limiter or a counter or something like that. You can do very simply in Durable Objects. You can have as many Durable Objects as you want. Each one of them has a SQLite database attached to it. You can have 10 gigabytes per one. And you can then kind of do whatever, you can kind of shard however you want, right? You could have a Durable Object per customer that tracks something that you need to be done real time. You could have a Durable Object per chat room.</p>
<p>As long as you don‚Äôt kind of ‚Äî like it does have a set amount of compute, a Durable Object, but you can use it for all sorts of magical things. And I think it‚Äôs a real underknown thing that Cloudflare has. Coming from Pusher, it‚Äôs like the kind of real-time primitive now. And a lot of the stuff we‚Äôd reach for something like Pusher, Durable Objects ‚Äî especially when you‚Äôre building a fully real-time system ‚Äî is really grateful.</p>

              </div>


            <div>
              
              <p>Yeah. You chose TypeScript based on Cloudflare Workers, it sounds like, because that gave you three hundred locations across the world, Durable Objects, great ecosystem, no DevOps. For those who choose Go ‚Äî or I don‚Äôt think you choose Rust for this because it‚Äôs just not the kind of place you put Rust ‚Äî but Go would compete for the same kind of mind share for you. How would the system have been different if you chose Go, or can you even think about that?</p>
            </div>


            <div>
<p>[<a href="#t=62:10">62:10</a>] I haven‚Äôt actually written any Go, so I don‚Äôt know if I can give a good comparison. But from the perspective of what we do have out there ‚Äî there are similar real-time voice agent platforms in Python. And I think because a lot of the people building the models, the voice models, then built coordination systems like Layercode for coordinating the real-time conversations, Python was the language they chose.</p>
<p>And I think what‚Äôs more important is the patterns rather than the specific languages. And so we actually wrote the first implementation with RxJS, and that has an implementation in most popular languages. I hadn‚Äôt used it before, but we chose it because it was for stream processing. It‚Äôs not really for real-time systems, but it gives you subjects, channels ‚Äî these kinds of, it has its own names for these things ‚Äî but basically it‚Äôs like a pub-subby kind of thing. And then it‚Äôs got these kind of functional chaining things where you can then kind of pipe things and filter things and filter messages and split messages and things like that.</p>
<p>And that did allow us to build the first version of this kind of quite dynamic system. We didn‚Äôt touch on it, but interruptions is this other really difficult dynamic part where whilst the agent is speaking its response to you, if the user starts speaking again, you then need to decide in real time whether the user is interrupting the agent or are they just going ‚Äúyeah‚Äù and like agreeing with the agent, or are they trying to say ‚Äúoh stop.‚Äù How much of the hard problems ‚Äî we have to still be transcribing audio even when the user is hearing it, and we‚Äôve got to deal with background noise and everything.</p>
<p>And then when we‚Äôre confident the user is trying to interrupt the agent, we‚Äôve then got to do this whole kind of state change where we tear down all of this in-flight LLM request, in-flight voice generation request, and then as quickly as possible start focusing on the user‚Äôs new question. And especially if their interruption is really short, like ‚Äústop‚Äù ‚Äî suddenly you‚Äôve got to tear down all the old stuff, transcribe the word ‚Äústop,‚Äù then ship that as a new LLM request to the backend, generate the response, and then get the agent speaking back as quickly as possible.</p>
<p>And it‚Äôs all happening down one pipe, as it were, at the end of the day, right? It‚Äôs like audio from the browser microphone and then audio replaying back. And we would have bugs like you‚Äôd interrupt the agent, but then when it started replying there‚Äôd still be a few chunks of 20 millisecond audio from the old response snuck in there, or the old audio would be interleaved with the new audio from the agent back. And you‚Äôre kind of in Audacity or something, some audio editor, trying to work out like what‚Äôs going ‚Äî why does it sound like this? And you‚Äôre rearranging bits of audio going, ‚ÄúOkay, the responses are taking turns every 20 milliseconds, it‚Äôs interleaving the two responses,‚Äù trying to work out what‚Äôs going on. Real pain in the bottom, yeah.</p>

              </div>


            <div>
              
              <p>When you solve that problem with the interruption, do you focus on the false examples, the true examples? So do you like have these ‚Äî if it is an interruption you can tell it‚Äôs an interruption by these 17 known cases? Like how do you direct that, the interrupt?</p>
            </div>


            <div>
              
              <p>It really depends on the use case. How you configure the voice agent really depends on how the voice agent is being used, right? Like a therapy voice agent needs to behave very differently than a vet appointment booking answering phone agent.</p>
            </div>


            <div>
              
              <p>[<a href="#t=66:21">66:21</a>] Yeah. What about dogs barking in the background?</p>
            </div>


            <div>
<p>Yeah, there‚Äôs that. And when we call that audio environments, that‚Äôs often an early issue users have. It‚Äôs interesting, they‚Äôre like, ‚ÄúWell, my users call from cafes and it kind of really misunderstands them.‚Äù And big problem with audio transcription ‚Äî it just transcribes any audio it hears, right? So if someone‚Äôs talking behind you, the model doesn‚Äôt quite know that‚Äôs irrelevant conversation. It‚Äôs just transcribing it all.</p>
<p>But if you imagine the therapy voice agent, it needs to actually not respond too quickly to the user and allow the user to have long pondering thoughts, long sentences, big pauses. Maybe tears, they‚Äôre crying, or just some sort of human ‚Äî you know, interrupt, but it‚Äôs not a true interrupt. It‚Äôs something that you should maybe even capture and process.</p>
<p>And so you can choose a few different levels of interruption, right? You can just interrupt when you hear any word. By default, we interrupt when we hear any word that‚Äôs not a filler word, so you filter out things like that. And then if you need some more intelligence, you can actually just ship off the partial transcripts to an LLM in real time.</p>
<p>So let‚Äôs say the user‚Äôs speaking while and starts interrupting the agent ‚Äî every kind of word you get, or a few words, you fire up a request to Gemini Flash and you say, ‚ÄúHere‚Äôs the previous thing that the user said, here‚Äôs what the agent said, here‚Äôs what the user just said. Respond yes or no, do you think they‚Äôre interrupting the agent?‚Äù And you get that back in about 250-300 milliseconds. And you just ‚Äî as you get new transcripts you can cancel the old ones ‚Äî you just constantly try and make that request until the user stops speaking. Then you get the response from that and then you can kind of make quite an intelligent decision.</p>
<p>But these things feel very hacky, but they actually work very well.</p>

              </div>


            <div>
              
              <p>[<a href="#t=68:26">68:26</a>] Well, the first thing I think about there is that Gemini Flash is not local. So you do have to deal with an outage or latency or downtime. Or in Cloudflare‚Äôs case, most recently, a lot of downtime because of usage ‚Äî like really heavy usage. Unless it is ‚Äî I‚Äôve had more trepidation with Cloudflare than ever, and I‚Äôm like, ‚ÄúOkay cool, I get it.‚Äù You know, I‚Äôm not upset with you because I empathize with how in the world do you scale those services.</p>
            </div>


            <div>
              
              <p>Yeah, it‚Äôs the Ralph effect.</p>
            </div>


            <div>
              
              <p>It‚Äôs the Ralph effect. And I‚Äôm like ‚Äî so why does your system not allow for a local LLM to be just as smart as Gemini Flash might be to answer that very simple question? Like an interrupt, it‚Äôs a pretty easy thing to determine.</p>
            </div>


            <div>
<p>Yeah, yeah. I think smaller LLMs can do that. Gemini is just incredibly fast, and I think because of their TPU infrastructure they‚Äôve got an incredibly low TTFT ‚Äî time to first token ‚Äî which is the most important thing. But I agree that there are smaller LLMs, and actually I think probably maybe one of the Groq with a qLLaMA is actually might even be a bit faster. We should try that.</p>
<p>But you make a point about reliability. People really notice it in voice agents when it doesn‚Äôt work, for sure. And especially for businesses relying on it to collect a bunch of calls for them. And so that is one of the other helpful things that platforms like us provide as well.</p>

              </div>


            <div>
<p>Or even just cost. I imagine over time, cost ‚Äî I mean, right now you‚Äôre probably fine with it as you‚Äôre innovating and maybe you‚Äôre finding out customer fit, ability, reliability, all those things. And you‚Äôre sort of just-in-time building a lot of the stuff and you‚Äôre maybe okay with the inherent cost of innovation. But at some point you may flatten a little bit and you‚Äôre like, ‚ÄúYou know what, if we had been running that locally for the last little bit, we just saved 50 grand,‚Äù you know?</p>
<p>I don‚Äôt know what the number is, but the local model becomes a version of free when you own the hardware and you own the compute and you own the pipe to it, and you can own the SLA latency to it as well. The reliability comes from that.</p>

              </div>


            <div>
<p>And there‚Äôs some cool ‚Äî there‚Äôs a new transcription model from Nvidia and they‚Äôve got some voice models as well. And so there was a great demo of fully open source, like all voice agent platform, that was done with Pipecat ‚Äî which is the Python coordination agent, open source project that I was mentioning. And they‚Äôve got a really great pattern. They have a plugin pattern for the voice agent, and I think that‚Äôs the right pattern.</p>
<p>And we‚Äôve adopted a similar ‚Äî and other frameworks have done that ‚Äî we‚Äôve adopted a similar pattern for us. When we rebuilt it recently, the important thing is the plugins are independent things that you can test in isolation. That was the biggest problem we had with RxJS ‚Äî the whole thing was kind of, you know, those mixing kind of audio mixing things with cables going everywhere. It was kind of like that, right, with RxJS subjects going absolutely everywhere. It was kind of hard ‚Äî it was hard for us as humans to understand. It was the kind of code where you come back to a week later and go, ‚ÄúWhat was happening here?‚Äù</p>
<p>And things like, you know, oftentimes we‚Äôd end up writing code where the code at the top of the file was actually the thing that happened last in the execution of it. You know, basic stuff like that, just because that‚Äôs how the RxJS was kind of telling us to do it or kind of guiding us and how we had to initialize things.</p>
<p>But that was one of the key things ‚Äî we moved to a plugin architecture. We went to a very basic ‚Äî we‚Äôve got no kind of RxJS-style stream processing plugin. It‚Äôs just all very simple JavaScript with async iterables, and we just pass a waterfall of messages down through plugins. And it‚Äôs so much better. And we can take out a plugin if we need to, and we can unit test a plugin, and we can write integration tests and mock out plugins up and down. And we‚Äôre about to launch that, and that‚Äôs just such a game changer.</p>
<p>And then interestingly, tying back to LLMs, we ended up here because with the first implementation we found it hard as developers to understand the code. We‚Äôd run the LLMs ‚Äî they were hopeless. They just could not hold the state of this dynamic, crazy, multi-subject stream system in their head.</p>

              </div>


            <div>
              
              <p>Context was everywhere, right? Like it was all ‚Äî it was here, it was there.</p>
            </div>


            <div>
              
              <p>Yeah. Even if you ‚Äî I would do things like take the whole file. I was like, copying and pasting files into ChatGPT Pro being like, ‚ÄúYou have ‚Äî you definitely have all the context here. Fix this problem.‚Äù And they couldn‚Äôt solve the problem.</p>
            </div>


            <div>
              
              <p>Fix it.</p>
            </div>


            <div>
<p>And part of the problem was that complexity. I mean, not having the ability to test things in isolation then meant we couldn‚Äôt have a kind of TDD loop, whether it was with the human or with an agent. And so ‚Äî and because we couldn‚Äôt use agents to add features to this platform, to the core of the platform, it was slowing us down.</p>
<p>And so that‚Äôs when we really started to use coding agents ‚Äî Claude Code, Codex ‚Äî like really properly and hard. We were like ‚Äî I spent like two weeks just in Claude Code and Codex, and the mission was: if I can get the coding agent to write the new version of this ‚Äî it was kind of not even a refactor, it had to be rewritten, start from scratch, first principles ‚Äî then it will, by virtue of it writing it, understand it. And then I‚Äôll be able to use coding agents to add features.</p>
<p>And I started with literally the API docs for our public API, because I didn‚Äôt want to change that, and the API docs of all of the providers and models we implement with ‚Äî like the speech-to-text and text-to-speech model provider endpoints ‚Äî and just some ideas about, ‚ÄúI think we should just use a simple waterfall pipe, like pass messages through the plugins.‚Äù</p>
<p>And that experience was really interesting because it felt like molding clay. Because I did care about ‚Äî I really cared about how the code looked, because I wanted humans as well as ‚Äî the agents aren‚Äôt quite good enough to build this whole thing from a prompt, but I think they will be in a year or two, right? But it did an okay job, and it needed a lot of reprompting ‚Äî ‚Äúrefactor this, re-architect this‚Äù ‚Äî but it felt like clay in one sense because, and you mentioned this earlier, you can just write some code and even if it‚Äôs wrong, you‚Äôve kind of learned some experience.</p>

              </div>


            <div>
              
              <p>Yeah.</p>
            </div>


            <div>
              
              <p>I was able to just say, ‚ÄúWrite this whole plugin architecture and do it,‚Äù and it would do it, and I‚Äôd be like, ‚ÄúOh, that seems a bit wrong, that‚Äôs hard to understand.‚Äù I was like, ‚ÄúWrite it again like this. Write it again like this.‚Äù And I suddenly got that experience of throwing away code because it hadn‚Äôt taken me weeks and weeks to write this code.</p>
            </div>


            <div>
              
              <p>It had taken you 10 minutes.</p>
            </div>


            <div>
              
              <p>And I was there, just threw it away. And you still have your chat session too, so even if you had to scroll back up a little bit, or maybe even copy that out to a file for long-term memory if you needed to, you still have that there as a reference point.</p>
            </div>


            <div>
              
              <p>Yeah. I find myself doing similar things, which is like just trust the model, throw it away and do it again if you need to. Learn the mistake, go down the wrong road for the learning, and make the prompt better.</p>
            </div>


            <div>
<p>And it did a terrific job. And then the bit that really got it over the finish line was then I said ‚Äî I gave it this script that we used to have to do manually to test our voice agent. You know, it‚Äôs like: connect to the voice agent, say this to the voice agent, tell it to tell you a long story, now interrupt the story, you shouldn‚Äôt hear any leftover audio from the long story ‚Äî like all these things, there‚Äôs like 20 different tests you had to do.</p>
<p>I gave it that script and I was like, ‚ÄúWrite the test suite for all of these tests.‚Äù And then it did. And I gave it all these bugs we had in our backlog. I was like, ‚ÄúWrite tests for this.‚Äù And I just started doing TDD on our backlog, and it was great.</p>
<p>Then I was like, ‚ÄúWrite a bunch ‚Äî‚Äù I did like a chaos monkey thing. I was like, ‚ÄúWrite a bunch of tests for like crazy stuff the users could do with the API.‚Äù</p>

              </div>


            <div>
              
              <p>Yes.</p>
            </div>


            <div>
<p>Found a bunch of bugs and issues, security issues. And then it kind of ‚Äî it got it working, got a bunch of unit tests. And I was still having to kind of do a bit of manual testing. And then one day I was like, you know what, I really want ‚Äî no one‚Äôs made an integration test thing for voice agents. There are a few observation platforms, observability platforms and eval platforms.</p>
<p>So I was like, I just wanted to simulate conversations. And it‚Äôs so ‚Äî that‚Äôs part of the magic, is trying something that you‚Äôre like, ‚ÄúThis is a pain in the ass to build,‚Äù or like, ‚ÄúHow is this even going to work?‚Äù Well, I just got it to build it.</p>
<p>And I recorded some WAV files of me saying things, and I gave it to them. I was like, ‚ÄúMake an integration test suite for this and feed the WAV files like you‚Äôre having a conversation, and check the transcripts you get back.‚Äù Wow. And it did a great job. And then it was actually able to fully simulate those conversations and do all the tests.</p>
<p>And then that ‚Äî I mean, we‚Äôve got these practices like TDD which are going to hold value, right? It was so valuable for the model, for the agent, to be running the test, fixing the test, running the test, fixing the test. And that feels a bit like magic when you get that working.</p>

              </div>


            <div>
<p>So much to cover in this journey. I‚Äôm so glad we had this conversation. I kind of feel like a good place to begin the end ‚Äî not actually end ‚Äî is back to this idea that is on your about page.</p>
<p>And I just got a reMarkable, because I love to write and I really hate paper, because this thing has Linux on it. And I wrote an API that I now API to my reMarkable Pro tablet. So amazing. I‚Äôm loving this.</p>

              </div>


            <div>
              
              <p>Behind me?</p>
            </div>


            <div>
              
              <p>So you can be able to Claude Code or Codex to your tablet?</p>
            </div>


            <div>
              
              <p>That‚Äôs next.</p>
            </div>


            <div>
<p>I just got it. I just got it. So like, that‚Äôs the next thing. I‚Äôm going to have this ‚Äî it‚Äôs a little playground for me, basically. But it‚Äôs real time. So if you see me looking over here writing ‚Äî audience, or even you Damien ‚Äî I‚Äôm not not paying attention. I‚Äôm writing things down.</p>
<p>And the one thing I wrote down earlier from your about page was ‚Äúthe era of the small giant,‚Äù which you alluded to, but you didn‚Äôt say those exact words. And the reason why I think it might be a good place to begin to end is I want to ‚Äî I think you might be able to encourage the single developer that maybe in the last couple of months they‚Äôve just begun to touch and not resist falling into this gravity hole, or however we describe this resistance we‚Äôve had as developers, loving to read our own code and code review and all the things as humans, and now to not resist as much, or if at all, and just trust the model.</p>
<p>To give them this word of encouragement towards, ‚ÄúHey, you‚Äôre a single developer,‚Äù and in your case, Damien, you don‚Äôt need a DevOps. It‚Äôs not that they‚Äôre not valuable or useful, but you chose a model, a way to develop your application, solve your problem, that didn‚Äôt require a DevOps team. Give them that encouragement. What does it mean to be in this era of the small giant?</p>

              </div>


            <div>
<p>[<a href="#t=80:41">80:41</a>] I think the hardest thing is our own mindset, right? I just found this with coding agents. You start off putting in things where you kind of have an idea, you know what to expect out of it. And then you start just putting in stuff that just seems a bit ridiculous and ambitious. And oftentimes it fails, but more and more it‚Äôs working. That‚Äôs a very magical feeling, and it‚Äôs a very revealing kind of experience.</p>
<p>And so I think we can all be more ambitious now. I think we all ‚Äî and especially as engineers, we know how the whole thing works, right? There is a lot of power everyone‚Äôs been given with vibe coding. Being able to vibe code ‚Äî there are a lot of security issues I think will be solved over time ‚Äî but as engineers, we have the knowledge to be able to take things fully through, deploy things, scale them, fix the issues that the LLMs can still get stuck on.</p>
<p>But we can do so much more now. We can be so much more ambitious now. And I think the thing that everyone should ‚Äî every engineer should be doing now is not only trying out Claude Code and Codex and doing something new and fun. I mean, the great thing is it‚Äôs so low risk. It‚Äôs so easy to do that you can build something ridiculous and fun that you‚Äôve always wanted to do.</p>

              </div>


            <div>
              
              <p>Yeah.</p>
            </div>


            <div>
<p>You can just ‚Äî and you can build something for a friend, for your wife. And that‚Äôs really exciting.</p>
<p>And I think this Ralph Wiggum thing ‚Äî very kind of basic idea ‚Äî is give a spec.md, todo.md, just an ambitious task or a long list of tasks in a markdown file, and you run a shell script. And all it does is it just says to Claude Code, ‚ÄúDo the next bit of work. When there‚Äôs no more work to do, return complete.‚Äù And the shell script just greps for ‚Äúcomplete,‚Äù and if it hasn‚Äôt seen that word in some XML tags, ‚Äúcomplete,‚Äù it just calls Claude Code again.</p>
<p>And like many of these things, it seems like a terrible idea, it seems ridiculous, but it is also incredible what it can do. And so I think that‚Äôs probably ‚Äî to feel what the future is going to be like, I feel like you write down something very ambitious in a markdown file, or transcribe an idea you have that you‚Äôve been thinking about for a while, and you set a Ralph Wiggum script off on it, and you just go for a long walk or go and have lunch. And when you come back ‚Äî I mean, it‚Äôs a very exciting feeling.</p>
<p>And as a developer, it‚Äôs very fun because then you get to go through all this code and be like, ‚ÄúWhy did it do it?‚Äù And you‚Äôre like, ‚ÄúOh, that was pretty smart. But I didn‚Äôt like that. Okay, that was quite a good idea. It messed up this bit.‚Äù But that‚Äôs ‚Äî I just feel like that‚Äôs a very, very exciting experience.</p>

              </div>


            <div>
              
              <p>Very cool. I definitely agree with that. I‚Äôm looking forward to writing that todo.md or spec.md and just going for that walk. Because I haven‚Äôt done it yet. I‚Äôve only peaked at some of the videos and some of the demos, but I haven‚Äôt tried the Ralph Wiggum loop yet.</p>
            </div>


            <div>
              
              <p>I‚Äôm gonna post on X a one-liner as well, because I think you can just then copy and paste the thing.</p>
            </div>


            <div>
<p>There‚Äôs their blog post to read, yeah.</p>
<p>Well, I feel like with everything, I want to make it more ceremonious. Because I want to ‚Äî it‚Äôs not because it needs to be, because I want to know ‚Äî I want to give myself space to think of something that I think will be challenging for me, even, you know? And then give it to the thing and go away, like you said, and come back happy.</p>
<p>I want to save space to do that when I can give it full mind share, versus the incremental 20 minutes or 10 minutes or whatever it might be that I have available to give it. I kind of want to give it a bit more ceremony, not because it deserves it, because I want to actually do it for myself.</p>
<p>So I‚Äôm just in this constant learning scenario. It‚Äôs a pretty wild era to be a developer and to be an enabled developer. These non-technical folks that may get introduced to a terminal-like thing that‚Äôs basically just Claude in a directory, really, and ask questions and get a just-in-time interface managed to them only ‚Äî that‚Äôs a really, really, really cool world to be in.</p>
<p>And it doesn‚Äôt mean that software goes away. It just means there‚Äôs gonna be a heck of a lot more of it out there. And I do concur that maybe code doesn‚Äôt matter anymore. Maybe it won‚Äôt in a year. Maybe it won‚Äôt in six weeks. I don‚Äôt know how many weeks it‚Äôll take.</p>
<p>Let‚Äôs truly aim with this. What‚Äôs over the horizon for you? What‚Äôs over the horizon for Layercode? What is coming?</p>

              </div>


            <div>
              
              <p>So the show release ‚Äî next Wednesday you‚Äôve got a week, given that horizon. And no one‚Äôs listening. It‚Äôs a week from now.</p>
            </div>


            <div>
              
              <p>What‚Äôs on the horizon for you that you can give us a peek at? Is there anything?</p>
            </div>


            <div>
<p>We are working really hard to bring down the cost of voice agents. There is a magic number of one dollar an hour for running a voice agent, where suddenly a huge, huge number of use cases open up ‚Äî whether it‚Äôs consumer applications, gaming. There are so many places where voice AI will be super valuable, super fun, and isn‚Äôt implemented yet.</p>
<p>And with the choices we made being on Cloudflare, with the system we‚Äôve built, we‚Äôre going to be able to bring out the lowest cost platform. I‚Äôm very excited for that.</p>
<p>And most of all, very excited just to see voice AI everywhere. Voice AI ‚Äî voice is just such a wonderful interface, right? I find myself dictating all the time to Claude Code, and you can kind of get out your thoughts so much better. And I‚Äôm excited to see how many applications we can enable adding voice AI into their application.</p>
<p>And then we get an insight into the future of voice AI as well, with the companies that are building ‚Äî a lot of them startups ‚Äî and they‚Äôre building some crazy, crazy new things with voice AI on our platform. So there‚Äôs going to be some amazing stuff with voice coming out this year.</p>

              </div>


            <div>
              
              <p>What‚Äôs the sweet spot for Layercode right now that you can invite folks to come and try?</p>
            </div>


            <div>
              
              <p>Well, the great thing is we‚Äôve got a CLI ‚Äî single command you can run ‚Äî and you‚Äôll get a Next.js demo app all connected to the live voice agent. And you can get a voice agent up and running within a minute. So it‚Äôs super fun, worth trying. And then from that point, you can use Claude Code, Codex, and just start building from that.</p>
            </div>


            <div>
<p>Well friends, right here at the last minute of the very last question, Damien‚Äôs internet dropped off or something happened. I‚Äôm not sure. But it was a fun conversation with Damien.</p>
<p>Kind of wild to be talking to somebody 17 years later after being one of the first ‚Äî if not the first, I‚Äôm pretty sure the first ‚Äî sponsor of this podcast. What a wild world it is to be this deep in years and experience and history in software and to just still be enamored by the possibilities.</p>
<p>I hope you enjoyed today‚Äôs conversation with Damien, and we‚Äôll see you next time.</p>

              </div>

          

        </div>
      </section>

      
    </div></div>
  </div>
</body>
</html>