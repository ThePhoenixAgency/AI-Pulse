<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Smashing the state machine: the true potential of web race conditions</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
</style>
</head>
<body>
  <h1>Smashing the state machine: the true potential of web race conditions</h1>
  <div class="metadata">
    Source: PortSwigger Research | Date: 8/9/2023 8:00:00 PM | Lang: EN |
    <a href="https://portswigger.net/research/smashing-the-state-machine" target="_blank">Original Article</a>
  </div>
  <div class="content">
    <div><div> <div> <p><img alt="James Kettle" src="https://portswigger.net/content/images/profiles/callout_james_kettle_112px.png"></p>
</div> <ul> <li> <p><span></span><strong>Published: </strong>09 August 2023 at 18:00 UTC</p> </li> <li> <p><strong>Updated: </strong>18 September 2023 at 14:17 UTC</p> </li> <li> </li> </ul> <p><img src="https://portswigger.net/cms/images/f3/d4/607f-article-state-machine_article.png"><br></p><p>For too long, web race condition attacks have focused on a tiny handful of scenarios. Their true potential has been masked thanks to tricky workflows, missing tooling, and simple network jitter hiding all but the most trivial, obvious examples.
</p><p>
In this paper, I'll introduce new classes of race condition that go far beyond the limit-overrun exploits you're probably already familiar with. With these I'll exploit both multiple high-profile websites and Devise, a popular authentication framework for Rails.
</p><p>
I'll also introduce the single-packet attack; a jitter-dodging strategy that can squeeze 30 requests sent from Melbourne to Dublin into a sub-1ms execution window. This paper is accompanied by a full complement of free online labs, so you'll be able to try out your new skill set immediately.</p><p>This research paper accompanies a presentation at <a href="https://www.blackhat.com/us-23/briefings/schedule/index.html#smashing-the-state-machine-the-true-potential-of-web-race-conditions-31712" target="_blank">Black Hat USA</a>,&nbsp;<a href="https://defcon.org/html/defcon-31/dc-31-schedule.html#:~:text=Smashing%20the%20state%20machine%3A%20the%20true%20potential%20of%20web%20race%20conditions" target="_blank">DEF CON</a>&nbsp;&amp; <a href="https://nullcon.net/goa-2023/speaker-smashing-the-state-machine-the-true-potential-of-web-race-conditions" target="_blank">Nullcon</a>:</p><p></p><p>It is also available in a <a href="https://portswigger.net/kb/papers/rifmwla/racewhitepaper.pdf" target="_blank">print/download-friendly PDF</a>&nbsp;format.</p>
<h3>Outline</h3><ul>
<li><a href="#introduction">The true potential</a></li><ul><li><a href="#beyond-limit-overrun">Beyond limit-overrun</a></li><li><a href="#single-packet-attack">Single-packet attack</a></li><li><a href="#methodology">Methodology</a></li></ul><li><a href="#case-studies">Case studies</a></li><ul><li><a href="#object-masking">Object masking</a></li><li><a href="#multi-endpoint">Multi-endpoint</a></li><li><a href="#single-endpoint">Single-endpoint</a></li><li><a href="#deferred">Deferred</a></li></ul>
<li><a href="#further-research">Further research</a></li><li><a href="#defence">Defence</a></li><li><a href="#takeaways">Takeaways</a></li>
</ul>
<h3>Background</h3><h4>Race condition fundamentals</h4><p> To begin, let's recap race condition fundamentals. I'll keep this brief - if you'd prefer an in-depth introduction, check out our new <a target="_blank" href="https://portswigger.net/web-security/race-conditions">Web Security Academy topic</a>.
</p><p>Most websites handle concurrent requests using multiple threads, all reading and writing from a single, shared database. Application code is rarely crafted with concurrency risks in mind and as a result, <a href="https://portswigger.net/web-security/race-conditions">race conditions</a> plague the web. Exploits are typically limit-overrun attacks - they use synchronized requests to overcome some kind of limit, for example:</p><ul> <li>Redeeming a gift card multiple times</li> <li><a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-limit-overrun">Repeatedly applying a single discount code</a></li> <li>Rating a product multiple times</li> <li>Withdrawing or transferring cash in excess of your account balance</li> <li><a target="_blank" href="https://portswigger.net/research/cracking-recaptcha-turbo-intruder-style">Reusing a single CAPTCHA solution</a></li> <li><a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-bypassing-rate-limits">Bypassing an anti-bruteforce rate-limit</a></li></ul><p>The underlying cause of these is also similar - they all exploit the time-gap between the security check and the protected action. For example, two threads may simultaneously query a database and confirm that the <span>TOP10</span> discount code hasn't been applied to the cart, then both attempt to apply the discount, resulting in it being applied twice. You'll often find these referred to as 'time of check, time of use' (TOCTOU) flaws for this reason.
</p><p>Please note that race-conditions are not limited to a specific web-app architecture. It's easiest to reason about a multi-threaded single-database application, but more complex setups typically end up with state stored in even more places, and ORMs just hide the dangers under layers of abstraction. Single-threaded systems like NodeJS are slightly less exposed, but can still end up vulnerable.</p>
<h4>Beyond limit-overrun exploits</h4><p>I used to think race conditions were a well-understood problem. I had discovered and exploited plenty, implemented the 'last-byte sync' technique in Turbo Intruder, and used that to exploit various targets <a target="_blank" href="https://portswigger.net/research/cracking-recaptcha-turbo-intruder-style">including Google reCAPTCHA</a>. Over time, Turbo Intruder has become the de-facto tool for hunting web race conditions.
</p><p>However, there was one thing I didn't understand. A <a target="_blank" href="https://www.josipfranjkovic.com/blog/race-conditions-on-web">blog post from 2016</a> by Josip Franjković detailed four vulnerabilities, and while three of them made perfect sense to me, one didn't. In the post, Josip explained how he <span>"somehow succeeded to confirm a random email address"</span> by accident, and neither he nor Facebook's security team were able to identify the cause until two months later. The bug? Changing your Facebook email address to two different addresses simultaneously could trigger an email containing two distinct confirmation codes, one for each address: </p><p><code>/confirmemail.php?e=user@gmail.com&amp;c=13475&amp;code=84751</code></p><p>
I had never seen a finding like this before, and it confounded every attempt to visualize what might be happening server-side. One thing was for sure - this wasn't a limit-overrun.
</p><p>
Seven years later, I decided to try and figure out what happened.
</p> <h4>The true potential of web race conditions</h4><p>The true potential of race conditions can be summed up in a single sentence. Every pentester knows that multi-step sequences are a hotbed for vulnerabilities, but <span>with race conditions, everything is multi-step</span>.</p><p>
To illustrate this, let's plot the state machine for a serious vulnerability that I discovered by accident a while back. When a user logged in, they were presented with a 'role selection' page containing a range of buttons that would assign a role, and redirect to a specific application. The request flow looked something like:</p><table> <tbody> <tr><td>POST /login</td><td>302 Found</td></tr> <tr><td>GET /role</td><td>200 Found</td></tr> <tr><td>POST /role</td><td>302 Found</td></tr> <tr><td>GET /application&nbsp;</td><td>200 OK</td></tr> </tbody>
</table>
<p>In my head, the state machine for the user's role looked like this:</p><p><img src="https://portswigger.net/cms/images/53/8c/286a-article-blackhat_diagrams-01.png"><br></p><p>I attempted to elevate privileges by forcibly browsing directly from the role selection page to an application without selecting a role, but this didn't work and so I concluded that it was secure.
</p><p>However, this state machine had a mistake. I had incorrectly assumed that the <span>GET /role</span> request didn't change the application state. In actual fact, the application was initialising every session with administrator privileges, then overwriting them as soon as the browser fetched the role selection page. Here's an accurate state machine:
</p><p><img src="https://portswigger.net/cms/images/a2/67/43dd-article-blackhat_diagrams-02.png"><br></p><p>By refusing to follow the redirect to /role and skipping straight to an application, anyone could gain super-admin privileges.
</p><p>I only discovered this through extreme luck, and it took me hours of retrospective log digging to figure out the cause. This vulnerability pattern is frankly a weird one, but we can learn something valuable from the near-miss. </p>
<p>My primary mistake was the assumption that the GET request wouldn't change the application state. However, there's a second assumption that's even more common - that "requests are atomic". If we ditch this assumption too, we realize this pattern could occur <span>in the span of a single login request</span>:</p><p><img src="https://portswigger.net/cms/images/2d/23/4445-article-blackhat_diagrams-03.png"><br></p>
<p>This scenario captures the essence of 'with race conditions, everything is multi-step'. Every HTTP request may transition an application through multiple fleeting, hidden states, which I'll refer to as 'sub-states'. If you time it right, you can abuse these sub-states for unintended transitions, break business logic, and achieve high-impact exploits. Let's get started.
</p> <h3>Single-packet attack</h3>
<p>A sub-state is a short-lived state that an application transitions through while processing a single request, and exits before the request completes. Sub-states are only occupied for a brief time window - often around 1ms (0.001s). I'll refer to this time window as the 'race window'.</p><p>To discover a sub-state, you need an initial HTTP request to trigger a transition through the sub-state, and a second request that interacts with the same resource during the race window. For example, to discover the vulnerability mentioned earlier you would send a request to log in, and a second request that attempted to access the admin panel. Vulnerabilities with small race windows have historically been extremely difficult to discover thanks to network jitter. Jitter erratically delays the arrival of TCP packets, making it tricky to get multiple requests to arrive close together, even when using techniques like last-byte sync:
</p><p><img src="https://portswigger.net/cms/images/f9/1e/4365-article-blackhat_diagrams-07.png"><br></p><p>In search of a solution, I've developed the 'single-packet attack'. Using this technique, you can make 20-30 requests arrive at the server simultaneously - regardless of network jitter:</p><p><img src="https://portswigger.net/cms/images/b6/d6/9239-article-blackhat_diagrams-08.png"><br></p><p>I implemented the single-packet attack in the open-source Burp Suite extension <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder">Turbo Intruder</a>. To benchmark it, I repeatedly sent a batch of 20 requests 17,000km from Melbourne to Dublin, and measured the gap between the start-of-execution timestamp of the first and last request in each batch. I've published the benchmark scripts in <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/resources/examples/">the examples folder</a> so you can try them for yourself if you like.
</p>
<table> <tbody> <tr><th>Technique</th><th>Median spread</th><th>Standard deviation</th></tr> <tr><td>Last-byte sync</td><td>4ms</td><td>3ms</td></tr> <tr><td>Single-packet attack</td><td>1ms</td><td>0.3ms</td></tr> </tbody>
</table>
<p>By these measures, the single-packet attack is 4 to 10 times more effective. When replicating one real-world vulnerability, the single-packet attack was successful after around 30 seconds, and last-byte sync took over two hours.</p>
<p>One great side effect of this is that we've been able to launch a Web Security Academy topic containing labs with realistic race windows, without alienating users who live far away from our servers or have high-jitter connections. You can try the single-packet attack out for yourself by tackling our <a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-limit-overrun">limit-overrun lab</a> with the <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/resources/examples/race-single-packet-attack.py">single-packet-attack.py</a> Turbo Intruder template. The race-window on this lab ended up so small that exploitation is near-impossible using multiple packets. It's also available in Repeater via the new 'Send group in parallel' option in Burp Suite.
</p>
<p>Let's take a look under the hood.</p>
<h4>Developing the single-packet attack</h4>
<p>The single-packet attack was inspired by the 2020 USENIX presentation <a target="_blank" href="https://www.usenix.org/conference/usenixsecurity20/presentation/van-goethem">Timeless Timing Attacks</a>. In that presentation, they place two entire HTTP/2 requests into a single TCP packet, then look at the response order to compare the server-side processing time of the two requests:</p><p><img src="https://portswigger.net/cms/images/05/e7/9c53-article-blackhat_diagrams-13.png"></p><p>This is a novel possibility with HTTP/2 because it allows HTTP requests to be sent over a single connection concurrently, whereas in HTTP/1.1 they have to be sequential.</p>
<p>The use of a single TCP packet completely eliminates the effect of network jitter, so this clearly has potential for race condition attacks too. However, two requests isn't enough for a reliable race attack thanks to server-side jitter - variations in the application's request-processing time caused by uncontrollable variables like CPU contention.</p>
<p>I spotted an opportunity to adapt a trick from the HTTP/1.1 'last-byte sync' technique. Since servers only process a request once they regard it as complete, maybe by withholding a tiny fragment from each request we could pre-send the bulk of the data, then 'complete' 20-30 requests with a single TCP packet:</p>
<p><img src="https://portswigger.net/cms/images/af/9a/d56c-article-blackhat_diagrams-14.png"><br></p>
<p>After a few weeks of experimenting, I'd built an implementation that worked on all tested HTTP/2 servers.</p>
<h4>Rolling your own implementation
</h4><p>This concept is honestly pretty obvious, and after implementing it I discovered someone else had the same idea <a target="_blank" href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/47110/master_Papli_Kaspar_2020.pdf">back in 2020</a>, but nobody noticed at the time and their algorithm &amp; implementation didn't receive the polish, testing and integration essential to prove its true value. The reason I'm so excited about the single-packet attack is that it's powerful, universal, and trivial. Even after spending months refining it to work on all major webservers the algorithm is still so simple it fits on a single page, and so easy to implement that I expect it to end up in all major web testing tools.</p><p>The primary reason it's so easy to implement is that thanks to some creative abuse of <a target="_blank" href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle's algorithm</a>, it doesn't require a custom TCP or TLS stack. You can just pick an HTTP/2 library to hook into (trust me, coding your own is not much fun), and apply the following steps:</p><p>First, pre-send the bulk of each request:</p><ul><li>If the request has no body, send all the headers, but don't set the END_STREAM flag. Withhold an empty data frame with END_STREAM set.</li><li>If the request has a body, send the headers and all the body data except the final byte. Withhold a data frame containing the final byte.</li></ul><p>You might be tempted to send the full body and rely on not sending END_STREAM, but this will break on certain HTTP/2 server implementations that use the content-length header to decide when a message is complete, as opposed to waiting for END_STREAM.</p><p>Next, prepare to send the final frames:</p><ul><li>Wait for 100ms to ensure the initial frames have been sent.</li> <li>Ensure TCP_NODELAY is disabled - it's crucial that Nagle's algorithm batches the final frames.</li> <li>Send a ping packet to warm the local connection. If you don't do this, the OS network stack will place the first final-frame in a separate packet.
</li></ul><p>Finally, send the withheld frames. You should be able to verify that they landed in a single packet using Wireshark.</p><p>This approach worked on all dynamic endpoints on all tested servers. It doesn't work for static files on certain servers but as static files aren't relevant to race condition attacks, I haven't attempted to find a workaround for this. In Turbo Intruder, the static-file quirk results in a negative timestamp as the response is received before the request is completed. This behavior can be used as a way of testing if a file is static or not.</p><p>If you're not sure which HTTP/2 stack to build on, I think Golang's might be a good choice - I've seen that successfully extended for advanced HTTP/2 attacks in the past. If you'd like to see a reference implementation in Kotlin, feel free to use Turbo Intruder. The relevant code can be found in <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/src/SpikeEngine.kt">SpikeEngine</a> and <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/src/SpikeConnection.kt">SpikeConnection</a>.</p><h4>Adapting to the target architecture</h4><p>It's worth noting that many applications sit behind a front-end server, and these may decide to forward some requests over existing connections to the back-end, and to create fresh connections for others.
</p><p>As a result, it's important not to attribute inconsistent request timing to application behavior such as locking mechanisms that only allow a single thread to access a resource at once. Also, front-end request routing is often done on a per-connection basis, so you may be able to smooth request timing by performing server-side connection warming - sending a few inconsequential requests down your connection before performing the attack. You can try this technique out for yourself on our <a target="_blank" href="https://portswigger.net/web-security/race-conditions/lab-race-conditions-multi-endpoint">multi-endpoint lab</a>.</p>
<h3>Methodology</h3><p>Now that we've established 'everything is multi-step', and developed a technique to allow accurate request synchronization and make race conditions reliable, it's time to start hunting vulnerabilities. Classic limit-overrun vulnerabilities can be discovered using a trivial methodology: identify a limit, and try to overrun it. Discovering exploitable sub-states for more advanced attacks is not quite so simple.</p><p>Over months of testing, I've developed the following black-box methodology to help. I recommend using this approach even if you have source-code access; in my experience it's extremely challenging to identify race conditions through pure code analysis.</p><p><img src="https://portswigger.net/cms/images/2f/d3/9618-article-blackhat_diagrams-06.png"><br></p>
<h4>Predict potential collisions</h4><p>Prediction is about efficiency. Since everything is multi-step, ideally we'd test every possible combination of endpoints on the entire website. This is impractical - instead, we need to predict where vulnerabilities are likely to occur. One tempting approach is to simply try and find replicas of the vulnerabilities described in this paper later on - this is nice and easy, but you'll miss out on exciting, undiscovered variants.</p><p>To start, identify objects with security controls that you'd like to bypass. This will typically include users and sessions, plus some business-specific concepts like orders.</p><p>For each object, we then need to identify all the endpoints that either write to it, or read data from it and then use that data for something important. For example, users might be stored in a database table that is modified by registration, profile-edits, password reset initiation, and password reset completion. Also, a website's login functionality might read critical data from the users table when creating sessions.</p>
<p>A race condition vulnerability requires a 'collision' - two concurrent operations on a shared resource. We can use
three key questions to rule out endpoints that are unlikely to cause collisions. For each object and the
associated endpoints, ask:
</p>
<h5>1) How is the state stored?</h5>
<p>Data that's stored in a persistent server-side data structure is ideal for exploitation. Some endpoints store their state entirely client-side, such as password resets that work by emailing a JWT - these can be safely skipped.</p>
<p>Applications will often store some state in the user session. These are often somewhat protected against sub-states - more on that later.</p>
<h5>2) Are we editing or appending?</h5><p>Operations that edit existing data (such as changing an account's primary email address) have ample collision potential, whereas actions that simply append to existing data (such as adding an additional email address) are unlikely to be vulnerable to anything other than limit-overrun attacks.
</p>
<h5>3) What's the operation keyed on?</h5>
<p>Most endpoints operate on a specific record, which is looked up using a 'key', such as a username, password reset
token, or filename. For a successful attack, we need two operations that use the same key. For example, picture two
plausible password reset implementations:
</p><p><img src="https://portswigger.net/cms/images/2e/8d/494e-article-collision.png"><br></p><p>In the first implementation, the user's password reset token is stored in the <span>users</span> table in the database, and the supplied <span>userid</span> acts as the key. If an attacker uses two requests to trigger a reset for two different userids at the same time, two different database records will be altered so there's no potential for a collision. By identifying the key, you've identified that this attack is probably not worth attempting. </p>
<p>In the second implementation, the state is stored in the user's session, and the token-storage operation is keyed on the user's sessionid. If an attacker uses two requests to trigger a reset for two different emails at the same time, both threads will attempt to alter the same session's <span>token</span> and <span>userid</span> attributes, and the session may end up containing one user's <span>userid</span>, and a <span>token</span> that was sent to the other user.</p> <h4>Probe for clues</h4><p>Now that we've selected some high-value endpoints, it's time to probe for clues - hints that hidden sub-states exist. We don't need to cause a meaningful exploit yet - our objective at this point is simply to evoke a clue. As such, you'll want to send a large number of requests to maximize the chance of visible side-effects, and mitigate server-side jitter. Think of this as a chaos-based strategy - if we see something interesting, we'll figure out what actually happened later.</p>
<p>Prepare your blend of requests, targeting endpoints and parameters to trigger all relevant code paths. Where possible, use multiple requests to trigger each code path multiple times, with different input values.</p>
<p>Next, benchmark how the endpoints behave under normal conditions by sending your request-blend with a few seconds between each request.</p>
<p>Finally, use the single-packet attack (or last-byte sync if HTTP/2 isn't supported) to issue all the requests at once. You can do this in Turbo Intruder using the single-packet-attack template, or in Repeater using the 'Send group in parallel' option.</p><p>Analyze the results and look for clues in the form of any deviation from the benchmarked behavior. This could be a change in one or more responses, or a second-order effect like different email contents or a visible change in your session. Clues can be subtle and counterintuitive so if you skip the benchmark step, you'll miss vulnerabilities.
</p><p>Pretty much anything can be a clue, but pay close attention to the request processing time. If it's shorter than you'd expect, this can indicate that data is being passed to a separate thread, greatly increasing the chances of a vulnerability. If it's longer than you expect, that could indicate resource limits - or that the application is using locking to avoid concurrency issues. Note that PHP locks on the sessionid by default, so you need to use a separate session for every request in your batch or they'll get processed sequentially.
</p><h4>Prove the concept</h4><p>If you spot a clue, the final step is to prove the concept and turn it into a viable attack. The exact steps here will depend on the attack you're attempting, but there are a few general pointers that may be useful:</p>
<p>When you send a batch of requests, you may find that an early request pair triggers a vulnerable end-state, but later requests overwrite/invalidate it and the final state is unexploitable. In this scenario, you'll want to eliminate all unnecessary requests - two should be sufficient for exploiting most vulnerabilities. </p>
<p>Dropping to two requests will make the attack more timing-sensitive, so you may need to retry the attack multiple times or automate it. On a couple of targets I ended up writing a Turbo Intruder script to repeatedly trigger emails, retrieve them from Burp Collaborator, and extract and visit the links within. You can find an example in the <a target="_blank" href="https://github.com/PortSwigger/turbo-intruder/blob/master/resources/examples/email-link-extraction.py">email-extraction template</a>.</p>
<p>Finally, don't forget to escalate! Think of each race condition as a structural weakness, rather than an isolated vulnerability. Advanced race conditions can cause unusual and unique primitives, so the path to maximum impact isn't always obvious. For example, in one case I ended up with different endpoints on a single website disagreeing about what my email address was. During this research I personally missed out on ~$5k due to overlooking one exploit avenue until after the vulnerability was patched.
</p>
<h3>Case studies</h3> </div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'smooth' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
  </script>
</body>
</html>