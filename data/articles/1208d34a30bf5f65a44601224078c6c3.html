<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="UTF-8">
<title>ChatGPT Health : une étude pointe des problèmes dans les recommandations de consultation</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>ChatGPT Health : une étude pointe des problèmes dans les recommandations de consultation</h1>
  <div class="metadata">
    Source: Next INpact | Date: 2/26/2026 7:45:00 AM | <a href="https://next.ink/226311/chatgpt-health-une-etude-pointe-des-problemes-dans-les-recommandations-de-consultation/" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: FR
  </div>
  <div class="content">
    <div><div> <p>OpenAI a tout juste sorti ChatGPT Health qu’une équipe de chercheuses et chercheurs publient une première étude sur les d’éventuels risques associés à l’outil. L’entreprise l’a lancé il y a même pas deux mois, profitant de la <a href="https://next.ink/217866/la-fda-reduit-sa-surveillance-des-dispositifs-de-sante-portables-ou-sappuyant-sur-lia/" target="_blank" rel="noopener noreferrer">réduction</a> de la surveillance des dispositifs de santé s’appuyant sur l’IA de la Food &amp; drugs Administration (FDA, agence états-unienne responsable de la régulation concernant les médicaments et les produits alimentaires).</p> <ul>
<li> <a href="https://next.ink/217989/openai-lance-chatgpt-sante-sappuyant-sur-de-multiples-donnees-fournies-par-lutilisateur/"> OpenAI lance ChatGPT Santé s’appuyant sur de multiples données fournies par l’utilisateur </a>
</li> <li> <a href="https://next.ink/217866/la-fda-reduit-sa-surveillance-des-dispositifs-de-sante-portables-ou-sappuyant-sur-lia/"> La FDA réduit sa surveillance des dispositifs de santé portables ou s’appuyant sur l’IA </a>
</li> </ul> <p>L’entreprise prenait bien ses précautions oratoires, expliquant que «&nbsp;<em>la fonctionnalité n’a pas vocation à établir un diagnostic ni à proposer un traitement. Elle vous aide plutôt à répondre aux questions du quotidien et à comprendre des tendances dans le temps, au-delà des seuls moments de maladie, afin que vous vous sentiez mieux informé et préparé pour des échanges médicaux importants </em>». Et elle affirmait avoir évalué son système avec son benchmark santé maison, sans pour autant donner de détail sur les résultats.</p> <h3>Une très rapide publication de l’étude</h3> <p>Ce lundi 23 février, la revue Nature Medicine <a href="https://www.nature.com/articles/s41591-026-04297-7">publie</a> une première étude qui essaye d’évaluer l’outil. Le processus est excessivement rapide pour la publication d’un travail de recherche qui peut prendre parfois plus d’un an&nbsp;: sortie de ChatGPT Health le 7 janvier, expérimentations faites entre le 9 et le 11 janvier, soumission de l’article le 15 janvier et mise en ligne le 23 février. </p> <p>On imagine que la course à la publication est une des causes et on espère que la publication ne devra pas être rétractée pour une erreur d’analyse faite dans la précipitation. La revue a voulu aller tellement vite qu’elle n’a pas pris le temps d’éditer l’article et ne laisse l’accès qu’à une version non éditée du texte [<a href="https://www.nature.com/articles/s41591-026-04297-7_reference.pdf">PDF</a>].</p> <h3>ChatGPT Health recommande-t-il bien d’aller ou non consulter&nbsp;?</h3> <p>Les chercheuses et chercheurs de Mount Sinai à New York ont testé le chatbot en lui soumettant des situations de problèmes de santé et en lui demandant de les conseiller entre A/ rester à la maison B/ voir un médecin dans les prochaines semaines, C/ voir un médecin dans les 24&nbsp;-&nbsp;48&nbsp;h et D/ Aller aux urgences immédiatement. Voici un exemple&nbsp;:</p> <figure><img alt="" src="https://i0.wp.com/next.ink/wp-content/uploads/2026/02/image-151.png?ssl=1"></figure> <p>En tout, ils ont testé 60 scénarios classiques de 21 domaines cliniques différents, et ce plusieurs fois et avec des profils de patients différents (profil ethnique, genre, avec une barrière d’accès aux soins plus ou moins élevée). En tout, ils ont obtenu 960 réponses qu’ils ont ensuite analysées en comparant avec les réponses que l’outil aurait dû donner selon un consensus médical.</p> <p>Le premier point intéressant qu’ils relèvent c’est que «<em> la race, le sexe et les obstacles aux soins des patients n’ont pas eu d’effets significatifs</em>&nbsp;». Ainsi, concernant les recommandations de consultation, les chercheurs n’auraient pas trouvé de biais en fonction des différences des patients chez ChatGPT Health. </p> <p>Mais les auteurs de l’étude pointent quand même un problème de l’IA générative d’Open AI spécialisée dans les conseils en santé. Ainsi, l’outil se trompe dans 64,8 % de ses réponses concernant des problèmes bénins qui ne nécessiteraient pas consultation&nbsp;: à 54,7 % il les pousse à faire une consultation de routine et à 10 % à consulter en urgence.</p> <p>De l’autre côté du spectre, pour plus de la moitié des cas qui devraient conduire aux urgences directement, ChatGPT Health conseille seulement d’aller voir un médecin dans les 24&nbsp;-&nbsp;48&nbsp;h. Pour l’autre moitié, l’outil donne le bon conseil.</p> <p>Pour les cas de routine, ChatGPT Health aiguille plutôt bien et pour les cas de consultation rapide, il peut avoir tendance à envoyer directement aux urgences&nbsp;:</p> <figure>
<figure><img alt="" src="https://i0.wp.com/next.ink/wp-content/uploads/2026/02/image-152.png?ssl=1"></figure> <figure><img alt="" src="https://i0.wp.com/next.ink/wp-content/uploads/2026/02/image-154.png?ssl=1"></figure>
</figure> <h3>Un affichage aléatoire des messages de prévention pour les personnes suicidaires</h3> <p>Les chercheurs soulignent un comportement particulier concernant les suicides. OpenAI a mis en place une redirection vers la 988 Lifeline, l’équivalent d’un numéro vert américain pour le soutien à la santé mentale. Mais les chercheurs expliquent que «<em> les messages de prévention en cas de crise se sont déclenchés de manière imprévisible lors des présentations d’idées suicidaires, se déclenchant davantage lorsque les patients ne décrivaient aucune méthode spécifique que lorsqu’ils le faisaient</em>&nbsp;».</p> <p>«&nbsp;<em>Ce résultat était particulièrement surprenant et préoccupant</em>&nbsp;», explique la chercheuse Girish N. Nadkarni dans le <a href="https://www.mountsinai.org/about/newsroom/2026/research-identifies-blind-spots-in-ai-medical-triage">communiqué</a> de presse de l’équipe,«&nbsp;<em>nous nous attendions à une certaine variabilité, mais ce que nous avons observé allait au-delà de l’incohérence. Les alertes du système étaient inversées par rapport au risque clinique, apparaissant de manière plus fiable pour les scénarios à faible risque que pour les cas où une personne partageait son intention de se faire du mal. Dans la vie réelle, lorsqu’une personne explique précisément comment elle compte se faire du mal, cela indique un danger plus immédiat et plus grave, et non l’inverse</em>&nbsp;».</p> </div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>