<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="UTF-8">
<title>L’Inde oblige les plateformes à tatouer les contenus audiovisuels générés par IA</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>L’Inde oblige les plateformes à tatouer les contenus audiovisuels générés par IA</h1>
  <div class="metadata">
    Source: Next INpact | Date: 2/19/2026 3:11:36 PM | <a href="https://next.ink/225429/linde-oblige-les-plateformes-a-tatouer-les-contenus-audiovisuels-generes-par-ia/" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: FR
  </div>
  <div class="content">
    <div><div> <p>L’adage «&nbsp;<em>je crois ce que je vois</em>&nbsp;» est périmé du fait de l’avènement des deepfakes, qui «&nbsp;<em>constituent une menace importante pour la vie privée des individus et la société dans son ensemble</em>&nbsp;», avance le <a href="https://gazettetracker.com/g/CG-DL-E-08022025-260852" target="_blank">Deepfake Prevention and Criminalisation Act</a>.</p> <p>Cette loi indienne vise à prévenir et à criminaliser la création, la diffusion et l’utilisation de contenus synthétiques générés par IA sans consentement ou sans filigrane numérique. D’après <a href="https://techcrunch.com/2026/02/10/india-orders-social-media-platforms-to-take-down-deepfakes-faster/" target="_blank">TechCrunch</a>, les plateformes pourront se voir ordonner de les retirer dans un délai de trois heures, voire de deux heures seulement dans certains cas. Auparavant, ce délai pouvait monter à trois jours, précise <a href="https://www.liberation.fr/international/asie-pacifique/la-france-et-linde-sur-la-meme-longueur-donde-pour-reguler-lia-20260218_MI3A2VT62ZFMDNDQULDQJ2HBAM/" target="_blank">Libération</a>.</p> <p>Les plateformes et médias sociaux permettant à leurs utilisateurs de partager du contenu audiovisuel devront aussi exiger qu’ils précisent s’ils ont été générés par IA, mais également déployer des outils pour vérifier ces déclarations, veiller à ce que les deepfakes soient clairement identifiés et accompagnés de données de provenance traçables, et empêcher le partage de contenus synthétiques interdits (notamment les usurpations d’identité, images intimes non consenties et contenus liés à des crimes graves).</p> <p>Les plateformes seront tenues de déployer des «&nbsp;<em>mesures techniques raisonnables et appropriées</em>&nbsp;» pour empêcher leurs utilisateurs de créer ou de partager des contenus audio et vidéo illégaux générés de manière synthétique, précise <a href="https://www.theverge.com/ai-artificial-intelligence/877206/youtube-instagram-x-india-deepfake-detection-deadline" target="_blank">The Verge</a>.</p> <p>Les contenus générés par IA qui ne seront pas bloqués devront quant à eux intégrer des «&nbsp;<em>métadonnées permanentes ou d’autres mécanismes techniques appropriés permettant d’en déterminer la provenance</em>&nbsp;», et les doter de marquages visibles et/ou audibles pour permettre aux utilisateurs d’identifier immédiatement qu’il s’agit de contenus synthétiques.</p> <h3>Le «&nbsp;retard considérable&nbsp;» des systèmes de détection et d’étiquetage de l’IA</h3> <p>L’Inde compte un milliard d’internautes, principalement des jeunes, ce qui en fait l’un des marchés les plus importants pour les plateformes sociales, souligne The Verge, pour qui «&nbsp;<em>toute obligation imposée dans ce pays pourrait avoir un impact sur les efforts de modération des deepfakes à travers le monde, soit en améliorant la détection jusqu’à ce qu’elle soit réellement efficace, soit en obligeant les entreprises technologiques à reconnaître la nécessité de trouver de nouvelles solutions</em>&nbsp;».</p> <p>Sauf que c’est plus facile à dire qu’à faire, eu égard au «&nbsp;<em>retard considérable</em>&nbsp;» des systèmes de détection et d’étiquetage de l’IA à l’heure actuelle. La Coalition for Content Provenance and Authenticity (<a href="https://en.wikipedia.org/wiki/Content_Authenticity_Initiative" target="_blank">C2PA</a>), de la Content Authenticity Initiative (<a href="https://contentauthenticity.org/" target="_blank">CAI</a>), lancée en 2021 par Arm, la BBC, Intel, Microsoft et Adobe, insère ainsi des métadonnées détaillées dans les images, vidéos et fichiers audio au moment de leur création ou de leur modification, afin de décrire de manière invisible comment ils ont été créés ou modifiés.</p> <ul>
<li> <div> <p> <abbr> <span>Mercredi 14 février 2024 à 06h46</span> <span>14/02/2024 06h46</span> </abbr> </p> </div>
</li> </ul> <p>Mais si Facebook, Instagram, YouTube et LinkedIn ajoutent des étiquettes aux contenus signalés par le système C2PA, «&nbsp;<em>il est clair que cela ne fonctionne pas</em>&nbsp;», assène The Verge, pour qui «&nbsp;<em>ces étiquettes sont difficiles à repérer, et certains contenus synthétiques qui devraient comporter ces métadonnées passent entre les mailles du filet</em>&nbsp;».</p> <p>De plus, les plateformes de médias sociaux ne peuvent pas étiqueter correctement les contenus produits par des tiers, tels que les modèles d’IA open source ou les applications dites «&nbsp;nudify&nbsp;» qui refusent d’adopter la norme volontaire C2PA.</p> <h3>Il sera impossible pour les plateformes de respecter cette nouvelle loi</h3> <p>The Verge souligne également que «&nbsp;<em>l’interopérabilité est l’un des principaux enjeux de la norme C2PA</em>&nbsp;», mais bien que les nouvelles règles indiennes puissent encourager son adoption, «&nbsp;<em>elles sont si faciles à supprimer que certaines plateformes en ligne peuvent involontairement les effacer lors du téléchargement de fichiers </em>».</p> <p>Étant donné que les amendements précisent les mécanismes de traçabilité qui doivent être mis en œuvre «&nbsp;<em>dans la mesure où cela est techniquement possible</em>&nbsp;», les responsables à l’origine de la décision indienne sont probablement conscients que les technologies actuelles de détection et d’étiquetage par IA ne sont pas encore au point, conclut The Verge&nbsp;: «&nbsp;<em>Les organisations qui soutiennent la C2PA affirment depuis longtemps que le système fonctionnera si suffisamment de personnes l’utilisent. C’est donc l’occasion de le prouver</em>&nbsp;».</p> <p>Interrogé par Libé, Pratik Sinha, cofondateur du média spécialisé dans le fact-checking Alt News, avance qu’il sera «<em> impossible pour les plateformes de respecter cette nouvelle loi. Nous sommes le pays le plus peuplé au monde et chaque jour, des milliards de posts sont générés </em>». Il s’interroge aussi sur les risques de censure politique&nbsp;:</p> <blockquote>
<p>«&nbsp;<em>Qui détermine si un post-généré par IA est illégal ou non&nbsp;? Normalement, en Inde, cela devrait relever d’une décision de justice, mais dans les faits, c’est la police qui s’en occupe. Cette loi a été votée pour faciliter la suppression des contenus qui critiquent le gouvernement, alors que les militants proches du pouvoir peuvent poster des fausses informations sans être inquiétés.</em>&nbsp;»</p>
</blockquote> <ul>
<li> <div> <p> <abbr> <span>Mardi 02 décembre 2025 à 16h58</span> <span>02/12/2025 16h58</span> </abbr> </p> </div>
</li> </ul> </div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>