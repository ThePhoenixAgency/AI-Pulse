<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Introducing the Palmyra-mini family: Powerful, lightweight, and ready to reason!</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Introducing the Palmyra-mini family: Powerful, lightweight, and ready to reason!</h1>
  <div class="metadata">
    Source: Hugging Face Blog | Date: 9/11/2025 8:04:44 PM | <a href="https://huggingface.co/blog/Writer/announcing-palmyra-mini" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div> <p><a href="https://huggingface.co/blog"> Back to Articles</a></p> <div><div> <p><span><span><a href="https://huggingface.co/rakshith-writer"><img alt="Rakshith's avatar" src="https://huggingface.co/avatars/9623d7ffc10260dfeb290758c5a165ae.svg"></a> </span> </span></p> </div><div> <p><span><span><a href="https://huggingface.co/tperes"><img alt="Tom Peres's avatar" src="https://huggingface.co/avatars/8d7579e0acf5dc6aeed29e782013af2e.svg"></a> </span> </span></p> </div></div> <p> <img src="https://huggingface.co/Writer/palmyra-mini-thinking-b/resolve/main/logo-mini-b%20benchmark-performance.png?download=true">
</p> <div><nav><ul><li><a href="#benchmark-highlights">Benchmark Highlights:</a> <ul></ul> </li><li><a href="#benchmark-note">Benchmark Note:</a> <ul></ul> </li><li><a href="#footnotes">Footnotes:</a> <ul></ul> </li></ul></nav></div><p>The team at WRITER is thrilled to announce the release of three new open models in the Palmyra-mini family. These models are designed to be powerful, lightweight, and highly performant for their size (1.5B to 1.7B), making them ideal for a wide range of applications with efficient inference. </p>
<ul>
<li><a href="https://huggingface.co/Writer/palmyra-mini">palmyra-mini</a>: A powerful, lightweight non-thinking base model.</li>
<li><a href="https://huggingface.co/Writer/palmyra-mini-thinking-a">palmyra-mini-thinking-a</a>: A specialized variant optimized for complex reasoning and logic.</li>
<li><a href="https://huggingface.co/Writer/palmyra-mini-thinking-b">palmyra-mini-thinking-b</a>: Another specialized variant that excels at mathematical equations and reasoning.</li>
</ul>
<p>The "thinking" models have been trained with a Chain of Thought (CoT) approach, which improves their reasoning abilities. We're excited to see what the community will build with these new models! </p>
<p>GGUF and MLX quantizations are also available for your convenience:</p>
<ul>
<li><p><a href="https://huggingface.co/Writer/palmyra-mini-GGUF">palmyra-mini-GGUF</a></p>
</li>
<li><p><a href="https://huggingface.co/Writer/palmyra-mini-thinking-a-GGUF">palmyra-mini-thinking-a-GGUF</a></p>
</li>
<li><p><a href="https://huggingface.co/Writer/palmyra-mini-thinking-b-GGUF">palmyra-mini-thinking-b-GGUF</a></p>
</li>
<li><p><a href="https://huggingface.co/Writer/palmyra-mini-GGUF">palmyra-mini-MLX-BF16</a></p>
</li>
<li><p><a href="https://huggingface.co/Writer/palmyra-mini-thinking-a-MLX-BF16">palmyra-mini-thinking-a-MLX-BF16</a></p>
</li>
<li><p><a href="https://huggingface.co/Writer/palmyra-mini-thinking-b-MLX-BF16">palmyra-mini-thinking-b-MLX-BF16</a></p>
</li>
</ul>
<h2> <a href="#benchmark-highlights"> <span></span> </a> <span> Benchmark Highlights: </span>
</h2>
<ul>
<li><p>palmyra-mini: Our non-reasoning improved base model, delivering a score of 52.6% on Big Bench Hard (get-answer)(exact_match), making it a fantastic all-rounder for a wide variety of generative tasks.</p>
</li>
<li><p>palmyra-mini-thinking-a: This variant is your go-to for complex logical challenges. Trained with a Chain of Thought (CoT) approach, it achieves an impressive 82.87% on GSM8K (strict match), demonstrating its powerful reasoning capabilities. It has the highest overall average score on benchmarks relative to other models in the release. </p>
</li>
<li><p>palmyra-mini-thinking-b: Pushing the boundaries of problem-solving, this model scores a solid 92.5% on AMC23. It's a great choice when you need a model that can "think" its way through demanding tasks. This has the highest average benchmark scores in the benchmarks AIME24,AIME25, GPQA, HMMT25, HLE, MMLU_PRO,MATH500, LCB relative to the other models in the release.</p>
</li>
</ul>
<h2> <a href="#benchmark-note"> <span></span> </a> <span> Benchmark Note: </span>
</h2>
<p>We're releasing both pass@1(avg-of-1) and pass@1(avg-of-64) results.
Benchmarking methodology (sampling parameters: temperature 0.6, top_p 0.95):
Pass@1(avg-of-1) scores:</p>
<p>GSM8K through MBPP: collected using lm_eval framework.
AIME24 through HMMT25: collected using lighteval framework.</p>
<p>Pass@1(avg-of-64) scores: collected using nemoskills framework.</p>
<h2> <a href="#footnotes"> <span></span> </a> <span> Footnotes: </span>
</h2>
<p>Since all the base models are Qwen architecture the inference should be runnable on popular inference frameworks such as vLLM, SGLang, TRTLLM, TGI.</p>
<p>For palmyra-thinking-b the base model was <a href="https://huggingface.co/nvidia/OpenReasoning-Nemotron-1.5B">https://huggingface.co/nvidia/OpenReasoning-Nemotron-1.5B</a>. We ran RL fine tuning and observed that it's capable of improving performance. While Reinforcement learning improved single-shot accuracy (pass@1), it reduced sampling diversity, leading to a drop in majority@64 performance compared to the SFT base model. This highlights a trade-off between accuracy and diversity, and we believe transparency around these findings will spark further research along mode collapse, small model performance and other areas. </p>
<p>Through this work, we've tried to push the boundaries of what's achievable with small parameter models, and we're excited to see how the community will continue advancing inference efficiency without sacrificing performance quality. </p>
</div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="history.back()" title="Retour">←</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>