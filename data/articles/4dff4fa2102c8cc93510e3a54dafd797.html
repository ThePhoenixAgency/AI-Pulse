<!DOCTYPE html><html lang="fr"><head>
<meta charset="UTF-8">
<title>Finalement, le gouvernement prévoit de donner la régulation de l’IA à la CNIL</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
</style>
</head>
<body>
  <h1>Finalement, le gouvernement prévoit de donner la régulation de l’IA à la CNIL</h1>
  <div class="metadata">
    Source: Next INpact | Date: 2/13/2026 3:44:31 PM | <a href="https://next.ink/224252/finalement-le-gouvernement-prevoit-de-donner-la-regulation-de-lia-a-la-cnil/" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: FR
  </div>
  <div class="content"><p>La CNIL semble avoir gagné la bataille d'influence dans la régulation de l'IA. En tout cas, c'est le sens que prend un amendement déposé par le gouvernement dans le projet de loi qui prévoit, entre autres, d'adapter le droit français à l'AI Act. Ce projet de loi « portant diverses dispositions d'adaptation au droit de l'Union européenne » a été déposé au Sénat en novembre dernier par le gouvernement en engageant la procédure accélérée. Le législateur doit notamment décider quelle institution sera chargée, en France, de la régulation de l'intelligence artificielle prévue par le règlement européen. Intense bataille entre potentiels régulateurs Depuis 2023, et donc avant même le vote du texte européen, la CNIL essaye de faire sienne cette place de régulateur de la technologie, devenue centrale politiquement et économiquement ces dernières années. Après avoir écarté les divers comités créés par l'exécutif ces dernières années, la CNIL avait obtenu l'appui de certains députés en 2024, à condition qu'elle se transforme. L'ARCOM et le ministère de l'Économie, via la DGCCRF, essayaient aussi de prendre l'ascendant sur ce dossier. Les trois organisations avaient mis en avant, en juin 2024, la signature d'une « convention de coopération » entre elles pour la mise en œuvre du règlement européen sur les services numériques. En septembre dernier, Bercy semblait avoir pris l'ascendant et communiquait pour assurer que «&nbsp;la DGCCRF, experte de la surveillance de marché et accomplie dans la collaboration avec d'autres régulateurs, ainsi que la DGE, représentante de la France au Comité européen de l'IA, coordonneraient les actions des autorités&nbsp;». Le ministère de l'Économie diffusait aussi un «&nbsp;schéma de gouvernance des autorités de surveillance de marché&nbsp;» sur lequel la DGCCRF, avec la DGE, était clairement aux manettes&nbsp;: Mais finalement, le gouvernement a choisi la CNIL comme autorité chargée d'assurer la mise en œuvre de l'AI Act sur le sol français. De fait, le texte initial du projet de loi présenté au Sénat n'avait pas tranché la question. Selon nos confrères de Contexte, le Conseil d’État estimait que le schéma prévu par Bercy risquait «&nbsp;d’enfreindre la règle du "non bis in idem"&nbsp;», c'est-à-dire l'impossibilité de double sanction. En effet, selon l'institution, le plan prévu par le ministère de l'Économie risquait de mettre en place des doubles affectations d’autorités sur certaines catégories d’IA. Le gouvernement a donc dû revoir sa copie. La CNIL ramasse la mise Finalement, l'amendement au texte qu'il a déposé ce jeudi 12 février veut modifier la loi Informatique et libertés de 1978 pour donner de nouvelles compétences à la CNIL, qui devra « assurer la mise en œuvre effective&nbsp;» de l'AI Act. L'autorité aura aussi à charge le contrôle des pratiques d’intelligence artificielle interdites. Sur la notation sociale, elle partagera cette charge de contrôle avec la DGCCRF. Elle se voit aussi confier « le contrôle du respect des obligations de transparence applicables à certains systèmes d’intelligence artificielle, notamment ceux mettant en œuvre des dispositifs de reconnaissance des émotions ou de catégorisation biométrique&nbsp;», comme l'explique le gouvernement dans l'objet de son amendement. La CNIL est également désignée comme autorité compétente à l’égard des obligations de transparence de certains systèmes d’intelligence artificielle au sens de l’article 50 du même règlement, qui obligera les contenus générés par IA à être labellisés comme tels. [Récap] Nous avons découvert des milliers de sites d’info générés par IA&nbsp;: tous nos articles Elle est désignée comme organisme notifié qui doit intervenir pour « l’évaluation du système de gestion de la qualité et de l’évaluation de la documentation technique&nbsp;» des systèmes d’IA considérés comme à « haut risque&nbsp;» par le règlement européen concernant les systèmes d’identification biométrique, de décisions relatives au travail (emploi, recrutement...) et «&nbsp;certaines applications relevant de la répression, des contrôles aux frontières ou de la gestion des migrations ». Même chose concernant les systèmes à haut risque dans l'éducation, mais la DGCCRF récupère la compétence sur les systèmes concernant la formation professionnelle. Dans ce texte, l'Arcom ne retrouve plus qu'un rôle de consultation lorsque les systèmes d’intelligence artificielle concernés présentent un lien direct avec les processus démocratiques. « Il y a quelques incertitudes sur les périmètres respectifs des uns et des autres », a quand même estimé la rapporteure du texte Marie-Lise Housseau (UC) auprès de nos confrères de Contexte, alertée par l'Arcom. La sénatrice pourrait proposer quelques modifications pour éclaircir les choses. Le Sénat doit examiner le texte en séance publique lundi 16 février.</p></div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
  </script>

</body></html>