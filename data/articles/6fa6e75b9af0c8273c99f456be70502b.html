<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Police arresting 1,000 paedophile suspects a month across UK</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Police arresting 1,000 paedophile suspects a month across UK</h1>
  <div class="metadata">
    Source: The Guardian World | Date: 2/17/2026 7:33:49 PM | <a href="https://www.theguardian.com/uk-news/2026/feb/17/police-arresting-1000-paedophile-suspects-a-month-across-uk" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div><p>Child sexual abuse in the UK is soaring, police have said, with 1,000 paedophile suspects being arrested each month and the number of children being rescued from harm rising by 50% in the last five years.</p><p>The National <a href="https://www.theguardian.com/uk/ukcrime">Crime</a> Agency said the growth in offending across the UK was driven by technology and linked to the radicalisation of offenders in online forums, encouraging people to view images of child sexual abuse by reassuring them it was normal.</p><p>Most contact with children happened on mainstream social media platforms, with algorithms pushing paedophilic material to people who have shown a previous interest in it.</p><p>The significant increase in every measure “really worries us”, said Rob Jones, the NCA’s director general of operations.</p><p>Leads about people interested in sexually abusing children had risen tenfold in a decade, he said, with 1,200 children a month being safeguarded.</p><p>Jones added that the majority of images of abuse were “known images” that had been in circulation for some time, and that tech companies had the ability to stop them.</p><p>“The threat is getting worse, despite our best efforts… There is more access to children online,” he said.</p><p>“Children are more reliant on the internet, and what we see from offenders is a move to collaborate and coordinate activities on the dark web, but to use the open web as a discovery platform to identify and abuse vulnerable children.”</p><p>Police were “racing” to get to the worst offenders, who were in positions of trust or had access to children and made up 15% of more than 33,000 leads last year.</p><p>Jones said potential offenders were introduced to material by algorithms, and forums told people interested in the sexual abuse of children that they were not criminals.</p><p>“I think, societally, things have changed … If you go into an online forum and you’ve got a sexual interest in children, you’ll be told that you are normal.</p><p>“Because of the way algorithms drive people with like-minded interests together, because of the way people operate, they will be told that what they are doing is normal, it will be rationalised, it will be normalised, and then you will see almost a radicalisation process where their behaviour will be encouraged, and they will be told that everything they’ve been told, that’s told them it’s wrong throughout their life, it’s the opposite.”</p><p>Last week a former London nursery worker, Vincent Chan, was jailed for 18 years for child sex offences, including sexually abusing toddlers in his care, and offences at a primary school where he was previously employed.</p><p>On Tuesday, Joao-Carlos Jardim Dos Santos Teixeira, 26, from Eastbourne, was jailed for 11 years for sharing and discussing child sexual abuse material, including AI-generated images.</p><p>Jones said offenders were “determined” and had adapted to avoid detection, but that technology companies could and should do more. “Over the last five years, we have continually said that the use of technology is increasing the opportunities for child sex offenders, and the risk to children and young people,” he said. “We have seen some improvements by tech companies, but it’s nowhere near what’s actually needed to protect children in this day and age.”</p><p>There is barely concealed annoyance in UK law enforcement at the perceived lack of action by tech companies while children suffer, tempered by the fact that their cooperation is vital for the ten of thousands of leads officers get every year.</p><p>Jones said images already circulating, which represent the majority of such abuse, could be identified by tech companies and taken down. “They could stop a lot more. So if you have an unencrypted environment where AI is used to detect known images, that is the low-hanging fruit that we should expect is no longer available on the open web, and that is something that we’ve talked about a lot for many, many years: <a href="https://www.theguardian.com/society/2018/jun/21/internet-companies-can-should-screen-out-child-abuse-images">that technology is available,</a> it is detectable, it can be taken down. So we should no longer be finding known images.”</p><p>The Online Safety Act, while a help, was not enough, police said.</p><p>“You can’t have a world where you don’t have protective measures in place for children, and that is the challenge with the open web,” Jones said. “At the moment, there are not enough protective measures in place, although they are coming through and moving towards a regulated environment, that’s not coming in place quickly enough to contain this.”</p><p>Becky Riggs, the acting chief constable for Staffordshire police who is the National Police Chiefs’ Council lead for child protection and abuse investigation,<strong> </strong>said some platforms were better than others, and the number of referrals was rising despite the growth of end-to-end encryption, which means activity cannot be monitored.</p><p>“Every victim that experiences this type of crime, it has unimaginable consequences, which are often lifelong and, sadly in the online world, are often relived as well because the images are shared across a network of individuals.”</p><p>Jones said a proposed ban on under 16s using social media was “not a silver bullet” and the NCA said the livestreamed sexual abuse of children could be bought online and on demand for as little as £20.</p><p>Police said there was no typical offender and previously it had been estimated that <a href="https://www.nationalcrimeagency.gov.uk/threats-2025/nsa-csa-2025">up to 840,000 adults in the UK</a> had a sexual interest in children.</p></div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>