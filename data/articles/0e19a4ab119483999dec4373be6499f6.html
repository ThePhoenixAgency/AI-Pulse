<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>GitHub - al1-nasir/codegraph-cli: AI-powered code intelligence CLI with multi-agent analysis, impact graphs, and conversational coding.</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>GitHub - al1-nasir/codegraph-cli: AI-powered code intelligence CLI with multi-agent analysis, impact graphs, and conversational coding.</h1>
  <div class="metadata">
    Source: Hacker News Show | Date: 2/17/2026 4:39:54 AM | <a href="https://github.com/al1-nasir/codegraph-cli" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><h1>CodeGraph CLI</h1><a href="#codegraph-cli"></a></div>
<p><strong>Code intelligence from the terminal. Semantic search, impact analysis, multi-agent code generation, and conversational coding — all backed by your choice of LLM.</strong></p>
<p><a href="/al1-nasir/codegraph-cli/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/08cef40a9105b6526ca22088bc514fbfdbc9aac1ddbf8d4e6c750e3a88a44dca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667" alt="License: MIT"></a>
<a href="https://www.python.org"><img src="https://camo.githubusercontent.com/0bc512e1bdf1845306c37fdcd12588f541a0931ad3ffa8a40f329a534f2c886d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e392532422d626c75652e737667" alt="Python 3.9+"></a>
<a href="https://github.com/al1-nasir/codegraph-cli"><img src="https://camo.githubusercontent.com/76b7d4da5dcc20cd69b65e4f3888f79333a0f0fd4da7ce2beb02b1f84162a0a6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d322e312e322d626c75652e737667" alt="Version"></a>
<a href="https://github.com/al1-nasir/codegraph-cli/actions/workflows/ci.yml"><img src="https://github.com/al1-nasir/codegraph-cli/actions/workflows/ci.yml/badge.svg" alt="CI"></a></p>
<hr>
<div><h2>Overview</h2><a href="#overview"></a></div>
<p>CodeGraph CLI (</p><pre><code>cg</code></pre>) parses your codebase into a semantic graph, then exposes that graph through search, impact analysis, visualization, and a conversational interface. It supports six LLM providers and optionally runs a CrewAI multi-agent system that can read, write, patch, and rollback files autonomously.<p></p>
<p>Core capabilities:</p>
<ul>
<li><strong>Semantic Search</strong> — find code by meaning, not string matching</li>
<li><strong>Impact Analysis</strong> — trace multi-hop dependencies before making changes</li>
<li><strong>Graph Visualization</strong> — interactive HTML and Graphviz DOT exports</li>
<li><strong>Browser-Based Explorer</strong> — visual code navigation with Mermaid diagrams and AI explanations</li>
<li><strong>Conversational Chat</strong> — natural language coding sessions with RAG context</li>
<li><strong>Multi-Agent System</strong> — CrewAI-powered agents for code generation, refactoring, and analysis</li>
<li><strong>DOCX Export</strong> — generate professional project documentation with architecture diagrams</li>
<li><strong>Auto Onboarding</strong> — AI-generated README from your code graph</li>
<li><strong>File Rollback</strong> — automatic backups before every file modification</li>
</ul>
<hr>
<div><h2>Installation</h2><a href="#installation"></a></div>
<div><pre>pip install codegraph-cli</pre></div>
<p>With neural embedding models (semantic code search):</p>
<div><pre>pip install codegraph-cli[embeddings]</pre></div>
<p>With CrewAI multi-agent support:</p>
<div><pre>pip install codegraph-cli[crew]</pre></div>
<p>Everything:</p>
<div><pre>pip install codegraph-cli[all]</pre></div>
<p>For development:</p>
<div><pre>git clone https://github.com/al1-nasir/codegraph-cli.git
<span>cd</span> codegraph-cli
pip install -e <span><span>"</span>.[dev]<span>"</span></span></pre></div>
<hr>
<div><h2>Quick Start</h2><a href="#quick-start"></a></div>
<div><h3>1. Configure your LLM provider</h3><a href="#1-configure-your-llm-provider"></a></div>
<div><pre>cg config setup</pre></div>
<p>This runs an interactive wizard that writes configuration to </p><pre><code>~/.codegraph/config.toml</code></pre>. Alternatively, switch providers directly:<p></p>
<div><pre>cg config set-llm openrouter
cg config set-llm groq
cg config set-llm ollama</pre></div>
<div><h3>2. Index a project</h3><a href="#2-index-a-project"></a></div>
<div><pre>cg project index /path/to/project --name myproject</pre></div>
<p>This parses the source tree using tree-sitter, builds a dependency graph in SQLite, and generates embeddings for semantic search.</p>
<div><h3>3. Use it</h3><a href="#3-use-it"></a></div>
<div><pre>cg analyze search <span><span>"</span>authentication logic<span>"</span></span>
cg analyze impact UserService --hops 3
cg analyze graph process_payment --depth 2
cg chat start
cg chat start --crew <span><span>#</span> multi-agent mode</span>
cg explore open <span><span>#</span> browser-based code explorer</span>
cg onboard <span><span>#</span> auto-generate project README</span>
cg <span>export</span> docx <span><span>#</span> export documentation to DOCX</span></pre></div>
<hr>
<div><h2>Supported LLM Providers</h2><a href="#supported-llm-providers"></a></div>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Type</th>
<th>Configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ollama</td>
<td>Local, free</td>
<td><pre><code>cg config set-llm ollama</code></pre></td>
</tr>
<tr>
<td>Groq</td>
<td>Cloud, free tier</td>
<td><pre><code>cg config set-llm groq</code></pre></td>
</tr>
<tr>
<td>OpenAI</td>
<td>Cloud</td>
<td><pre><code>cg config set-llm openai</code></pre></td>
</tr>
<tr>
<td>Anthropic</td>
<td>Cloud</td>
<td><pre><code>cg config set-llm anthropic</code></pre></td>
</tr>
<tr>
<td>Gemini</td>
<td>Cloud</td>
<td><pre><code>cg config set-llm gemini</code></pre></td>
</tr>
<tr>
<td>OpenRouter</td>
<td>Cloud, multi-model</td>
<td><pre><code>cg config set-llm openrouter</code></pre></td>
</tr>
</tbody>
</table>
<p>All configuration is stored in </p><pre><code>~/.codegraph/config.toml</code></pre>. No environment variables required.<p></p>
<div><pre>cg config show-llm <span><span>#</span> view current provider, model, and endpoint</span>
cg config unset-llm <span><span>#</span> reset to defaults</span></pre></div>
<hr>
<div><h2>Embedding Models</h2><a href="#embedding-models"></a></div>
<p>CodeGraph supports configurable embedding models for semantic code search. Choose based on your hardware and quality needs:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Download</th>
<th>Dim</th>
<th>Quality</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>hash</td>
<td>0 bytes</td>
<td>256</td>
<td>Keyword-only</td>
<td><pre><code>cg config set-embedding hash</code></pre></td>
</tr>
<tr>
<td>minilm</td>
<td>~80 MB</td>
<td>384</td>
<td>Decent</td>
<td><pre><code>cg config set-embedding minilm</code></pre></td>
</tr>
<tr>
<td>bge-base</td>
<td>~440 MB</td>
<td>768</td>
<td>Good</td>
<td><pre><code>cg config set-embedding bge-base</code></pre></td>
</tr>
<tr>
<td>jina-code</td>
<td>~550 MB</td>
<td>768</td>
<td>Code-aware</td>
<td><pre><code>cg config set-embedding jina-code</code></pre></td>
</tr>
<tr>
<td>qodo-1.5b</td>
<td>~6.2 GB</td>
<td>1536</td>
<td>Best</td>
<td><pre><code>cg config set-embedding qodo-1.5b</code></pre></td>
</tr>
</tbody>
</table>
<p>The default is </p><pre><code>hash</code></pre> (zero-dependency, no download). Neural models require the <pre><code>[embeddings]</code></pre> extra and are downloaded on first use from HuggingFace.<p></p>
<div><pre>cg config set-embedding jina-code <span><span>#</span> switch to a neural model</span>
cg config show-embedding <span><span>#</span> view current model and all options</span>
cg config unset-embedding <span><span>#</span> reset to hash default</span></pre></div>
<p>After changing the embedding model, re-index your project:</p>
<div><pre>cg index /path/to/project</pre></div>
<hr>
<div><h2>Commands</h2><a href="#commands"></a></div>
<p>CodeGraph CLI organizes commands into logical groups:</p>
<div><pre><code>cg config — LLM, embedding, and setup configuration
cg project — Index, load, and manage project memories
cg analyze — Search, impact, graph, and RAG context
cg chat — Interactive chat with AI agents
cg explore — Visual code explorer in browser
cg export — Export project documentation
cg onboard — Auto-generate project README
</code></pre></div>
<div><h3>Configuration (<pre><code>cg config</code></pre>)</h3><a href="#configuration-cg-config"></a></div>
<div><pre>cg config setup <span><span>#</span> interactive LLM setup wizard</span>
cg config set-llm openrouter <span><span>#</span> switch LLM provider</span>
cg config unset-llm <span><span>#</span> reset LLM config to defaults</span>
cg config show-llm <span><span>#</span> show current LLM settings</span>
cg config set-embedding jina-code <span><span>#</span> switch embedding model</span>
cg config unset-embedding <span><span>#</span> reset to hash default</span>
cg config show-embedding <span><span>#</span> show current embedding model</span></pre></div>
<div><h3>Project Management (<pre><code>cg project</code></pre>)</h3><a href="#project-management-cg-project"></a></div>
<div><pre>cg project index <span>&lt;</span>path<span>&gt;</span> [--name NAME] <span><span>#</span> parse and index a codebase</span>
cg project list <span><span>#</span> list all indexed projects</span>
cg project load <span>&lt;</span>name<span>&gt;</span> <span><span>#</span> switch active project</span>
cg project current <span><span>#</span> print active project name</span>
cg project delete <span>&lt;</span>name<span>&gt;</span> <span><span>#</span> remove a project index</span>
cg project merge <span>&lt;</span>src<span>&gt;</span> <span>&lt;</span>dst<span>&gt;</span> <span><span>#</span> merge two project graphs</span>
cg project unload <span><span>#</span> unload without deleting</span>
cg project init <span><span>#</span> quickstart wizard</span>
cg project watch <span><span>#</span> auto-reindex on file changes</span></pre></div>
<div><h3>Code Analysis (<pre><code>cg analyze</code></pre>)</h3><a href="#code-analysis-cg-analyze"></a></div>
<div><pre>cg analyze search <span>&lt;</span>query<span>&gt;</span> [--top-k N] <span><span>#</span> semantic search across the graph</span>
cg analyze impact <span>&lt;</span>symbol<span>&gt;</span> [--hops N] <span><span>#</span> multi-hop dependency impact analysis</span>
cg analyze graph <span>&lt;</span>symbol<span>&gt;</span> [--depth N] <span><span>#</span> ASCII dependency graph</span>
cg analyze export-graph --format html <span><span>#</span> interactive vis.js visualization</span>
cg analyze export-graph --format dot <span><span>#</span> Graphviz DOT format</span>
cg analyze rag-context <span>&lt;</span>query<span>&gt;</span> <span><span>#</span> raw RAG retrieval for debugging</span>
cg analyze tree [--full] <span><span>#</span> directory tree of indexed project</span>
cg analyze sync [--dry-run] <span><span>#</span> incremental index sync</span>
cg analyze health <span><span>#</span> project health dashboard</span></pre></div>
<div><h3>Interactive Chat (<pre><code>cg chat</code></pre>)</h3><a href="#interactive-chat-cg-chat"></a></div>
<div><pre>cg chat start <span><span>#</span> start or resume a session</span>
cg chat start --new <span><span>#</span> force a new session</span>
cg chat start --crew <span><span>#</span> multi-agent mode (CrewAI)</span>
cg chat start -s <span>&lt;</span>id<span>&gt;</span> <span><span>#</span> resume a specific session</span>
cg chat list <span><span>#</span> list all sessions</span>
cg chat delete <span>&lt;</span>id<span>&gt;</span> <span><span>#</span> delete a session</span>
cg chat <span>export</span> <span>&lt;</span>id<span>&gt;</span> --format markdown <span><span>#</span> export session to file</span></pre></div>
<p>In-chat commands:</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mode</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><pre><code>/help</code></pre></td>
<td>Both</td>
<td>Show available commands</td>
</tr>
<tr>
<td><pre><code>/clear</code></pre></td>
<td>Both</td>
<td>Clear conversation history</td>
</tr>
<tr>
<td><pre><code>/new</code></pre></td>
<td>Both</td>
<td>Start a fresh session</td>
</tr>
<tr>
<td><pre><code>/exit</code></pre></td>
<td>Both</td>
<td>Save and exit</td>
</tr>
<tr>
<td><pre><code>/apply</code></pre></td>
<td>Standard</td>
<td>Apply pending code proposal</td>
</tr>
<tr>
<td><pre><code>/preview</code></pre></td>
<td>Standard</td>
<td>Preview pending file changes</td>
</tr>
<tr>
<td><pre><code>/backups</code></pre></td>
<td>Crew</td>
<td>List all file backups</td>
</tr>
<tr>
<td><pre><code>/rollback &lt;file&gt;</code></pre></td>
<td>Crew</td>
<td>Restore a file from backup</td>
</tr>
<tr>
<td><pre><code>/undo &lt;file&gt;</code></pre></td>
<td>Crew</td>
<td>Alias for rollback</td>
</tr>
</tbody>
</table>
<div><h3>Visual Explorer (<pre><code>cg explore</code></pre>)</h3><a href="#visual-explorer-cg-explore"></a></div>
<div><pre>cg explore open <span><span>#</span> launch browser-based code explorer</span>
cg explore open --port 9000 <span><span>#</span> use custom port</span></pre></div>
<p>Opens a local web UI with directory tree navigation, syntax-highlighted code, AI explanations, dependency graphs, and Mermaid diagrams.</p>
<div><h3>Documentation Export (<pre><code>cg export</code></pre>)</h3><a href="#documentation-export-cg-export"></a></div>
<div><pre>cg <span>export</span> docx <span><span>#</span> basic DOCX with structure + diagrams</span>
cg <span>export</span> docx --enhanced <span><span>#</span> add AI-powered explanations</span>
cg <span>export</span> docx --include-code <span><span>#</span> include source code listings</span>
cg <span>export</span> docx --enhanced --depth files --include-code <span><span>#</span> full export</span></pre></div>
<div><h3>Auto Onboarding</h3><a href="#auto-onboarding"></a></div>
<div><pre>cg onboard <span><span>#</span> print AI-generated README to stdout</span>
cg onboard --save <span><span>#</span> save as ONBOARD.md in project dir</span>
cg onboard -o README.md <span><span>#</span> save to specific file</span>
cg onboard --no-llm <span><span>#</span> template-only, no LLM call</span></pre></div>
<hr>
<div><h2>Multi-Agent System</h2><a href="#multi-agent-system"></a></div>
<p>When you run </p><pre><code>cg chat start --crew</code></pre>, CodeGraph launches a CrewAI pipeline with four specialized agents:<p></p>
<table>
<thead>
<tr>
<th>Agent</th>
<th>Role</th>
<th>Tools</th>
</tr>
</thead>
<tbody>
<tr>
<td>Project Coordinator</td>
<td>Routes tasks to the right specialist</td>
<td>Delegation only</td>
</tr>
<tr>
<td>File System Engineer</td>
<td>File I/O, directory traversal, backups</td>
<td>list_directory, read_file, write_file, patch_file, delete_file, rollback_file, file_tree</td>
</tr>
<tr>
<td>Senior Software Developer</td>
<td>Code generation, refactoring, bug fixes</td>
<td>All tools (file ops + code analysis)</td>
</tr>
<tr>
<td>Code Intelligence Analyst</td>
<td>Search, dependency tracing, explanations</td>
<td>search_code, grep, project_summary, read_file</td>
</tr>
</tbody>
</table>
<p>Every file modification automatically creates a timestamped backup in </p><pre><code>~/.codegraph/backups/</code></pre>. Files can be rolled back to any previous state via <pre><code>/rollback</code></pre> or <pre><code>cg v2 rollback</code></pre>.<p></p>
<hr>
<div><h2>Architecture</h2><a href="#architecture"></a></div>
<div><pre><code>CLI Layer (Typer + Rich) | +-- config ─────────&gt; ConfigManager (TOML) | +-- project ────────&gt; MCPOrchestrator ──&gt; GraphStore (SQLite) | | | | +-- Parser +-- VectorStore (LanceDB) | | (tree-sitter) | | +-- RAGRetriever +-- Embeddings (configurable) | +-- LLM Adapter hash | minilm | bge-base | jina-code | qodo-1.5b +-- analyze ────────&gt; Search, Impact, Graph, Tree, Sync, Health | +-- chat ───────────&gt; ChatAgent (standard mode) | CrewChatAgent (--crew mode) | +-- Coordinator Agent | +-- File System Agent ──&gt; 8 file operation tools | +-- Code Gen Agent ─────&gt; all 11 tools | +-- Code Analysis Agent &gt; 3 search/analysis tools | +-- explore ────────&gt; Starlette + Uvicorn (browser UI) | +-- export ─────────&gt; DOCX generator + Mermaid diagrams | +-- onboard ────────&gt; AI README generation from code graph
</code></pre></div>
<p><strong>Embeddings</strong>: Five models available via </p><pre><code>cg config set-embedding</code></pre>. Hash (default, zero-dependency) through Qodo-Embed-1-1.5B (best quality, 6 GB). Neural models use raw <pre><code>transformers</code></pre> + <pre><code>torch</code></pre> — no sentence-transformers overhead. Models are cached in <pre><code>~/.codegraph/models/</code></pre>.<p></p>
<p><strong>Parser</strong>: tree-sitter grammars for Python, JavaScript, and TypeScript. Extracts modules, classes, functions, imports, and call relationships into a directed graph.</p>
<p><strong>Storage</strong>: SQLite for the code graph (nodes + edges), LanceDB for vector embeddings. All data stored under </p><pre><code>~/.codegraph/</code></pre>.<p></p>
<p><strong>LLM Adapter</strong>: Unified interface across six providers. For CrewAI, models are routed through LiteLLM. Configuration is read exclusively from </p><pre><code>~/.codegraph/config.toml</code></pre>.<p></p>
<hr>
<div><h2>Project Structure</h2><a href="#project-structure"></a></div>
<div><pre><code>codegraph_cli/ cli.py # main Typer application, command wiring cli_groups.py # command group definitions (config, project, analyze) cli_chat.py # interactive chat REPL with Rich output cli_setup.py # setup wizard, set-llm, set-embedding cli_explore.py # browser-based visual code explorer (Starlette) cli_export.py # DOCX export with Mermaid diagrams cli_onboard.py # AI-generated project README cli_health.py # project health dashboard cli_quickstart.py # quickstart / init wizard cli_watch.py # auto-reindex on file changes config.py # loads config from TOML config_manager.py # TOML read/write, provider and embedding config llm.py # multi-provider LLM adapter parser.py # tree-sitter AST parsing (Python, JS, TS) storage.py # SQLite graph store embeddings.py # configurable embedding engine (5 models) rag.py # RAG retriever vector_store.py # LanceDB vector store orchestrator.py # coordinates parsing, search, impact graph_export.py # DOT and HTML graph export project_context.py # unified file access layer crew_tools.py # 11 CrewAI tools (file ops + analysis) crew_agents.py # 4 specialized CrewAI agents crew_chat.py # CrewAI orchestrator with rollback chat_agent.py # standard chat agent chat_session.py # session persistence models.py # core data models templates/ graph_interactive.html # vis.js graph template
</code></pre></div>
<hr>
<div><h2>Development</h2><a href="#development"></a></div>
<div><pre>git clone https://github.com/al1-nasir/codegraph-cli.git
<span>cd</span> codegraph-cli
python -m venv .venv <span>&amp;&amp;</span> <span>source</span> .venv/bin/activate
pip install -e <span><span>"</span>.[dev,crew,embeddings]<span>"</span></span>
pytest</pre></div>
<hr>
<div><h2>License</h2><a href="#license"></a></div>
<p>MIT. See <a href="/al1-nasir/codegraph-cli/blob/main/LICENSE">LICENSE</a>.</p>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>