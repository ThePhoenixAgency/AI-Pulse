<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>AI vs. the Pentagon: killer robots, mass surveillance, and red lines</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>AI vs. the Pentagon: killer robots, mass surveillance, and red lines</h1>
  <div class="metadata">
    Source: The Verge | Date: 2/27/2026 5:16:53 PM | <a href="https://www.theverge.com/ai-artificial-intelligence/886082/ai-vs-the-pentagon-killer-robots-mass-surveillance-and-red-lines" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div><section><p>Can AI firms set limits on how and where the military uses their models? Anthropic is in heated negotiations with the Pentagon after refusing to comply with new military contract terms that would require it to loosen the guardrails on its AI models, allowing for “any lawful use,” even mass surveillance of Americans and fully autonomous lethal weapons.</p><p>Pentagon CTO Emil Michael is pushing for Anthropic to be <a href="https://www.theverge.com/ai-artificial-intelligence/883456/anthropic-pentagon-department-of-defense-negotiations">designated a “supply chain risk”</a> if it doesn’t comply, a label usually only given to national security threats. Anthropic’s rivals OpenAI and xAI have reportedly agreed to the new terms, but even after a White House meeting with Defense Secretary Pete Hegseth, Anthropic CEO Dario Amodei is <a href="https://www.theverge.com/news/885773/anthropic-department-of-defense-dod-pentagon-refusal-terms-hegseth-dario-amodei">still refusing</a> to cross his company’s red line, stating that “threats do not change our position: we cannot in good conscience accede to their request.”</p><p><em>Follow along here for the latest updates on the clash between AI companies and the Pentagon…</em></p></section><section><ul><li><div><p><img alt="Hayden Field" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/06/HAYDEN_BLURPLE.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p></div><h2><a href="https://www.theverge.com/ai-artificial-intelligence/885963/anthropic-dod-pentagon-tech-workers-ai-labs-react">We don’t have to have unsupervised killer robots</a></h2><div><div><p><img alt="STK432_Government__CVirginia_D" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/STK432_Government__CVirginia_D.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p><p><img alt="STK432_Government__CVirginia_D" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/STK432_Government__CVirginia_D.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p></div><p><cite>Image: Cath Virginia / The Verge</cite></p></div><div><p>It’s the day of the Pentagon’s looming ultimatum for Anthropic: allow the US military <a href="https://www.theverge.com/ai-artificial-intelligence/883456/anthropic-pentagon-department-of-defense-negotiations">unchecked access</a> to its technology, including for mass surveillance and fully autonomous lethal weapons, or potentially be designated a “supply chain risk” and potentially lose hundreds of billions of dollars in contracts. Amid the intensifying public statements and threats, tech workers across the industry are looking at their own companies’ government and military contracts wondering what kind of future they’re helping to build.</p><p>While the Department of Defense has spent weeks negotiating with Anthropic over removing its guardrails, including allowing the US military to use Anthropic’s AI kill targets with no human oversight, OpenAI and xAI had <a href="https://www.washingtonpost.com/technology/2026/02/22/pentagon-anthropic-ai-dispute/">reportedly</a> already agreed to such terms, although OpenAI is <a href="https://www.washingtonpost.com/technology/2026/02/22/pentagon-anthropic-ai-dispute/">reportedly</a> attempting to adopt the same red lines in the agreements as Anthropic. The overall situation has left employees at some companies with defense contracts feeling betrayed. “When I joined the tech industry, I thought tech was about making people’s lives easier,” an Amazon Web Services employee told <em>The Verge</em>, “but now it seems like it’s all about making it easier to surveil and deport and kill people.”</p><p><a href="https://www.theverge.com/ai-artificial-intelligence/885963/anthropic-dod-pentagon-tech-workers-ai-labs-react">Read Article &gt;</a></p></div></li><li><div><p><img alt="Hayden Field" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/06/HAYDEN_BLURPLE.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p></div><h2><a href="https://www.theverge.com/news/885773/anthropic-department-of-defense-dod-pentagon-refusal-terms-hegseth-dario-amodei">Anthropic refuses Pentagon’s new terms, standing firm on lethal autonomous weapons and mass surveillance</a></h2><div><div><p><img alt="Photo illustration of Dario Amodei of Anthropic." src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/25469941/STK202_DARIO_AMODEI_CVIRGINIA_D.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p><p><img alt="Photo illustration of Dario Amodei of Anthropic." src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/25469941/STK202_DARIO_AMODEI_CVIRGINIA_D.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p></div><p><cite>Image: Cath Virginia / The Verge, Getty Images</cite></p></div><div><p>Less than 24 hours before the deadline in an ultimatum issued by the Pentagon, Anthropic has refused the Department of Defense’s demands for unrestricted access to its AI.</p><p>It’s the <a href="https://www.theverge.com/ai-artificial-intelligence/883456/anthropic-pentagon-department-of-defense-negotiations">culmination of a dramatic exchange</a> of public statements, social media posts, and behind-the-scenes negotiations, coming down to Defense Secretary Pete Hegseth’s desire to renegotiate all AI labs’ current contracts with the military. But Anthropic, so far, has refused to back down from its two current red lines: no mass surveillance of Americans, and no lethal autonomous weapons (or weapons with license to kill targets with no human oversight whatsoever). OpenAI and xAI had <a href="https://www.washingtonpost.com/technology/2026/02/22/pentagon-anthropic-ai-dispute/">reportedly</a> already agreed to the new terms, while Anthropic’s refusal had led to CEO Dario Amodei being summoned to the White House this week for a meeting with Hegseth himself, in which the Secretary <a href="https://www.npr.org/2026/02/24/nx-s1-5725327/pentagon-anthropic-hegseth-safety">reportedly</a> issued an ultimatum to the CEO to back down by the end of business day on Friday or else.</p><p><a href="https://www.theverge.com/news/885773/anthropic-department-of-defense-dod-pentagon-refusal-terms-hegseth-dario-amodei">Read Article &gt;</a></p></div></li><li><div><p><img alt="Tina Nguyen" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/LA-Times-headshot-copy.jpeg?quality=90&amp;strip=all&amp;crop=3.0503978779841%2C0%2C93.899204244032%2C100&amp;w=2400"></p></div><h2><a href="https://www.theverge.com/ai-artificial-intelligence/884165/pentagon-anthropic-emil-michael-steve-feinberg">Pete Hegseth’s Pentagon AI bro squad includes a former Uber executive and a private equity billionaire</a></h2><div><p><img alt="Defense Department Showcases Multi-Domain Autonomous Display In Pentagon’s Courtyard" src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-2225411614.jpg?quality=90&amp;strip=all&amp;crop=0%2C0.0049265937530762%2C100%2C99.990146812494&amp;w=2400"></p><p><img alt="Defense Department Showcases Multi-Domain Autonomous Display In Pentagon’s Courtyard" src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-2225411614.jpg?quality=90&amp;strip=all&amp;crop=0%2C0.0049265937530762%2C100%2C99.990146812494&amp;w=2400"></p></div></li><li><div><p><img alt="Tina Nguyen" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/LA-Times-headshot-copy.jpeg?quality=90&amp;strip=all&amp;crop=3.0503978779841%2C0%2C93.899204244032%2C100&amp;w=2400"></p></div><h2><a href="https://www.theverge.com/ai-artificial-intelligence/883456/anthropic-pentagon-department-of-defense-negotiations">Inside Anthropic’s existential negotiations with the Pentagon</a></h2><div><div><p><img alt="268367_dod_and_anthropic’s_public_fight_over_lethal_autonomous_weapons_a_mass_surveillance_CVirginia" src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268367_dod_and_anthropics_public_fight_over_lethal_autonomous_weapons_a_mass_surveillance_CVirginia.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p><p><img alt="268367_dod_and_anthropic’s_public_fight_over_lethal_autonomous_weapons_a_mass_surveillance_CVirginia" src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268367_dod_and_anthropics_public_fight_over_lethal_autonomous_weapons_a_mass_surveillance_CVirginia.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></p></div><p><cite>Image: Cath Virginia / The Verge, Getty Images</cite></p></div><div><p>Anthropic’s weekslong battle with the Department of Defense has played out over social media posts, admonishing public statements, and direct quotes from unnamed Pentagon officials to the news media. But the future of the $380 billion AI startup comes down to just three words: “any lawful use.” The new terms, which OpenAI and xAI have <a href="https://www.washingtonpost.com/technology/2026/02/22/pentagon-anthropic-ai-dispute/">reportedly</a> already agreed to, would give the US military carte blanche to use services for mass surveillance and lethal autonomous weapons, AI that has full power to track and kill targets with no humans involved in the decision-making process.</p><p>The negotiations have turned ugly, with Pentagon CTO Emil Michael, formerly a top executive at the ridehailing company Uber, driving the government’s threats to designate Anthropic as a “supply chain risk,” according to two people familiar with negotiations. This classification is usually reserved for threats to national security, including malicious foreign influence or cyber warfare. Anthropic CEO Dario Amodei will <a href="https://www.axios.com/2026/02/23/hegseth-dario-pentagon-meeting-antrhopic-claude">reportedly</a> meet with Secretary Pete Hegseth on Tuesday at the Pentagon, and an unnamed Defense official described it as a “shit-or-get-off-the-pot meeting.”</p><p><a href="https://www.theverge.com/ai-artificial-intelligence/883456/anthropic-pentagon-department-of-defense-negotiations">Read Article &gt;</a></p></div></li></ul></section></div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>