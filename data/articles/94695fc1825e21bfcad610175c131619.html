<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="UTF-8">
<title>Règlement sur l’IA et lutte contre les risques systémiques au menu de l’INESIA</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Règlement sur l’IA et lutte contre les risques systémiques au menu de l’INESIA</h1>
  <div class="metadata">
    Source: Next INpact | Date: 2/18/2026 9:02:00 AM | <a href="https://next.ink/225034/reglement-sur-lia-et-lutte-contre-les-risques-systemiques-au-menu-de-linesia/" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: FR
  </div>
  <div class="content">
    <div><div> <p>Comment évaluer l’intelligence artificielle&nbsp;? Comment détecter à temps ses comportements imprévus&nbsp;? Limiter les risques que créent d’éventuels mésusages&nbsp;? Telles sont certaines des questions auxquelles l’Institut national pour l’évaluation et la sécurité de l’IA (INESIA) inauguré le 31 janvier 2025 devra répondre au fil des deux prochaines années.</p> <p>Dévoilé juste avant le Sommet de Paris sur l’<a href="https://next.ink/169604/sommet-pour-laction-sur-lia-quels-sont-les-enjeux/">action pour l’IA</a> de février 2025, l’INESIA réunit l’Agence nationale de la sécurité des systèmes d’information (ANSSI), l’Inria, le laboratoire national de métrologie et d’essais (LNE) et le pôle d’expertise de la régulation numérique (PEReN) pour <em>«&nbsp;soutenir le développement de l’intelligence artificielle et accompagner la transformation de l’économie qu’elle induit&nbsp;»</em>. Cette mission s’effectue tout en <em>«&nbsp;étudiant&nbsp;scientifiquement les effets de ces technologies&nbsp;»</em>, en particulier <em>«&nbsp;en termes de sécurité&nbsp;»</em>.</p> <p>Pour 2026 et 2027, elle s’effectuera selon trois axes, détaille sa feuille de route <a href="https://www.sgdsn.gouv.fr/publications/linstitut-national-pour-levaluation-et-la-securite-de-lia-adopte-sa-feuille-de-route" target="_blank">publiée</a> mi-février. Pilotée par la Direction générale des Entreprises (DGE) et le Secrétariat général de la défense et de la sécurité nationale (SGDSN), l’entité travaillera en effet au soutien à la régulation, notamment en matière de mise en œuvre du règlement européen sur l’intelligence artificielle (RIA, ou AI Act), à la maîtrise des <em>«&nbsp;risques systémiques&nbsp;»</em> de ce type de technologies et à l’évaluation de la <em>«&nbsp;performance et de la fiabilité des modèles et systèmes&nbsp;»</em>. Certaines de ses actions prendront aussi un angle transverse, notamment pour tout ce qui touche à la veille académique et méthodologique, ou encore à l’animation scientifique autour de ses activités.</p> <h3>Performance, interprétabilité, «&nbsp;alignement aux valeurs et intentions humaines&nbsp;»</h3> <p>Le constat que dresse l’INESIA est aussi clair que succinct&nbsp;: <em>«&nbsp;le rythme des progrès de l’IA ne faiblit pas&nbsp;»</em>, et à ce titre, les évolutions du secteur posent des questions de performance, d’interprétabilité, de robustesse face à l’imprévu, mais aussi <em>«&nbsp;d’alignement aux valeurs et intentions humaines&nbsp;»</em>. </p> <p>L’institut ne définit pas ces différents termes, quand bien même les <em>«&nbsp;valeurs et intentions humaines&nbsp;»</em> varient certainement d’un individu à l’autre. La notion même d’alignement reste sujette à des <a href="https://next.ink/135681/transhumanisme-long-termisme-comment-les-courants-tescreal-influent-le-developpement-de-lia/">débats scientifiques</a>&nbsp;: certains, dont le Future of Life Institute, estiment nécessaire d’œuvrer à l’émergence d’IA <em>«&nbsp;alignées&nbsp;»</em> à des valeurs prédéfinies, faute de quoi ces systèmes créeraient de potentiels <em>«&nbsp;risques existentiels&nbsp;»</em> (un champ qui a notamment émergé des <a href="https://next.ink/135101/luniversite-doxford-ferme-le-future-of-humanity-institute-dirige-par-nick-bostrom/">travaux du philosophe Nick Bostrom</a>). D’autres, dont les chercheurs Timnit Gebru et Emile Torres, considèrent de leur côté que le champ de la <em>«&nbsp;sécurité de l’IA&nbsp;»</em> (<em>AI safety</em>) n’œuvre qu’à renforcer la <a href="https://next.ink/135681/transhumanisme-long-termisme-comment-les-courants-tescreal-influent-le-developpement-de-lia/">course</a> de l’industrie de l’IA.</p> <ul>
<li> <div> <p> <abbr> <span>Mercredi 20 novembre 2024 à 18h18</span> <span>20/11/2024 18h18</span> </abbr> </p> </div>
</li> </ul> <p>Quoiqu’il en soit, dans l’environnement actuel, et notamment face au déploiement large de systèmes génératifs, <em>«&nbsp;les méthodes d’évaluation conçues pour des systèmes fermés, monofonctionnels ou statiques, montrent leurs limites&nbsp;»</em>, indique l’INESIA. Pour faire face, et pouvoir notamment <em>«&nbsp;mesurer et contenir les risques à fort potentiel systémiques, y compris ceux liés à la manipulation de l’information, à la cybersécurité ou à la déstabilisation de processus collectifs&nbsp;»</em>, l’entité compte participer au champ scientifique en devenir qu’est l’évaluation de l’IA.</p> <h3>Accompagner l’évolution réglementaire</h3> <p>Dans ses travaux, l’entité œuvrera à <em>«&nbsp;construire une démarche scientifique et stratégique, structurer une capacité souveraine d’évaluation, coordonner les expertises publiques et mutualiser les moyens&nbsp;»</em>, et à agir dans les réseaux internationaux. En pratique, l’INESIA rejoindra notamment le réseau grandissant d’<em>AI Safety Institutes</em>, des instituts créés dans une dizaine de pays, et dont le réseau international a organisé sa première rencontre en <a href="https://digital-strategy.ec.europa.eu/en/news/first-meeting-international-network-ai-safety-institutes" target="_blank">novembre 2024</a>.</p> <p>Sur les enjeux d’appui à la régulation, elle accompagnera notamment la mise en œuvre du RIA, en fournissant des outils d’évaluation aux diverses autorités concernées. Elle poursuivra les travaux de détection des contenus synthétiques déjà en cours du côté de VIGINUm et du PEReN. Il s’agira enfin de créer des méthodes d’évaluation adaptées à la cybersécurité des systèmes d’IA comme aux produits de cybersécurité intégrant des technologies d’IA, dans le prolongement du projet Sécurité des Produits d’IA (SEPIA) que l’ANSSI mène depuis un an.</p> <h3>S’équiper face aux risques systémiques</h3> <p>Côté risques systémiques, il s’agira d’abord de développer les recherches permettant de mieux les caractériser, ce qui doit ensuite permettre à la puissance publique d’agir plus précisément. En la matière, l’INESIA vise notamment les usages d’IA à des fins de désinformation, d’attaque contre la cybersécurité, de déstabilisation d’un système économique, etc. </p> <p>Elle prévoit d’identifier des projets de recherche ciblés, puis publiera des méthodes d’atténuation en source ouverte, <em>«&nbsp;si opportun&nbsp;»</em>. Les performances et les risques des systèmes d’IA agentiques seront plus particulièrement étudiés, notamment pour comprendre <em>«&nbsp;leurs capacités en matière de cybersécurité et estimer la mesure des possibilités d’usages à des fins criminelles&nbsp;»</em>.</p> <p>Pour <em>«&nbsp;stimuler la créativité de l’écosystème&nbsp;»</em>, enfin, l’INESIA prévoit de conduire des<em> «&nbsp;challenges&nbsp;»</em> pour <em>«&nbsp;clarifier et faire progresser l’état de l’art&nbsp;»</em>. Évoquant une émulation internationale de nature à faire progresser rapidement certaines technologies, elle cherchera à <em>«&nbsp;susciter une «&nbsp;coopétition&nbsp;»&nbsp;» </em>entre participants.</p> </div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>