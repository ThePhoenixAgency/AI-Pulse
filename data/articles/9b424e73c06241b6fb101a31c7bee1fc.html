<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="UTF-8">
<title>Les chatbots IA fournissent des informations moins pr�cises aux utilisateurs vuln�rables, ce qui rend ces mod�les peu fiables en tant que sources d'information pour eux, selon une �tude</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Les chatbots IA fournissent des informations moins pr�cises aux utilisateurs vuln�rables, ce qui rend ces mod�les peu fiables en tant que sources d'information pour eux, selon une �tude</h1>
  <div class="metadata">
    Source: Developpez.com | Date: 2/20/2026 5:33:00 PM | <a href="https://intelligence-artificielle.developpez.com/actu/380455/Les-chatbots-IA-fournissent-des-informations-moins-precises-aux-utilisateurs-vulnerables-ce-qui-rend-ces-modeles-peu-fiables-en-tant-que-sources-d-information-pour-eux-selon-une-etude/" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: FR
  </div>
  <div class="content">
    <div><div> <p><img src="https://www.developpez.com/images/logos/intelligence-artificielle2.png"> <b>Une �tude du MIT Center for Constructive Communication r�v�le que les principaux mod�les d'IA sont moins performants pour les utilisateurs ayant un niveau d'anglais moins �lev�, un niveau d'�ducation moins �lev� et qui ne sont pas originaires des �tats-Unis. Ces mod�les refusent �galement plus souvent de r�pondre aux questions de ces utilisateurs et, dans certains cas, leur r�pondent avec un langage condescendant ou paternaliste. Les chercheurs affirment : � <i>Nos conclusions sugg�rent qu'ils pourraient en r�alit� exacerber les in�galit�s existantes en fournissant syst�matiquement des informations erron�es ou en refusant de r�pondre aux questions de certains utilisateurs. Les personnes qui pourraient avoir le plus besoin de ces outils pourraient recevoir des informations de qualit� m�diocre, fausses, voire nuisibles.</i> �</b></p><p>En novembre 2025, <a href="https://droit.developpez.com/actu/377524/OpenAI-fait-face-a-7-poursuites-judiciaires-alleguant-que-ChatGPT-a-pousse-des-personnes-au-suicide-et-a-des-delires-dangereux-et-pour-suicide-assiste-homicide-involontaire-et-negligence/" target="_blank">OpenAI a �t� confront�e � sept nouvelles poursuites judiciaires en Californie</a>, all�guant que son syst�me d'intelligence artificielle (IA) ChatGPT aurait pouss� des personnes au suicide et � des d�lires dangereux. D�pos�es par deux groupes de d�fense des droits, ces poursuites affirment qu'OpenAI a commercialis� GPT-4o en d�pit d'avertissements internes concernant son comportement manipulateur. Les plaintes affirment qu'OpenAI a pr�cipit� la mise sur le march� de ChatGPT au d�triment de la s�curit� des utilisateurs. OpenAI affirme examiner les dossiers et qualifie les situations ayant conduit � ces suicides d'� incroyablement d�chirantes �.</p><p>Les grands mod�les de langage (LLM) ont �t� pr�sent�s comme des outils susceptibles de d�mocratiser l'acc�s � l'information dans le monde entier, en offrant des connaissances dans une interface conviviale, ind�pendamment du milieu ou de la localisation de l'utilisateur. Cependant, une nouvelle �tude du Center for Constructive Communication (CCC) du MIT sugg�re que ces syst�mes d'intelligence artificielle pourraient en r�alit� �tre moins performants pour les utilisateurs qui pourraient le plus en b�n�ficier.</p><p>Une �tude men�e par des chercheurs du CCC, bas� au MIT Media Lab, a r�v�l� que les chatbots IA de pointe, notamment GPT-4 d'OpenAI, Claude 3 Opus d'Anthropic et Llama 3 de Meta, fournissent parfois des r�ponses moins pr�cises et moins v�ridiques aux utilisateurs ayant un niveau d'anglais moins �lev�, un niveau d'�ducation formelle moins �lev� ou qui ne sont pas originaires des �tats-Unis. Ces mod�les refusent �galement plus souvent de r�pondre aux questions de ces utilisateurs et, dans certains cas, leur r�pondent avec un langage condescendant ou paternaliste.</p><p>� <i>Nous �tions motiv�s par la perspective que les LLM contribuent � rem�dier � l'in�galit� d'acc�s � l'information dans le monde</i> �, explique l'auteure principale Elinor Poole-Dayan SM '25, associ�e technique � la MIT Sloan School of Management, qui a dirig� la recherche en tant que membre affili�e du CCC et �tudiante en master en arts et sciences des m�dias. � <i>Mais cette vision ne peut devenir r�alit� sans garantir que les biais et les tendances n�fastes des mod�les soient att�nu�s de mani�re s�re pour tous les utilisateurs, ind�pendamment de leur langue, de leur nationalit� ou d'autres caract�ristiques d�mographiques.</i> �</p><p><img src="https://www.developpez.net/forums/attachments/p674419d1/a/a/a"></p>
<p><b>Sous-performances syst�matiques dans plusieurs dimensions</b></p><p>Pour cette recherche, l'�quipe a test� la mani�re dont les trois LLM r�pondaient � des questions issues de deux ensembles de donn�es : TruthfulQA et SciQ. TruthfulQA est con�u pour mesurer la v�racit� d'un mod�le (en s'appuyant sur des id�es fausses courantes et des v�rit�s litt�rales sur le monde r�el), tandis que SciQ contient des questions d'examens scientifiques testant l'exactitude des faits. Les chercheurs ont ajout� de courtes biographies d'utilisateurs � chaque question, en variant trois caract�ristiques : le niveau d'�ducation, la ma�trise de l'anglais et le pays d'origine.</p><p>Pour les trois mod�les et les deux ensembles de donn�es, les chercheurs ont constat� une baisse significative de la pr�cision lorsque les questions provenaient d'utilisateurs d�crits comme ayant un niveau d'�ducation moins �lev� ou ne parlant pas l'anglais comme langue maternelle. Les effets �taient les plus prononc�s pour les utilisateurs se trouvant � l'intersection de ces cat�gories : ceux qui avaient un niveau d'�ducation moins �lev� et qui ne parlaient pas l'anglais comme langue maternelle ont vu la qualit� des r�ponses baisser le plus fortement.</p><p>La recherche a �galement examin� l'influence du pays d'origine sur les performances du mod�le. En testant des utilisateurs des �tats-Unis, d'Iran et de Chine ayant des niveaux d'�ducation �quivalents, les chercheurs ont constat� que Claude 3 Opus, en particulier, obtenait des r�sultats nettement moins bons pour les utilisateurs iraniens sur les deux ensembles de donn�es.</p><p>� <i>Nous constatons la plus forte baisse de pr�cision chez les utilisateurs qui ne sont pas de langue maternelle anglaise et qui ont un niveau d'�ducation moins �lev�</i> �, explique Jad Kabbara, chercheur scientifique chez CCC et coauteur de l'article. �<i> Ces r�sultats montrent que les effets n�gatifs du comportement du mod�le par rapport � ces caract�ristiques des utilisateurs se combinent de mani�re pr�occupante, ce qui sugg�re que ces mod�les d�ploy�s � grande �chelle risquent de propager des comportements nuisibles ou des informations erron�es en aval vers ceux qui sont les moins � m�me de les identifier. </i>�</p><p><img src="https://www.developpez.net/forums/attachments/p674420d1/a/a/a"></p>
<p><b>Refus et langage condescendant</b></p><p>Les diff�rences les plus frappantes concernaient peut-�tre la fr�quence � laquelle les mod�les refusaient carr�ment de r�pondre aux questions. Par exemple, Claude 3 Opus a refus� de r�pondre � pr�s de 11 % des questions pos�es par des utilisateurs moins instruits et non anglophones, contre seulement 3,6 % pour le groupe t�moin sans biographie utilisateur. Lorsque les chercheurs ont analys� manuellement ces refus, ils ont constat� que Claude r�pondait avec un langage condescendant, paternaliste ou moqueur dans 43,7 % des cas pour les utilisateurs moins �duqu�s, contre moins de 1 % pour les utilisateurs hautement �duqu�s. Dans certains cas, le mod�le imitait un anglais approximatif ou adoptait un dialecte exag�r�.</p><p>Le mod�le a �galement refus� de fournir des informations sur certains sujets sp�cifiquement destin�s aux utilisateurs moins �duqu�s d'Iran ou de Russie, notamment des questions sur l'�nergie nucl�aire, l'anatomie et les �v�nements historiques, alors qu'il r�pondait correctement aux m�mes questions pour d'autres utilisateurs. � <i>C'est un autre indicateur sugg�rant que le processus d'alignement pourrait inciter les mod�les � cacher des informations � certains utilisateurs afin d'�viter de les d�sinformer, m�me si le mod�le conna�t clairement la bonne r�ponse et la fournit � d'autres utilisateurs</i> �, explique Kabbara.</p><p><b>Les �chos des pr�jug�s humains</b></p><p>Ces r�sultats refl�tent les sch�mas document�s des pr�jug�s sociocognitifs humains. Des recherches en sciences sociales ont montr� que les locuteurs natifs de l'anglais per�oivent souvent les locuteurs non natifs comme moins �duqu�s, moins intelligents et moins comp�tents, quelle que soit leur expertise r�elle. Des perceptions biais�es similaires ont �t� document�es chez les enseignants qui �valuent des �l�ves non natifs de langue anglaise.</p><p>� <i>La valeur des grands mod�les de langage est �vidente au vu de leur adoption extraordinaire par les individus et des investissements massifs qui sont consacr�s � cette technologie</i> �, explique Deb Roy, professeur en arts et sciences des m�dias, directeur du CCC et coauteur de l'article. � <i>Cette �tude nous rappelle � quel point il est important d'�valuer en permanence les biais syst�matiques qui peuvent s'insinuer discr�tement dans ces syst�mes, causant des pr�judices injustes � certains groupes sans que nous en soyons pleinement conscients.</i> �</p><p>Les implications sont particuli�rement pr�occupantes �tant donn� que les fonctionnalit�s de personnalisation, telles que la m�moire de ChatGPT, qui suit les informations des utilisateurs au fil des conversations, sont de plus en plus courantes. Ces fonctionnalit�s risquent de traiter de mani�re diff�rente les groupes d�j� marginalis�s.</p><p>� <i>Les LLM ont �t� commercialis�s comme des outils qui favoriseront un acc�s plus �quitable � l'information et r�volutionneront l'apprentissage personnalis� </i>�, explique Poole-Dayan. � <i>Mais nos conclusions sugg�rent qu'ils pourraient en r�alit� exacerber les in�galit�s existantes en fournissant syst�matiquement des informations erron�es ou en refusant de r�pondre aux questions de certains utilisateurs. Les personnes qui pourraient avoir le plus besoin de ces outils pourraient recevoir des informations de qualit� m�diocre, fausses, voire nuisibles.</i> �</p><p><img src="https://www.developpez.net/forums/attachments/p674421d1/a/a/a"></p><p>
Voici la conclusion des chercheurs :</p><div> <p> Dans cet article, nous �tudions comment la qualit� des r�ponses des LLM �volue en termes d'exactitude, de v�racit� et de refus des informations en fonction de trois caract�ristiques des utilisateurs : leur ma�trise de l'anglais, leur niveau d'�ducation et leur pays d'origine. Nous pr�sentons des exp�riences approfondies men�es sur trois LLM de pointe et deux ensembles de donn�es diff�rents ax�s sur la v�racit� et la factualit�. Nous montrons les performances syst�matiquement inf�rieures de GPT4, Llama 3 et Claude 3 Opus aupr�s des utilisateurs ayant une ma�trise moindre de l'anglais, un niveau d'�ducation moins �lev� et originaires de pays autres que les �tats-Unis. Cela se traduit par une pr�cision et une v�racit� r�duites des informations, une fr�quence accrue de refus de requ�tes et m�me un langage condescendant, tous ces ph�nom�nes �tant disproportionnellement plus fr�quents chez les groupes d'utilisateurs les plus marginalis�s. Ces r�sultats sugg�rent que les mod�les d�ploy�s � grande �chelle risquent de diffuser des informations erron�es en aval vers les personnes les moins � m�me de les identifier. Ce travail met en lumi�re les lacunes syst�matiques et biais�es des mod�les � l'�re des assistants IA personnalis�s aliment�s par des LLM. Cela remet en question les valeurs plus larges auxquelles nous aspirons pour aligner les syst�mes d'IA et la mani�re dont nous pourrions mieux concevoir des technologies qui... </p></div>
<p>La fin de cet article est r�serv�e aux abonn�s. Soutenez le Club Developpez.com en <a href="https://premium.developpez.com/abonnement">prenant un abonnement</a> pour que nous puissions continuer � vous proposer des publications.</p> </div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>