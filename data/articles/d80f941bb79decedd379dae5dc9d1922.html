<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Laurie Spiegel on the difference between algorithmic music and ‘AI’</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Laurie Spiegel on the difference between algorithmic music and ‘AI’</h1>
  <div class="metadata">
    Source: The Verge | Date: 2/17/2026 1:00:00 PM | <a href="https://www.theverge.com/report/879819/laurie-spiegel-is-celebrating-40-of-music-mouse-with-a-modern-revival" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div><p>In 1986, electronic music pioneer Laurie Spiegel created <a href="https://youtu.be/D-mmEvGOopk">Music Mouse</a>, a way for those with a Mac, Atari, or Amiga computer to dabble in algorithmic music creation. <a href="https://www.eventideaudio.com/software/music-mouse/">Music Mouse</a> is deceptively simple: Notes are arranged on an XY grid, and you play it by moving a mouse around. Back in 1986, the computer mouse was still a relatively novel device. While it can trace its origins back to the late ’60s, it wasn’t until the <a href="https://en.wikipedia.org/wiki/Macintosh_128K">Macintosh 128K</a> in 1984 that it started seeing widespread adoption.</p><p>By then Spiegel, was already an accomplished composer. Her 1980 album <a href="https://lauriespiegel.bandcamp.com/album/the-expanding-universe?search_item_id%3D1696851893%26search_item_type%3Da%26search_match_part%3D%253F%26search_page_id%3D5139357610%26search_page_no%3D0%26search_rank%3D2="><em>The Expanding Universe</em></a> is generally considered among the <a href="https://pitchfork.com/features/lists-and-guides/9948-the-50-best-ambient-albums-of-all-time/">greatest ambient</a> records of all time. And her composition “<a href="https://youtu.be/ErT83n_YdGs">Harmony of the Worlds</a>” is currently tearing through interstellar space as part of the Voyager Golden Record, launched in 1977. But she is also a technical wizard who joined Bell Labs in 1973 and was instrumental in early digital synthesis experiments and worked on an early computer graphics system called <a href="https://medium.com/a-computer-of-ones-own/laurie-spiegel-mother-of-vampire-42530eb6d552">Vampire</a>.</p><p>Spiegel was deeply drawn to algorithmic music composition and this new tool, the home computer. So, she created what she calls an “intelligent instrument” that enables the creation of complex melodies and harmonies with minimal music-theory knowledge. Music Mouse restricts you to particular scales, and then you explore them simply by pushing a mouse around.</p><p>Spiegel gives the user some control, of course. You can choose if notes move in parallel or contrary to each other, there are options to play notes back as chords or arpeggios, and there is even a simple pattern generator.</p><p>Despite being available for purchase until 2021, Spiegel never updated it to work on anything more current than Mac OS 9. Now, 40 years after its debut, it’s getting reborn for modern machines with help from <a href="https://www.eventideaudio.com/">Eventide</a>.</p><div><p><a href="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Music-Mouse-Hero-Lifestyle.png?quality=90&amp;strip=all&amp;crop=0,0,100,100" target="_blank"><img alt="Music Mouse running on a MacBook on a desk." src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Music-Mouse-Hero-Lifestyle.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p>While it would have been easy for Eventide and Spiegel to overload the 2026 version of Music Mouse with countless modern amenities and new features, they kept things restrained for version 1.0. The core feature set is the same, though the sound engine is more robust and includes patches based on Spiegel’s own <a href="https://www.youtube.com/watch?v=Q1Ha0MMT0aA">Yamaha DX7</a>. There are also some enhanced MIDI features, including the ability to feed data from Music Mouse into your DAW or an external synthesizer.</p><p>Laurie Spiegel answered some questions for us about the history of Music Mouse, algorithmic composition, AI, and why she thinks the computer is a “folk instrument.”</p><p><strong>What were the origins of Music Mouse? Was there something specific that inspired its creation?</strong></p><p>When the first Macs came out, the use of a mouse as an input device, as an XY controller, was altogether new. Previous computers had just alphanumeric keyboard input or maybe custom controllers. The most obvious thing I immediately wanted to do was to be able to push sound around with that mouse. So, as soon as the first C compilers came out, I coded up a way to do that. Pretty soon, though, I wanted the sound quantized into scales, then to add more voices to fill out the harmony. Then I wanted to have controls for timbre, tempo, and everything else I eventually added.</p><p><strong>How did you connect with Eventide for this new version? </strong></p><p>I first met Tony and Richard of Eventide all the way back in the early 1970s. They are longtime good friends. I’d been involved in various music tech projects at Eventide over the years. Tony knew that I really missed Music Mouse and that I still get a fair number of requests for the 1980s versions from people who keep vintage computers from that era just to be able to run Music Mouse or other obsolete software. He decided it was a musical instrument worth reviving. I had been wanting to revive it, but hadn’t been able to find the time to even just keep up with the way development tech keeps changing. My main thing is really composing music, and I have an active enough career doing that to not have enough time to do coding as well. I am extremely grateful to Eventide for resuscitating Music Mouse. I hope a lot of people will get a lot of music out of this new version.</p><p><strong>Did you feel compelled to make any big changes to it after 40 years?</strong></p><p>We decided to keep 1.0 of this new version of Music Mouse functionally the same as the 1980s original. The exceptions are adding a higher-quality internal synthesizer and providing ways to sync it with other software, to record or notate its MIDI output. We have a growing list of features to add in 2.0.</p><div><p>“It’s pretty easy by now to use computers to generate music-like material that is not actually the expression of an individual human being.”</p></div><p><strong>Are there any current innovations in music tech that excite you?</strong></p><p>That’s a hard question, because I am not all that excited about music tech right now. It’s music itself that holds my interest — composition, form, structure. I love counterpoint and the various contrapuntal forms. I studied them extensively when I was younger. Of course, harmonic progression is something I’m also very interested in, and in algorithmic assistance for composing it.</p><p>That various kinds of structures within music can now be more easily dealt with in computer software by now has both pros and cons. The pros include how much more deeply we have to understand how music works, how it is structured, and how it affects us, in order to represent it as a process description in software. That means learning, research, and self-discovery. The cons include that it’s pretty easy by now to use computers to generate music-like material that is not actually the expression of an individual human being. Music is a fundamental human experience. There is no human society that doesn’t have it. But it is something that comes from within human beings, as personal expression, as communication, as a sort of form of documentation of what we are feeling, and as a means of sharing it.</p><p><strong>You’ve been credited as saying that the computer is a new kind of folk instrument. Can you explain what you mean by that? How does something like Music Mouse fit into that model?</strong></p><p>Now that everyone with a computer or even just a phone has the ability to record and edit and play back and digitally process and transform sound, and particularly ever since sampling became a common musical technique, people have been doing remixes, collages, sonic montages… doing all kinds of stuff to audio they get from others or find online. This is very like what we used to call “the folk process,” in which music is repurposed, re-orchestrated, given new lyrics or otherwise modified as it goes from person to person and is adapted to fit what is meaningful in successive groups of people.</p><p>Music Mouse will help people create musical materials that can be used in a potentially infinite number of ways. It is a personal, often home-based instrument played by an individual, like a guitar.</p><div><p><a href="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/02-1990-LS-by-Marilyn-McLaren_cleaned.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" target="_blank"><img alt="Laurie Spiegel in 1990 in front of her Mac and a large collection of synths and other audio gear." src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/02-1990-LS-by-Marilyn-McLaren_cleaned.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><strong>You refer to Music Mouse as an “intelligent instrument”; it automates a certain amount of creation. What is the appeal of letting a computer take the wheel to a degree, as an artist?</strong></p><p>Music Mouse is not a generative algorithm or an “AI.” It’s a musical instrument that a person can play. It is, to some degree, what we used to call an “expert system,” as it has some musical expertise built in. But that is meant to be supportive for the real live human being who is playing it, not to replace them. It makes the playing of notes easier in order to let the player’s focus be on the level of phrasing or form. I have coded up generative algorithms for music. Music Mouse is not one of them. It’s an instrument that an individual can play, and it’s under their control. It enables a different perspective that’s from above the level of the individual note.</p><p><strong>Do you see a connection between modern generative AI and algorithmic composition tools?</strong></p><p>Of course. Algorithms can be used to generate music. I have written and used some. Music Mouse is not generative, though. It does nothing on its own. It’s a musical instrument played by a person.</p><p>What is currently called “AI” is different from previous generations of artificial intelligence. I expect there will doubtless be further evolution. In the early years of my use of computer logic in composing, AI was more of a rule-based practice. We would try to figure out how the mind was making a specific kind of decision, code up a simulation to test our hypothesis, and then refine our understanding in light of the result. After that, there was a period of AI taking more of a brute-force approach. Computer chess, for example, would involve generating all possible moves possible in a given situation, then eliminating those that would be less beneficial. Then neural nets were brought in for a next generation of AI. I look forward to getting beyond the imitative homogenizing LLM approach and seeing whatever comes next.</p><p>There are many ways of designing an algorithm that either generates music or else helps a human being to do that, making some of the decisions during the person’s creative process to leave them free to focus on other aspects. By taking over some of the decision-making, they can free a creative mind to focus on different perspectives. People just starting to learn music too often bog down and give up at the level of simply playing the notes, just figuring out where to put their fingers. We can make musical instruments now that let people use a bit of automation on those low levels to let them express themselves on a larger level, for example, to make gestures in texture-space rather than thinking ahead just one note at a time.</p><div><p>“Music Mouse is not a generative algorithm or an ‘AI.’ It’s a musical instrument that a person can play.”</p></div><p><strong>What do you think separates algorithmically generated music from something created by generative AI?</strong></p><p>Artificial intelligence refers to a specific subset of ways to use algorithms. An algorithm is just a description of a process, a sequence of steps to be taken. A generative algorithm can make decisions involved in the production of information, and, of course, music is a kind of information. You can think of AI as trying to simulate human intelligence. It might have a purpose, such as taking over some of our cognitive workload. In contrast, the purpose of generative algorithms is to create stuff. In music, that purpose is to create an experience.</p><p>Music Mouse is not a generative algorithmic program. It’s more of a small expert system in that it has built into it information and methods that can help its player get beyond the level of just finding notes, to the level of finding personal expression.</p><p><strong>Suno’s CEO Mikey Shulman has said that, “Increasingly taste is the only thing that matters in art and skill is going to matter a lot less.” In an age where music can be easily created using algorithms, plug-ins, and text prompts on cheap laptops and smartphones, do you see the role of composer being one primarily of curation?</strong></p><p>I can see where he’s coming from, but, no, I don’t think so. The range and kinds of skills used in the creative arts will continue to evolve and expand. But the history of creative techniques shows them to be largely cumulative versus sequential. The keyboard synthesizer has not replaced the piano, which has not replaced the harpsichord or the organ. We have them all, that whole lineage, all still in use. Each musical instrument or artistic technique implies its own unique artistic realm. Each is defined by its specific limitations, which guide us as we use them. It is true that skills and traditional techniques will be an option rather than a prerequisite to creating music and art, but people will still do them. Just as LPs and chemical film have made comebacks recently, I expect to see traditional musical skills do the same. We have had computers and synthesizers for decades, yet there are still little children captivated by instruments made out of wood or painting or drawing, and I have yet to use any music editing software that gives me the fluidity and freedom of a pencil on staff paper. There will just be more kinds of complementary ways of making music.</p><p>More importantly, we humans have imaginations and emotions. There are internal experiences going on inside of us that we feel driven to express, to communicate, to share. It doesn’t matter what machines can generate on their own. We will always have those internal subjective experiences, emotion, and imagination, and people will experience them intensely enough to feel driven to create them external to their own selves in order to communicate and share them. You can’t replace human self-expression or the need for it by simulating their results. Artistic creation comes from a fundamental human drive, the need for self-expression. Artistic creativity is an essential method of processing the intensity of being alive.</p><div><p><a href="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/03-1985-LS-by-Enrico-Ferorelli-studio-alt.jpeg?quality=90&amp;strip=all&amp;crop=0,0,100,100" target="_blank"><img alt="Laurie Spiegel in the studio in 1985." src="https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/03-1985-LS-by-Enrico-Ferorelli-studio-alt.jpeg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><strong>You told New Music USA in 2014 that, in regard to electronic music, “There is no single creator… the concept of a finite fixed-form piece with an identifiable creator that is property and a medium of exchange or the embodiment of economic value really disappears.” Does this idea shape your views on ownership of art?</strong></p><p>Those assumptions, which we inherited from the European classical model of music, are already much less prominent in our musical landscape. Improvisation, “process pieces,” the ease with which we can do transformations of audio files are all over the place. Folk music, and a lot of what we heard online here and there, might be audio that no longer has any known originator. We don’t know, and people don’t really care, who first created a swatch of sound. We are experiencing whatever has been done with it — different orchestrations, durations, signal processing. The huge proliferation of plug-ins and guitar effects pedals let anyone transform a sound beyond recognition. This is composition on a different level than on the level of the individual note, similarly to Music Mouse.</p><p>Another very important aspect of “folk music” is that it is typically played at home, with or for friends or family, or alone. This is very different from formal concert settings and programming we in the US inherited from Europe. For me, the most important musical experience is just about always at home, where we live. To quote what Pete Seeger said in his write-up of Music Mouse in <em>Sing Out</em>, that “she [meaning me] foresees a day when computer pieces will be like folksongs, anonymous common property to be altered by each new user. She would like to get music out of the concert hall and back into the living room.”</p><p>Music Mouse is available for macOS and Windows 11 for $29.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li><span><span><span></span><span>Terrence O'Brien</span></span></span></li><li></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>