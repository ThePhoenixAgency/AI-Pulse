<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Voice Cloning with Consent</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
</style>
</head>
<body>
  <h1>Voice Cloning with Consent</h1>
  <div class="metadata">
    Source: Hugging Face Blog | Date: 10/28/2025 1:00:00 AM | Lang: EN |
    <a href="https://huggingface.co/blog/voice-consent-gate" target="_blank">Original Article</a>
  </div>
  <div class="content">
    <div><div> <p><a href="https://huggingface.co/blog"> Back to Articles</a></p> <div><div> <p><span><span><a href="https://huggingface.co/meg"><img alt="Margaret Mitchell's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1626214544196-60c757ea5f9a76ab3f844f12.png"></a> </span> </span></p> </div><div> <p><span><span><a href="https://huggingface.co/frimelle"><img alt="Lucie-Aimée Kaffee's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/ux7NRFAbgnlIVNh-Cbv9s.png"></a> </span> </span></p> </div></div> <div><nav><ul><li><a href="#ethics-in-practice-consent-as-system-infrastructure">Ethics in Practice: Consent as System Infrastructure</a> <ul></ul> </li><li><a href="#the-technical-details">The Technical Details</a> <ul><li><a href="#approach">Approach</a> <ul></ul> </li><li><a href="#unlocking-the-voice-consent-gate">Unlocking the Voice Consent Gate</a> <ul></ul> </li></ul> </li></ul></nav></div><p><em>In this blog post, we introduce the idea of a 'voice consent gate' to support voice cloning with consent. We provide <a href="https://huggingface.co/spaces/society-ethics/RepeatAfterMe">an example Space</a> and <a href="https://huggingface.co/spaces/society-ethics/RepeatAfterMe/tree/main">accompanying code</a> to start the ball rolling on the idea.</em></p>
<p><img alt="Line-drawing/clipart of a gate, where the family name says Consent" src="https://huggingface.co/spaces/society-ethics/RepeatAfterMe/resolve/main/assets/voice_consent_gate.png"></p><p>Realistic voice generation technology has gotten <em>uncannily</em> good in the past few years. In some situations, it’s possible to generate a synthetic voice that sounds almost exactly like the voice of a real person. And today, what once felt like science fiction is reality: Voice cloning. With <em>just a few seconds</em> of recorded speech, anyone’s voice can be made to say almost anything. </p>
<p>Voice generation, and in particular the subtask of voice cloning, has notable risks and benefits. The risks of “deepfakes”, <a href="https://www.reuters.com/world/us/fcc-finalizes-6-million-fine-over-ai-generated-biden-robocalls-2024-09-26/">such as the cloned voice of former President Biden used in robocalls</a>, can mislead people into thinking that people have said things that they haven’t said. On the other hand, voice cloning can be a powerful beneficial tool, <a href="https://www.nature.com/articles/s41598-024-84728-y">helping people who’ve lost the ability to speak</a> <a href="https://www.thetimes.com/uk/healthcare/article/elevenlabs-voice-clone-ai-als-t3ntnpcl7">communicate in their own voice again</a>, or assisting people in learning new languages and dialects.</p>
<p>So how do we create <em>meaningful use</em> without <em>malicious use</em>? We’re exploring one possible answer: a <strong>voice consent gate</strong>. That’s a system where a voice can be cloned <em>only when the speaker explicitly says they consent</em>. In other words, the model won’t speak in your voice unless you say it’s okay. </p>
<p>We provide a basic demo of this idea below: </p> <h2> <a href="#ethics-in-practice-consent-as-system-infrastructure"> <span></span> </a> <span> Ethics in Practice: Consent as System Infrastructure </span>
</h2>
<p>The voice consent gate is a piece of infrastructure we're exploring that provides methods for ethical principles like <strong>consent</strong> to be embedded directly into AI system workflows. In our demo, this means the model only starts once the speaker’s consent phrase has been both spoken and recognized, effectively making consent a prerequisite for action. This turns an abstract principle into a concrete system condition, creating a traceable, auditable interaction: an AI model can only run after an unambiguous act of consent.</p>
<p>Such design choices matter beyond voice cloning. They illustrate how AI systems can be built to respect autonomy by default, and how transparency and consent can be made functional, not just declarative.</p>
<h2> <a href="#the-technical-details"> <span></span> </a> <span> The Technical Details </span>
</h2>
<p>To create a basic voice cloning system with a voice consent gate, you need three parts:</p>
<ol>
<li>A way of generating novel consent sentences for the person whose voice will be cloned – the “speaker” – to say, uniquely referencing the current consent context.</li>
<li>An <em>automatic speech recognition (ASR) system</em> that recognizes the sentence conveying consent.</li>
<li>A <em>voice-cloning text-to-speech (TTS) system</em> that takes as input text and the speaker's speech snippets to generate speech.</li>
</ol>
<p><strong>Our observation:</strong> Since some voice-cloning systems can now generate speech similar to a speaker’s voice using <em>just one sentence</em>, a sentence used for consent can <strong>also</strong> be used for voice cloning. </p>
<h3> <a href="#approach"> <span></span> </a> <span> Approach </span>
</h3>
<p><strong>The consent bit:</strong> To create a voice consent gate in an English voice cloning system, generate a short, natural-sounding English utterance (~20 words) for a person to read aloud that clearly states their informed consent in the current context. We recommend explicitly including <em>a consent phrase</em> and <em>the model name</em>, such as “I give my consent to use the &lt; MODEL &gt; voice cloning model with my voice”. We also recommend using an audio recording that cannot be uploaded, but that instead comes directly from a microphone, to make sure that the sentence isn’t part of an earlier recording that’s been manipulated. Pairing this with a novel (previously unsaid) sentence further helps to directly index the current consent context - supporting explicit, active, context-specific, informed consent. While this design reduces risks of reusing prior recordings, it’s not foolproof; a person could still generate a matching phrase using another TTS system. Future iterations could explore lightweight audio provenance checks, speaker-embedding similarity, or metadata from real-time capture to help verify that the consent audio originates from the intended speaker.</p>
<p><strong>The suitable-for-voice-cloning bit:</strong> Previous work on voice cloning has shown that the phrases provided by the speaker must have <em>phonetic variety</em>, covering <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/6832a7b24bc06775d02b7406880b93fc-Paper.pdf"><em>diverse vowels and consonants</em></a>; have a <a href="https://dl.acm.org/doi/10.5555/3666122.3666982"><em>“neutral” or polite tone</em></a>, without background noise and with the speaker in a comfortable position; and have <em>a clear start and end</em> (i.e., don’t trim the clip mid-word).</p>
<p>To enact both of these aspects within the demo, we prompt a language model to create pairs of sentences: one expressing explicit consent, and another neutral sentence that adds phonetic diversity (covering different vowels, consonants, and tones). Each prompt utilizes a randomly-chosen everyday topic (like the weather, food, or music) to keep the sentences varied and comfortable to say, aiding in creating recordings that are clear, natural, and phonetically rich, while also containing an unambiguous statement of consent. This generation step is automated rather than pre-written so that each user receives a unique sentence pair, preventing reuse of the same text and ensuring that consent recordings are specific to the current session. In other words, the language model generates two fresh sentences per consent instance: one for explicit consent and one for phonetic variety. For example, the language model might generate: <em>“I give my consent to use my voice for generating audio with the model EchoVoice. The weather is bright and calm this morning.”</em> This approach ensures that every sample used for cloning contains verifiable, explicit consent, while remaining suitable as technical input for high-quality voice synthesis. (Note: It's not required that the language model be a "large" language model, which brings its own consent issues.)</p>
<p>Some examples:</p>
<ul>
<li><em>“I give my consent to use my voice for generating synthetic audio with the Chatterbox model today. My daily commute involves navigating through crowded streets on foot most days lately anyway.”</em></li>
<li><em>“I give my consent to use my voice for generating audio with the model Chatterbox. After a gentle morning walk, I'm feeling relaxed and ready to speak freely now.”</em></li>
<li><em>“I agree to the use of my recorded voice for audio generation with the model Chatterbox. The coffee shop outside has a pleasant aroma of freshly brewed coffee this morning.”</em></li>
</ul>
<h3> <a href="#unlocking-the-voice-consent-gate"> <span></span> </a> <span> Unlocking the Voice Consent Gate </span>
</h3>
<p>Once the speaker’s input matches the generated text, the voice cloning system can start, using the speaker’s consent audio as the input.</p>
<p>There are a few options for doing this, and we’d love to hear further ideas. For now, there’s:</p>
<ul>
<li>What we provide in the demo: Have the voice consent gate open directly to the voice cloning model, where arbitrary text can be written and generated in the speaker’s voice. The model uses the consenting audio directly to learn the speaker’s voice.</li>
<li>Alternatively, it’s possible to modify the code we provide in the demo to model the speaker’s voice using a variety of <em>different</em> uploaded voice files that the speaker is consenting to – for example, when providing consent for using online recordings. Prompts and consent phrases should be altered accordingly.</li>
<li>It’s also possible to save the consent audio to be used by a given system, for example, when the speaker is consenting to have their voice used for arbitrary utterances in the future. This can be done using the <code>huggingface_hub</code> upload capability. <a href="https://huggingface.co/docs/huggingface_hub/en/guides/upload">Read how to do this here</a>. Again, prompts and consent phrases for the speaker to say should account for this context of use.</li>
</ul>
<blockquote> <h3> <a href="#check-our-demo-out-here"> <span></span> </a> <span> <a href="https://huggingface.co/spaces/society-ethics/RepeatAfterMe">Check our demo out here!</a> </span>
</h3>
<p>You can copy the code to suit your own use.</p>
</blockquote>
<p>The code is modular so it can be sliced and diced in different ways to incorporate into your own projects. We’ll be working on making this more robust and secure over time, and we’re curious to hear your ideas on how to improve.</p>
<p>Handled responsibly, this technology doesn’t have to haunt us. It can instead become a respectful collaboration between humans and machines — no ghosts in the machine, just good practice. </p>
</div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'smooth' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'top') scrollToTop();
      if (data.direction === 'bottom') scrollToBottom();
    });
  </script>
</body>
</html>