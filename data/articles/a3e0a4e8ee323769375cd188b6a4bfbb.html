<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Why Is My Code So Slow? A Guide to Py-Spy Python Profiling</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
</style>
</head>
<body>
  <h1>Why Is My Code So Slow? A Guide to Py-Spy Python Profiling</h1>
  <div class="metadata">
    Source: Towards Data Science | Date: 2/5/2026 2:30:00 PM | Lang: EN |
    <a href="https://towardsdatascience.com/why-is-my-code-so-slow-a-guide-to-py-spy-python-profiling/" target="_blank">Original Article</a>
  </div>
  <div class="content">
    <div><div>
<p> frustrating issues to debug in data science code aren’t syntax errors or logical mistakes. Rather, they come from code that does exactly what it is supposed to do, but takes its sweet time doing it.</p> <p>Functional but inefficient code can be a massive bottleneck in a data science workflow. In this article, I will provide a brief introduction and walk-through of <code>py-spy</code>, a powerful tool designed to profile your Python code. It can pinpoint exactly where your program is spending the most time so inefficiencies can be identified and corrected.</p> <h2>Example Problem</h2> <p>Let’s set up a simple research question to write some code for:</p> <p><strong>“For all flights going between US states and territories, which departing airport has the longest flights on average?”</strong></p> <p>Below is a simple Python script to answer this research question, using data retrieved from the <a href="https://www.transtats.bts.gov/homepage.asp">Bureau of Transportation Statistics</a> (BTS). The dataset consists of data from every flight within US states and territories between January and June of 2025 with information on the origin and destination airports. It is approximately 3.5 million rows.</p> <p>It calculates the <a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine Distance</a> — the shortest distance between two points on a sphere — for each flight. Then, it groups the results by departing airport to find the average distance and reports the top five.</p> <pre><code>import pandas as pd import math import time def haversine(lat_1, lon_1, lat_2, lon_2): """Calculate the Haversine Distance between two latitude and longitude points""" lat_1_rad = math.radians(lat_1) lon_1_rad = math.radians(lon_1) lat_2_rad = math.radians(lat_2) lon_2_rad = math.radians(lon_2) delta_lat = lat_2_rad - lat_1_rad delta_lon = lon_2_rad - lon_1_rad R = 6371 # Radius of the earth in km return 2*R*math.asin(math.sqrt(math.sin(delta_lat/2)**2 + math.cos(lat_1_rad)*math.cos(lat_2_rad)*(math.sin(delta_lon/2))**2)) if __name__ == '__main__': # Load in flight data to a dataframe flight_data_file = r"./data/2025_flight_data.csv" flights_df = pd.read_csv(flight_data_file) # Start timer to see how long analysis takes start = time.time() # Calculate the haversine distance between each flight's start and end airport haversine_dists = [] for i, row in flights_df.iterrows(): haversine_dists.append(haversine(lat_1=row["LATITUDE_ORIGIN"], lon_1=row["LONGITUDE_ORIGIN"], lat_2=row["LATITUDE_DEST"], lon_2=row["LONGITUDE_DEST"])) flights_df["Distance"] = haversine_dists # Get result by grouping by origin airport, taking the average flight distance and printing the top 5 result = ( flights_df .groupby('DISPLAY_AIRPORT_NAME_ORIGIN').agg(avg_dist=('Distance', 'mean')) .sort_values('avg_dist', ascending=False) ) print(result.head(5)) # End timer and print analysis time end = time.time() print(f"Took {end - start} s")</code></pre> <p>Running this code gives the following output:</p> <pre><code> avg_dist
DISPLAY_AIRPORT_NAME_ORIGIN Pago Pago International 4202.493567
Guam International 3142.363005
Luis Munoz Marin International 2386.141780
Ted Stevens Anchorage International 2246.530036
Daniel K Inouye International 2211.857407
Took 169.8935534954071 s</code></pre> <p>These results make sense, as the airports listed are in American Samoa, Guam, Puerto Rico, Alaska, and Hawaii, respectively. These are all locations outside of the contiguous United States where one would expect long average flight distances.</p> <p>The problem here isn’t the results — which are valid — but the execution time: <strong>almost three minutes</strong>! While three minutes might be tolerable for a one-off run, it becomes a productivity killer during development. Imagine this as part of a longer data pipeline. Every time a parameter is tweaked, a bug is fixed, or a cell is re-run, you are forced to sit idle while the program runs. That friction breaks your flow and turns a quick analysis into an all-afternoon affair.</p> <p>Now let’s see how <code>py-spy</code> can help us diagnose exactly what lines are taking so long.</p> <h2>What Is Py-Spy?</h2> <p>To understand what <code>py-spy</code> is doing and the benefits of using it, it helps to compare <code>py-spy</code> to the built-in Python profiler <code>cProfile</code>.</p> <ul>
<li><code>cProfile</code>: This is a <strong>Tracing Profiler</strong>, working similar to a stopwatch on each function call. The time between each function call and return is measured and reported. While highly accurate, this adds significant overhead, as the profiler has to constantly pause and record data, which can slow down the script significantly.</li> <li><code>py-spy</code>: This is a <strong>Sampling Profiler</strong>, working similar to a high speed camera looking at the whole program at once. <code>py-spy</code> sits completely outside the running Python script and takes high-frequency snapshots of the program’s state. It looks at the entire “Call Stack” to see exactly what line of code is being run and what function called it, all the way up to the top level.</li>
</ul> <h2>Running Py-spy</h2> <p>In order to run <code>py-spy</code> on a Python script, the <code>py-spy</code> library must be installed in the Python environment.</p> <pre><code>pip install py-spy</code></pre> <p>Once the <code>py-spy</code> library is installed, our script can be profiled by running the following command in the terminal:</p> <pre><code>py-spy record -o profile.svg -r 100 -- python main.py</code></pre> <p>Here is what each part of this command is actually doing:</p> <ul>
<li><code>py-spy</code>: Calls the tool.</li> <li><code>record</code>: This tells <code>py-spy</code> to use its “record” mode, which will continuously monitor the program while it runs and saves the data.</li> <li><code>-o profile.svg</code>: This specifies the output filename and format, telling it to output the results as an SVG file called <code>profile.svg</code>.</li> <li><code>-r 100</code>: This specifies the sampling rate, setting it to 100 times per second. This means that <code>py-spy</code> will check what the program is doing 100 times per second.</li> <li><code>--</code>: This separates the <code>py-spy</code> command from the Python script command. It tells <code>py-spy</code> that everything following this flag is the command to run, not arguments for <code>py-spy</code> itself.</li> <li><code>python main.py</code>: This is the command to run the Python script to be profiled with <code>py-spy</code>, in this case running <code>main.py</code>.</li>
</ul> <p><strong>Note</strong>: If running on Linux, <code>sudo</code> privileges are often a requirement for running <code>py-spy</code>, for security reasons.</p> <p>After this command is finished running, an output file <code>profile.svg</code> will appear which will allow us to dig deeper into what parts of the code are taking the longest.</p> <h2>Py-spy Output</h2> <figure><img src="https://contributor.insightmediagroup.io/wp-content/uploads/2026/02/image-16.png" alt=""><figcaption>Icicle Graph output from py-spy</figcaption></figure> <p>Opening up the output <code>profile.svg</code> reveals the visualization that <code>py-spy</code> has created for how much time our program spent in different parts of the code. This is known as a <strong>Icicle Graph</strong> (or sometimes a <strong>Flame Graph</strong> if the y-axis is inverted) and is interpreted as follows:</p> <ul>
<li><strong>Bars</strong>: Each colored bar represents a particular function that was called during the execution of the program.</li> <li><strong>X-axis (Population)</strong>: The horizontal axis represents the collection of all samples taken during the profiling. They are grouped so that the width of a particular bar represents the proportion of the total samples that the program was in the function represented by that bar. <strong>Note:</strong> This is <em>not</em> a timeline; the ordering does not represent when the function was called, only the total volume of time spent.</li> <li><strong>Y-axis (Stack Depth)</strong>: The vertical axis represents the call stack. The top bar labeled “all” represents the entire program, and the bars below it represent functions called from “all”. This continues down recursively with each bar broken down into the functions that were called during its execution. The very bottom bar shows the function that was actually running on the CPU when the sample was taken.</li>
</ul> <h3>Interacting with the Graph</h3> <p>While the image above is static, the actual <code>.svg</code> file generated by <code>py-spy</code> is fully interactive. When you open it in a web browser, you can:</p> <ul>
<li><strong>Search (Ctrl+F)</strong>: Highlight specific functions to see where they appear in the stack.</li> <li><strong>Zoom</strong>: Click on any bar to zoom in on that specific function and its children, allowing you to isolate complex parts of the call stack.</li> <li><strong>Hover</strong>: Hovering over any bar displays the specific function name, file path, line number, and the exact percentage of time it consumed.</li>
</ul> <p>The most critical rule for reading the icicle graph is simply: <strong>The wider the bar, the more frequent the function</strong>. If a function bar spans 50% of the graph’s width, it means that the program was working on executing that function for 50% of the total runtime.</p> <h3>Diagnosis</h3> <p>From the icicle graph above, we can see that the bar representing the Pandas <code>iterrows()</code> function is noticeably wide. Hovering over that bar when viewing the <code>profile.svg</code> file reveals that the true proportion for this function was <strong>68.36%</strong>. So over 2/3 of the runtime was spent in the <code>iterrows()</code> function. Intuitively this bottleneck makes sense, as <code>iterrows()</code> creates a Pandas Series object for every single row in the loop, causing massive overhead. This reveals a clear target to try and optimize the runtime of the script.</p> <h2>Optimizing The Script</h2> <p>The clearest path to optimize this script based on what was learned from <code>py-spy</code> is to stop using <code>iterrows()</code> to loop over every row to calculate that haversine distance. Instead, it should be replaced with a vectorized calculation using NumPy that will do the calculation for every row with just one function call. So the changes to be made are:</p> <ul>
<li>Rewrite the <code>haversine()</code> function to use vectorized and efficient C-level NumPy operations that allow whole arrays to be passed in rather than one set of coordinates at a time.</li> <li>Replace the <code>iterrows()</code> loop with a single call to this newly vectorized <code>haversine()</code> function.</li>
</ul> <pre><code>import pandas as pd import numpy as np import time def haversine(lat_1, lon_1, lat_2, lon_2): """Calculate the Haversine Distance between two latitude and longitude points""" lat_1_rad = np.radians(lat_1) lon_1_rad = np.radians(lon_1) lat_2_rad = np.radians(lat_2) lon_2_rad = np.radians(lon_2) delta_lat = lat_2_rad - lat_1_rad delta_lon = lon_2_rad - lon_1_rad R = 6371 # Radius of the earth in km return 2*R*np.asin(np.sqrt(np.sin(delta_lat/2)**2 + np.cos(lat_1_rad)*np.cos(lat_2_rad)*(np.sin(delta_lon/2))**2)) if __name__ == '__main__': # Load in flight data to a dataframe flight_data_file = r"./data/2025_flight_data.csv" flights_df = pd.read_csv(flight_data_file) # Start timer to see how long analysis takes start = time.time() # Calculate the haversine distance between each flight's start and end airport flights_df["Distance"] = haversine(lat_1=flights_df["LATITUDE_ORIGIN"], lon_1=flights_df["LONGITUDE_ORIGIN"], lat_2=flights_df["LATITUDE_DEST"], lon_2=flights_df["LONGITUDE_DEST"]) # Get result by grouping by origin airport, taking the average flight distance and printing the top 5 result = ( flights_df .groupby('DISPLAY_AIRPORT_NAME_ORIGIN').agg(avg_dist=('Distance', 'mean')) .sort_values('avg_dist', ascending=False) ) print(result.head(5)) # End timer and print analysis time end = time.time() print(f"Took {end - start} s")</code></pre> <p>Running this code gives the following output:</p> <pre><code> avg_dist
DISPLAY_AIRPORT_NAME_ORIGIN Pago Pago International 4202.493567
Guam International 3142.363005
Luis Munoz Marin International 2386.141780
Ted Stevens Anchorage International 2246.530036
Daniel K Inouye International 2211.857407
Took 0.5649983882904053 s</code></pre> <p>These results are identical to the results from before the code was optimized, but instead of taking nearly three minutes to process, <strong>it took just over half a second!</strong></p> <h2>Looking Ahead</h2> <p>If you are reading this from the future (late 2026 or beyond), check if you are running Python 3.15 or newer. Python 3.15 is expected to introduce a native sampling profiler in the standard library, offering similar functionality to <code>py-spy</code> without requiring external installation. For anyone on Python 3.14 or older <code>py-spy</code> remains the gold standard.</p> <h2>Conclusion</h2> <p>This article explored a tool for tackling a common frustration in data science — a script that functions as intended, but is inefficiently written and takes a long time to run. An example script was provided to learn which US departure airports have the longest average flight distance according to the Haversine distance. This script worked as expected, but took almost three minutes to run.</p> <p>Using the <code>py-spy</code> Python profiler, we were able to learn that the cause of the inefficiency was the use of the <code>iterrows()</code> function. By replacing <code>iterrows()</code> with a more efficient vectorized calculation of the Haversine distance, the runtime was optimized from three minutes down to just over half a second.</p> <p>See my <a href="https://github.com/KenMcCarthy24/language_substring_analysis">GitHub Repository</a> for the code from this article, including the preprocessing of the raw data from BTS. </p> <p>Thank you for reading!</p> <h2>Data Sources</h2> <ul>
<li><strong>Flight Data</strong>: Bureau of Transportation Statistics. (2026, January 22). <em>Reporting Carrier On-Time Performance (1987-present)</em> [Data set]. U.S. Department of Transportation. Retrieved from <a href="https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&amp;QO_fu146_anzr=b0-gvzr">https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&amp;QO_fu146_anzr=b0-gvzr</a></li> <li><strong>Airport Coordinates</strong>: Bureau of Transportation Statistics. (2026, January 22). <em>Aviation: Master Coordinate</em> [Data set]. U.S. Department of Transportation. Retrieved from <a href="https://transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FLL&amp;QO_fu146_anzr=N8vn6v10">https://transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FLL&amp;QO_fu146_anzr=N8vn6v10</a></li>
</ul> <p>Data from the Bureau of Transportation Statistics (BTS) is a work of the U.S. Federal Government and is in the public domain under <strong>17 U.S.C. § 105</strong>. It is free to use, share, and adapt without copyright restriction.</p>
</div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'smooth' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'smooth' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
  </script>
</body>
</html>