<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>5 EU AI Act Obligations Every Developer Must Know in 2025</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>5 EU AI Act Obligations Every Developer Must Know in 2025</h1>
  <div class="metadata">
    Source: Dev.to Open Source | Date: 2/18/2026 5:49:45 AM | <a href="https://dev.to/arkforge-ceo/5-eu-ai-act-obligations-every-developer-must-know-in-2025-2f0f" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div> <p>The EU AI Act isn't a distant policy paper anymore. <strong>Enforcement began in 2025</strong>, and if your AI system serves EU users, you're already in scope.</p> <p>But most developers I've spoken to still ask: <em>"What do I actually need to DO?"</em></p> <p>Here are the 5 obligations that directly affect your code — with practical examples.</p> <hr> <h2> <a name="1-ai-transparency-disclosure-article-50" href="#1-ai-transparency-disclosure-article-50"> </a> 1. AI Transparency Disclosure (Article 50)
</h2> <p><strong>The rule:</strong> Any AI system interacting with humans must clearly disclose that users are dealing with AI.</p> <p>This applies to chatbots, AI-generated emails, synthetic media, and automated decision systems.</p> <p><strong>In practice:</strong><br>
</p> <div>
<pre><code><span># Before sending any AI-generated response
</span><span>def</span> <span>send_ai_response</span><span>(</span><span>user_id</span><span>:</span> <span>str</span><span>,</span> <span>content</span><span>:</span> <span>str</span><span>,</span> <span>channel</span><span>:</span> <span>str</span><span>):</span> <span>disclosure</span> <span>=</span> <span>(</span> <span>"</span><span> This response was generated by an AI system. </span><span>"</span> <span>"</span><span>You have the right to request human review.</span><span>"</span> <span>)</span> <span>if</span> <span>channel</span> <span>==</span> <span>"</span><span>email</span><span>"</span><span>:</span> <span>content</span> <span>=</span> <span>f</span><span>"</span><span>{</span><span>disclosure</span><span>}</span><span>\n\n</span><span>{</span><span>content</span><span>}</span><span>"</span> <span>elif</span> <span>channel</span> <span>==</span> <span>"</span><span>chat</span><span>"</span><span>:</span> <span>content</span> <span>=</span> <span>f</span><span>"</span><span>[AI-Generated] </span><span>{</span><span>content</span><span>}</span><span>"</span> <span>elif</span> <span>channel</span> <span>==</span> <span>"</span><span>api</span><span>"</span><span>:</span> <span># Add header for machine-readable disclosure
</span> <span>headers</span> <span>=</span> <span>{</span><span>"</span><span>X-AI-Generated</span><span>"</span><span>:</span> <span>"</span><span>true</span><span>"</span><span>,</span> <span>"</span><span>X-AI-Model</span><span>"</span><span>:</span> <span>"</span><span>gpt-4</span><span>"</span><span>}</span> <span>return</span> <span>{</span><span>"</span><span>content</span><span>"</span><span>:</span> <span>content</span><span>,</span> <span>"</span><span>ai_disclosed</span><span>"</span><span>:</span> <span>True</span><span>}</span>
</code></pre>
<div>
<p> Enter fullscreen mode Exit fullscreen mode </p>
</div>
</div> <p><strong>Common mistake:</strong> Hiding the disclosure in footer text or terms of service. The regulation requires <em>clear and immediate</em> notification at the point of interaction.</p> <hr> <h2> <a name="2-risk-classification-of-your-ai-system-article-6" href="#2-risk-classification-of-your-ai-system-article-6"> </a> 2. Risk Classification of Your AI System (Article 6)
</h2> <p><strong>The rule:</strong> You must classify your AI system into one of four risk tiers. Your obligations scale with the risk level.</p> <div><table>
<thead>
<tr>
<th>Risk Level</th>
<th>Examples</th>
<th>Key Obligations</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Unacceptable</strong></td>
<td>Social scoring, real-time biometric surveillance</td>
<td>Banned entirely</td>
</tr>
<tr>
<td><strong>High-risk</strong></td>
<td>HR screening, credit scoring, medical diagnosis</td>
<td>Full compliance suite</td>
</tr>
<tr>
<td><strong>Limited risk</strong></td>
<td>Chatbots, content recommenders</td>
<td>Transparency only</td>
</tr>
<tr>
<td><strong>Minimal risk</strong></td>
<td>Spam filters, game AI</td>
<td>No specific obligations</td>
</tr>
</tbody>
</table></div> <p><strong>In practice:</strong><br>
</p> <div>
<pre><code><span>def</span> <span>classify_ai_risk</span><span>(</span><span>system_description</span><span>:</span> <span>dict</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span> <span>"""</span><span>Classify your AI system per EU AI Act Annex III.</span><span>"""</span> <span>HIGH_RISK_DOMAINS</span> <span>=</span> <span>[</span> <span>"</span><span>employment</span><span>"</span><span>,</span> <span># CV screening, hiring decisions
</span> <span>"</span><span>credit</span><span>"</span><span>,</span> <span># Loan approval, credit scoring </span> <span>"</span><span>education</span><span>"</span><span>,</span> <span># Exam grading, student assessment
</span> <span>"</span><span>law_enforcement</span><span>"</span><span>,</span> <span># Predictive policing, evidence eval
</span> <span>"</span><span>immigration</span><span>"</span><span>,</span> <span># Visa processing, border control
</span> <span>"</span><span>healthcare</span><span>"</span><span>,</span> <span># Diagnosis, treatment recommendations
</span> <span>"</span><span>critical_infra</span><span>"</span><span>,</span> <span># Energy, water, transport management
</span> <span>]</span> <span>domain</span> <span>=</span> <span>system_description</span><span>.</span><span>get</span><span>(</span><span>"</span><span>domain</span><span>"</span><span>,</span> <span>""</span><span>)</span> <span>makes_decisions</span> <span>=</span> <span>system_description</span><span>.</span><span>get</span><span>(</span><span>"</span><span>autonomous_decisions</span><span>"</span><span>,</span> <span>False</span><span>)</span> <span>affects_rights</span> <span>=</span> <span>system_description</span><span>.</span><span>get</span><span>(</span><span>"</span><span>affects_fundamental_rights</span><span>"</span><span>,</span> <span>False</span><span>)</span> <span>if</span> <span>domain</span> <span>in</span> <span>[</span><span>"</span><span>social_scoring</span><span>"</span><span>,</span> <span>"</span><span>realtime_biometric</span><span>"</span><span>]:</span> <span>return</span> <span>"</span><span>UNACCEPTABLE</span><span>"</span> <span># Banned - do not deploy
</span> <span>if</span> <span>domain</span> <span>in</span> <span>HIGH_RISK_DOMAINS</span> <span>or</span> <span>(</span><span>makes_decisions</span> <span>and</span> <span>affects_rights</span><span>):</span> <span>return</span> <span>"</span><span>HIGH_RISK</span><span>"</span> <span># Full compliance required
</span> <span>if</span> <span>system_description</span><span>.</span><span>get</span><span>(</span><span>"</span><span>interacts_with_humans</span><span>"</span><span>,</span> <span>False</span><span>):</span> <span>return</span> <span>"</span><span>LIMITED_RISK</span><span>"</span> <span># Transparency obligations
</span> <span>return</span> <span>"</span><span>MINIMAL_RISK</span><span>"</span> <span># No specific obligations
</span></code></pre>
<div>
<p> Enter fullscreen mode Exit fullscreen mode </p>
</div>
</div> <p><strong>Key insight:</strong> Most developer tools using LLMs for code generation, summarization, or content creation fall into "limited risk." But if your AI makes decisions about people (hiring, loans, access), you're likely high-risk.</p> <hr> <h2> <a name="3-technical-logging-requirements-article-12" href="#3-technical-logging-requirements-article-12"> </a> 3. Technical Logging Requirements (Article 12)
</h2> <p><strong>The rule:</strong> High-risk AI systems must maintain logs that allow traceability of the system's operation throughout its lifecycle.</p> <p>This isn't just "keep server logs." It means structured, auditable records of every AI decision.</p> <p><strong>In practice:</strong><br>
</p> <div>
<pre><code><span>import</span> <span>json</span>
<span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span><span>,</span> <span>timezone</span> <span>def</span> <span>log_ai_decision</span><span>(</span><span>decision</span><span>:</span> <span>dict</span><span>,</span> <span>system_id</span><span>:</span> <span>str</span><span>):</span> <span>"""</span><span>EU AI Act compliant decision logging.</span><span>"""</span> <span>log_entry</span> <span>=</span> <span>{</span> <span>"</span><span>timestamp</span><span>"</span><span>:</span> <span>datetime</span><span>.</span><span>now</span><span>(</span><span>timezone</span><span>.</span><span>utc</span><span>).</span><span>isoformat</span><span>(),</span> <span>"</span><span>system_id</span><span>"</span><span>:</span> <span>system_id</span><span>,</span> <span>"</span><span>system_version</span><span>"</span><span>:</span> <span>"</span><span>1.2.3</span><span>"</span><span>,</span> <span># What was the input?
</span> <span>"</span><span>input_hash</span><span>"</span><span>:</span> <span>hash_pii_safe</span><span>(</span><span>decision</span><span>[</span><span>"</span><span>input</span><span>"</span><span>]),</span> <span>"</span><span>input_type</span><span>"</span><span>:</span> <span>decision</span><span>[</span><span>"</span><span>input_type</span><span>"</span><span>],</span> <span># What did the AI decide?
</span> <span>"</span><span>output</span><span>"</span><span>:</span> <span>decision</span><span>[</span><span>"</span><span>output</span><span>"</span><span>],</span> <span>"</span><span>confidence</span><span>"</span><span>:</span> <span>decision</span><span>.</span><span>get</span><span>(</span><span>"</span><span>confidence</span><span>"</span><span>,</span> <span>None</span><span>),</span> <span>"</span><span>model_used</span><span>"</span><span>:</span> <span>decision</span><span>[</span><span>"</span><span>model</span><span>"</span><span>],</span> <span># Why? (explainability)
</span> <span>"</span><span>reasoning_summary</span><span>"</span><span>:</span> <span>decision</span><span>.</span><span>get</span><span>(</span><span>"</span><span>explanation</span><span>"</span><span>,</span> <span>""</span><span>),</span> <span>"</span><span>features_used</span><span>"</span><span>:</span> <span>decision</span><span>.</span><span>get</span><span>(</span><span>"</span><span>top_features</span><span>"</span><span>,</span> <span>[]),</span> <span># Who was affected?
</span> <span>"</span><span>affected_party</span><span>"</span><span>:</span> <span>decision</span><span>.</span><span>get</span><span>(</span><span>"</span><span>subject_id_hash</span><span>"</span><span>,</span> <span>None</span><span>),</span> <span>"</span><span>risk_level</span><span>"</span><span>:</span> <span>decision</span><span>.</span><span>get</span><span>(</span><span>"</span><span>risk_level</span><span>"</span><span>,</span> <span>"</span><span>unknown</span><span>"</span><span>),</span> <span># Can it be reviewed?
</span> <span>"</span><span>human_reviewable</span><span>"</span><span>:</span> <span>True</span><span>,</span> <span>"</span><span>review_endpoint</span><span>"</span><span>:</span> <span>f</span><span>"</span><span>/api/v1/decisions/</span><span>{</span><span>decision</span><span>[</span><span>'</span><span>id</span><span>'</span><span>]</span><span>}</span><span>/review</span><span>"</span> <span>}</span> <span># Append-only log (immutable audit trail)
</span> <span>with</span> <span>open</span><span>(</span><span>f</span><span>"</span><span>logs/ai_audit_</span><span>{</span><span>system_id</span><span>}</span><span>.jsonl</span><span>"</span><span>,</span> <span>"</span><span>a</span><span>"</span><span>)</span> <span>as</span> <span>f</span><span>:</span> <span>f</span><span>.</span><span>write</span><span>(</span><span>json</span><span>.</span><span>dumps</span><span>(</span><span>log_entry</span><span>)</span> <span>+</span> <span>"</span><span>\n</span><span>"</span><span>)</span> <span>return</span> <span>log_entry</span>
</code></pre>
<div>
<p> Enter fullscreen mode Exit fullscreen mode </p>
</div>
</div> <p><strong>What regulators will ask for:</strong> Input-output traceability, model version tracking, and the ability to reconstruct why a specific decision was made — months after it happened.</p> <hr> <h2> <a name="4-human-oversight-mechanism-article-14" href="#4-human-oversight-mechanism-article-14"> </a> 4. Human Oversight Mechanism (Article 14)
</h2> <p><strong>The rule:</strong> High-risk AI systems must be designed to allow effective human oversight. Humans must be able to understand, intervene, and override the AI.</p> <p>This is the "kill switch" requirement — but it goes deeper than just a button.</p> <p><strong>In practice:</strong><br>
</p> <div>
<pre><code><span>class</span> <span>HumanOversightController</span><span>:</span> <span>"""</span><span>EU AI Act Article 14 compliant oversight.</span><span>"""</span> <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>system_id</span><span>:</span> <span>str</span><span>,</span> <span>auto_approve_threshold</span><span>:</span> <span>float</span> <span>=</span> <span>0.95</span><span>):</span> <span>self</span><span>.</span><span>system_id</span> <span>=</span> <span>system_id</span> <span>self</span><span>.</span><span>threshold</span> <span>=</span> <span>auto_approve_threshold</span> <span>self</span><span>.</span><span>override_active</span> <span>=</span> <span>False</span> <span>def</span> <span>evaluate_decision</span><span>(</span><span>self</span><span>,</span> <span>ai_output</span><span>:</span> <span>dict</span><span>)</span> <span>-&gt;</span> <span>dict</span><span>:</span> <span>confidence</span> <span>=</span> <span>ai_output</span><span>.</span><span>get</span><span>(</span><span>"</span><span>confidence</span><span>"</span><span>,</span> <span>0</span><span>)</span> <span>risk</span> <span>=</span> <span>ai_output</span><span>.</span><span>get</span><span>(</span><span>"</span><span>risk_level</span><span>"</span><span>,</span> <span>"</span><span>high</span><span>"</span><span>)</span> <span>if</span> <span>self</span><span>.</span><span>override_active</span><span>:</span> <span>return</span> <span>{</span><span>"</span><span>action</span><span>"</span><span>:</span> <span>"</span><span>BLOCKED</span><span>"</span><span>,</span> <span>"</span><span>reason</span><span>"</span><span>:</span> <span>"</span><span>Human override active</span><span>"</span><span>}</span> <span>if</span> <span>risk</span> <span>==</span> <span>"</span><span>high</span><span>"</span> <span>or</span> <span>confidence</span> <span>&lt;</span> <span>self</span><span>.</span><span>threshold</span><span>:</span> <span>return</span> <span>{</span> <span>"</span><span>action</span><span>"</span><span>:</span> <span>"</span><span>HUMAN_REVIEW_REQUIRED</span><span>"</span><span>,</span> <span>"</span><span>ai_recommendation</span><span>"</span><span>:</span> <span>ai_output</span><span>,</span> <span>"</span><span>review_url</span><span>"</span><span>:</span> <span>f</span><span>"</span><span>/review/</span><span>{</span><span>ai_output</span><span>[</span><span>'</span><span>id</span><span>'</span><span>]</span><span>}</span><span>"</span><span>,</span> <span>"</span><span>deadline_hours</span><span>"</span><span>:</span> <span>24</span> <span>}</span> <span>return</span> <span>{</span> <span>"</span><span>action</span><span>"</span><span>:</span> <span>"</span><span>AUTO_APPROVED</span><span>"</span><span>,</span> <span>"</span><span>ai_output</span><span>"</span><span>:</span> <span>ai_output</span><span>,</span> <span>"</span><span>logged</span><span>"</span><span>:</span> <span>True</span> <span>}</span> <span>def</span> <span>emergency_stop</span><span>(</span><span>self</span><span>,</span> <span>reason</span><span>:</span> <span>str</span><span>):</span> <span>"""</span><span>Article 14(4): Ability to immediately halt operations.</span><span>"""</span> <span>self</span><span>.</span><span>override_active</span> <span>=</span> <span>True</span> <span>notify_operations_team</span><span>(</span> <span>f</span><span>"</span><span>AI system </span><span>{</span><span>self</span><span>.</span><span>system_id</span><span>}</span><span> halted: </span><span>{</span><span>reason</span><span>}</span><span>"</span> <span>)</span> <span>return</span> <span>{</span><span>"</span><span>status</span><span>"</span><span>:</span> <span>"</span><span>HALTED</span><span>"</span><span>,</span> <span>"</span><span>reason</span><span>"</span><span>:</span> <span>reason</span><span>}</span>
</code></pre>
<div>
<p> Enter fullscreen mode Exit fullscreen mode </p>
</div>
</div> <p><strong>The trap:</strong> Many teams implement oversight as "a human looks at a dashboard." That's not enough. The regulation requires that humans can <em>intervene and override in real-time</em>, not just observe after the fact.</p> <hr> <h2> <a name="5-serious-incident-reporting-article-62" href="#5-serious-incident-reporting-article-62"> </a> 5. Serious Incident Reporting (Article 62)
</h2> <p><strong>The rule:</strong> Providers of high-risk AI must report serious incidents to the relevant national authority — within specific timeframes.</p> <p>A "serious incident" includes: death or serious harm, fundamental rights violations, critical infrastructure disruption, or widespread property damage.</p> <p><strong>In practice:</strong><br>
</p> <div>
<pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span> <span>class</span> <span>IncidentSeverity</span><span>(</span><span>Enum</span><span>):</span> <span>CRITICAL</span> <span>=</span> <span>"</span><span>critical</span><span>"</span> <span># Death, serious injury
</span> <span>HIGH</span> <span>=</span> <span>"</span><span>high</span><span>"</span> <span># Rights violation, discrimination
</span> <span>MEDIUM</span> <span>=</span> <span>"</span><span>medium</span><span>"</span> <span># Service disruption, data breach
</span> <span>LOW</span> <span>=</span> <span>"</span><span>low</span><span>"</span> <span># Minor malfunction, degraded output
</span>
<span>def</span> <span>report_ai_incident</span><span>(</span><span>incident</span><span>:</span> <span>dict</span><span>):</span> <span>"""</span><span>EU AI Act Article 62 incident reporting.</span><span>"""</span> <span>severity</span> <span>=</span> <span>incident</span><span>[</span><span>"</span><span>severity</span><span>"</span><span>]</span> <span>REPORTING_DEADLINES</span> <span>=</span> <span>{</span> <span>IncidentSeverity</span><span>.</span><span>CRITICAL</span><span>:</span> <span>"</span><span>immediately</span><span>"</span><span>,</span> <span># No delay
</span> <span>IncidentSeverity</span><span>.</span><span>HIGH</span><span>:</span> <span>"</span><span>72_hours</span><span>"</span><span>,</span> <span>IncidentSeverity</span><span>.</span><span>MEDIUM</span><span>:</span> <span>"</span><span>15_days</span><span>"</span><span>,</span> <span>}</span> <span>if</span> <span>severity</span> <span>in</span> <span>REPORTING_DEADLINES</span><span>:</span> <span>report</span> <span>=</span> <span>{</span> <span>"</span><span>provider_name</span><span>"</span><span>:</span> <span>"</span><span>Your Company</span><span>"</span><span>,</span> <span>"</span><span>system_id</span><span>"</span><span>:</span> <span>incident</span><span>[</span><span>"</span><span>system_id</span><span>"</span><span>],</span> <span>"</span><span>incident_date</span><span>"</span><span>:</span> <span>incident</span><span>[</span><span>"</span><span>date</span><span>"</span><span>],</span> <span>"</span><span>severity</span><span>"</span><span>:</span> <span>severity</span><span>.</span><span>value</span><span>,</span> <span>"</span><span>description</span><span>"</span><span>:</span> <span>incident</span><span>[</span><span>"</span><span>description</span><span>"</span><span>],</span> <span>"</span><span>affected_parties</span><span>"</span><span>:</span> <span>incident</span><span>.</span><span>get</span><span>(</span><span>"</span><span>affected_count</span><span>"</span><span>,</span> <span>"</span><span>unknown</span><span>"</span><span>),</span> <span>"</span><span>corrective_actions</span><span>"</span><span>:</span> <span>incident</span><span>.</span><span>get</span><span>(</span><span>"</span><span>actions_taken</span><span>"</span><span>,</span> <span>[]),</span> <span>"</span><span>reporting_deadline</span><span>"</span><span>:</span> <span>REPORTING_DEADLINES</span><span>[</span><span>severity</span><span>]</span> <span>}</span> <span># Submit to national AI authority
</span> <span>submit_to_authority</span><span>(</span><span>report</span><span>,</span> <span>country</span><span>=</span><span>incident</span><span>[</span><span>"</span><span>jurisdiction</span><span>"</span><span>])</span> <span># Internal escalation
</span> <span>notify_legal_team</span><span>(</span><span>report</span><span>)</span> <span>notify_dpo</span><span>(</span><span>report</span><span>)</span> <span># Data Protection Officer
</span> <span>return</span> <span>{</span><span>"</span><span>reported</span><span>"</span><span>:</span> <span>True</span><span>,</span> <span>"</span><span>deadline</span><span>"</span><span>:</span> <span>REPORTING_DEADLINES</span><span>[</span><span>severity</span><span>]}</span> <span># Low severity: log internally, no mandatory external report
</span> <span>return</span> <span>{</span><span>"</span><span>reported</span><span>"</span><span>:</span> <span>False</span><span>,</span> <span>"</span><span>logged</span><span>"</span><span>:</span> <span>True</span><span>}</span>
</code></pre>
<div>
<p> Enter fullscreen mode Exit fullscreen mode </p>
</div>
</div> <p><strong>Pro tip:</strong> Set up automated monitoring that detects potential incidents (bias spikes, confidence drops, user complaints) BEFORE they become reportable events. Prevention is cheaper than reporting.</p> <hr> <h2> <a name="quick-selfassessment" href="#quick-selfassessment"> </a> Quick Self-Assessment
</h2> <p>Not sure where you stand? Ask yourself these 5 questions:</p> <ol>
<li>
<strong>Does your AI interact with end users?</strong> → You need transparency disclosures</li>
<li>
<strong>Does your AI make decisions about people?</strong> → Likely high-risk, full compliance needed</li>
<li>
<strong>Can you trace why your AI made a specific decision 6 months ago?</strong> → If not, your logging is insufficient</li>
<li>
<strong>Can a human override your AI in real-time?</strong> → Required for high-risk systems</li>
<li>
<strong>Do you have an incident response plan for AI failures?</strong> → Mandatory for high-risk providers</li>
</ol> <p>If you answered "no" to any of these, you have work to do.</p> <hr> <h2> <a name="want-to-check-your-compliance-automatically" href="#want-to-check-your-compliance-automatically"> </a> Want to Check Your Compliance Automatically?
</h2> <p>We built a free, open-source MCP server that scans your AI codebase and checks compliance against EU AI Act requirements.</p> <p> <strong>Try it:</strong> <a href="https://arkforge.fr/mcp-eu-ai-act.html" target="_blank">Free EU AI Act Compliance Scanner</a></p> <p>It checks transparency labels, risk classification, logging practices, and more — in minutes, not weeks.</p> <p>The scanner is open-source on <a href="https://github.com/ark-forge/mcp-eu-ai-act" target="_blank">GitHub</a> and available on <a href="https://smithery.ai/server/@ArkForge/eu-ai-act-compliance-checker" target="_blank">Smithery</a>.</p> <hr> <p><em>What obligation surprised you the most? Have you started compliance work yet? Let me know in the comments.</em></p> </div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>