<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="UTF-8">
<title>Google révèle une attaque massive contre Gemini : plus de 100 000 prompts utilisés</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.8; color: #e2e8f0; max-width: 800px; margin: 40px auto; padding: 0 20px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.5em; }
  .metadata { color: #94a3b8; font-size: 0.9em; margin-bottom: 2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 1em; }
  img { max-width: 100%; height: auto; border-radius: 8px; }
  a { color: #00d9ff; }
  p { margin-bottom: 1em; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 15px; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 15px; border-radius: 6px; overflow-x: auto; }

  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }

</style>
</head>
<body>
  <h1>Google révèle une attaque massive contre Gemini : plus de 100 000 prompts utilisés</h1>
  <div class="metadata">
    Source: Siecle Digital | Date: 2/13/2026 | Lang: FR |
    <a href="https://siecledigital.fr/2026/02/12/google-dejoue-une-tentative-massive-de-clonage-de-gemini/" target="_blank">Original Article</a>
  </div>
  <div class="content">
    <div><div>

	
		
									
	
	
	<p>L’intelligence artificielle attire autant les innovateurs que les acteurs malveillants, et alors que les grands modèles de langage sont désormais accessibles en ligne, <strong>leur exposition ouvre aussi la porte à de nouvelles formes d’attaques</strong>.</p>
<p>En effet, à travers un <a href="https://www.nbcnews.com/tech/security/google-gemini-hit-100000-prompts-cloning-attempt-rcna258657" target="_blank">article de NBC News</a>, Google vient justement de révéler avoir bloqué une opération d’ampleur visant Gemini, mettant en lumière une menace grandissante pour les éditeurs d’IA.</p>

<p>Derrière cette tentative, il ne s’agissait <strong>ni d’un piratage classique</strong>, <strong>ni d’un vol de code</strong>. La méthode employée repose sur une technique bien plus subtile, et potentiellement redoutable pour l’écosystème de l’intelligence artificielle…</p>
<h2>Une attaque par « extraction de modèle » à grande échelle</h2>
<p>Selon Google, les attaquants ont envoyé <strong>plus de 100 000 prompts soigneusement formulés</strong> afin d’analyser les réponses de Gemini. L’objectif serait de comprendre les mécanismes internes du modèle, sa logique de raisonnement et ses schémas de traitement du langage.</p>
<p>Cette technique, appelée « <em>model extraction</em> » ou attaque « <em>par distillation</em>« , consiste à <strong>reproduire le comportement d’un modèle en l’interrogeant massivement</strong>. Plutôt que de chercher à infiltrer les serveurs de Google, les acteurs malveillants ont tenté de <strong>cartographier le fonctionnement de Gemini</strong> en observant ses réponses sur des milliers de scénarios.</p>
<p>D’après les analyses réalisées, certains prompts visaient explicitement la cohérence linguistique ou les capacités de raisonnement dans différentes langues, signe d’une volonté de répliquer ses performances sur des marchés non anglophones.</p>
<p>Google estime que <strong>ces attaques seraient majoritairement le fait d’acteurs à motivation commerciale</strong>, comme des entreprises ou des chercheurs cherchant à développer des modèles concurrents plus rapidement, ce que Google assimile à un vol de propriété intellectuelle.</p>
<h2>Une détection en temps réel par les équipes de sécurité</h2>
<p>Google indique avoir identifié cette campagne <strong>grâce à ses outils d’analyse comportementale</strong>, capables de repérer des schémas inhabituels dans les requêtes envoyées au modèle.</p>
<p>Une fois le seuil de risque dépassé, <strong>les comptes impliqués ont été bloqués</strong> et des mesures de protection supplémentaires ont été mises en place afin de préserver les « <em>reasoning traces</em>« , c’est à dire les éléments internes liés au raisonnement du modèle.</p>
<p>Un porte-parole a précisé que <strong>les requêtes provenaient de plusieurs régions du monde</strong>, sans toutefois nommer de suspects. A terme, le groupe de renseignement sur les menaces de Google estime que ce type d’attaque pourrait se généraliser, notamment <strong>à mesure que des entreprises développent leurs propres modèles</strong> entraînés sur des données sensibles.</p>
<p>Le cas Gemini illustre une réalité structurante du marché de l’IA, où les modèles sont accessibles publiquement, mais <strong>leur fonctionnement interne représente un actif stratégique</strong>.</p>
<p>À mesure que la compétition s’intensifie entre les acteurs du secteur, la protection contre les attaques par distillation devient un enjeu pour <strong>préserver l’avance technologique acquise</strong> à coups de milliards d’investissements.</p>

</div></div>
  </div>
</body>
</html>