<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Seed News - ByteDance Seed Team</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Seed News - ByteDance Seed Team</h1>
  <div class="metadata">
    Source: Hacker News (nouveautés) | Date: 2/27/2026 8:10:45 PM | <a href="https://seed.bytedance.com/en/blog/seed2-0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div>
<p> <span>Products powered by large language models have been deeply integrated into our lives. In the past year or so, the LLM model series developed by Seed has supported C-end products with hundreds of millions of users, such as Doubao. Meanwhile, we've also noticed that with the arrival of the Agent era, LLMs will play an even more significant role in complex real-world tasks. For example, it can participate in scientific research, support complex software development, and even autonomously learn from context to complete various tasks with economic value.</span></p>
<p> <span><span>At this pivotal moment, we are honored to introduce&nbsp;</span></span><strong><span><span>the latest Seed2.0 series</span></span></strong><span><span>. It has been systematically optimized to meet the requirements of large-scale production deployment,&nbsp;</span></span><strong><span><span>aiming to help tackle complex real-world tasks.</span></span></strong>
</p>
<p> <span><span>By analyzing how the Seed general-purpose model is invoked in the MaaS service, we discovered that the highest proportion of requests is to process knowledge-intensive content from unstructured sources, like complex charts and documents. Companies usually expect the model to start with tasks that require "heavy reading and deep thinking" before engaging in complex and professional workflows. This places increasingly high demands on the model's ability to understand long content and execute multi-step tasks.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymloz8qca.jpg"><span><span><br></span></span>
</p> <p> <span><span>The distribution of Seed general-purpose model MaaS service usage scenarios in China's mainland, with data sourced from the " Volcengine Ark Collaboration Incentive Program," and relevant users have signed authorization agreements.</span></span>
</p>
<p> <span><span>Based on real-world usage scenarios, the Seed2.0 series has been optimized in the following aspects:</span></span>
</p>
<ul> <li> <p> <strong><span><span>More robust visual and multi-modal understanding:</span></span></strong><span><span>&nbsp;Seed2.0 has enhanced its visual perception and reasoning capabilities. It can now parse complex documents, tables, graphs, and video content with significantly improved accuracy, processing visual information more precisely.</span></span> </p> </li> <li> <p> <strong><span><span>More reliable execution of complex instructions:</span></span></strong><span><span>&nbsp;Seed2.0 has improved its instruction-following and reasoning performance and strengthened its capability to understand and execute tasks with multiple constraints, multiple steps, and long chains. It has now laid a foundation for supporting high-value tasks.</span></span> </p> </li> <li> <p> <strong><span><span>Faster and more flexible reasoning options</span></span></strong><span><span>:&nbsp;</span><span>Seed2.0 offers three general-purpose Agent models of different sizes - Pro, Lite, and Mini, along with a dedicated Code model, covering requirements under different scenarios for companies and developers to choose from.</span></span> </p> </li>
</ul>
<p> <span><span>Seed2.0 prioritizes user experience under large-scale online deployment, as evidenced by strong results on the LMSYS Chatbot Arena, a public human preference benchmark. Seed ranks 6th on the LMSYS Chatbot Arena — Text Arena (Overall) leaderboard and 3rd on the Vision Arena leaderboard as of Feb 16, 2026.</span></span>
</p>
<p> <span><span><b>In addition to better supporting production-level requirements, Seed2.0 is dedicated to striving for maximum model intelligence.</b> It has now advanced from solving Olympiad-level problems to handling research-level reasoning tasks. For example, Seed2.0 can explore Erdős-level math problems and also perform programming tasks related to some scientific tasks, further expanding the boundaries of machine intelligence.</span></span>
</p>
<p> <span><span>The Seed2.0 Pro and Code models have been launched on the Doubao App and TRAE, and the model API for the Seed2.0 full series is available on Volcano Engine. We welcome everyone to try it out and offer feedback.</span></span>
</p>
<blockquote> <p> <span><span>Homepage (including Model Card):&nbsp;</span></span><span> </span></p><span> </span><p><span> </span><span><span>https://seed.bytedance.com/seed2</span></span> </p>
</blockquote> <p> <strong><span><span>Comprehensive Upgrade to Multimodal Understanding</span></span></strong><strong><span><br></span></strong>
</p>
<p> <strong><span><span>SOTA</span></span></strong><strong><span><span>&nbsp;Performance Across Most Benchmarks</span></span></strong>
</p>
<p> <span><span>Seed2.0 delivers a comprehensive upgrade to multimodal capabilities,&nbsp;</span></span><strong><span><span>reaching industry-leading performance across a wide range of visual understanding tasks.</span></span></strong><span><span>&nbsp;It shows especially strong performance in visual reasoning, perception, spatial reasoning, and long-context understanding. Seed2.0 Pro achieves top scores on most major benchmarks.</span></span>
</p>
<p> <span><span>In math and visual reasoning, Seed2.0 Pro reaches state-of-the-art results on benchmarks such as MathVista, MathVision, MathKangaroo, and MathCanvas. It also delivers significantly higher scores than Seed1.8 on visual puzzle and logical reasoning benchmarks, including LogicVista and VisuLogic.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymloza828.jpg">
</p> <p> <span><span>Data marked with * comes from publicly available technical reports.</span></span>
</p>
<p> <span><span>Seed2.0's visual perception capabilities have been further enhanced. It achieves industry-leading scores on benchmarks such as VLMsAreBiased, VLMsAreBlind, and BabyVision, demonstrating accurate and reliable perception and judgment ability across diverse types of visual inputs.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozax9g.jpg">
</p> <p> <span><span>Data marked with * comes from publicly available technical reports.</span></span>
</p>
<p> <span><span>The progress in core visual understanding significantly boosts Seed2.0's performance in real-world scenarios. In document understanding tasks, models often receive raw materials with complex layouts rather than standardized inputs. Compared with Seed1.8, Seed2.0 shows markedly stronger capabilities in handling unstructured information, reaching top-tier performance on ChartQAPro and OmniDocBench 1.5.</span></span>
</p>
<p> <span><span>In long-context understanding, Seed2.0 achieves industry-best results on DUDE, MMLongBench, and MMLongBench-Doc.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozbmrj.jpg">
</p> <p> <span><span>Data marked with * comes from publicly available technical reports.</span></span>
</p>
<p> <span><span>For video scenarios, Seed2.0 strengthens its understanding of temporal sequences and motion perception. It ranks among the leading players on key benchmarks, including TVBench, TempCompass, and MotionBench, and surpasses human-level performance on EgoTempo. This reflects more stable and precise capture of changes, actions, and rhythm, translating into stronger engineering robustness and real-world readiness.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozcqle.jpeg">
</p> <p> <span><span>Data marked with * comes from publicly available technical reports</span></span>
</p>
<p> <span><span>In long-video scenarios, Seed2.0 outperforms other leading models across most evaluations. It efficiently and accurately handles hour-long videos. Additionally, the VideoCut tool further extends the duration range for processing long videos and improves inference accuracy. In real-world enterprise deployments with lengthy and information-dense videos, Seed2.0 can quickly capture key video information and generate accurate conclusions for downstream decision-making.</span></span>
</p>
<p><span>At the same time, Seed2.0 performs strongly across multiple real-time streaming video QA benchmarks. As an AI assistant, it can handle many tasks, such as real-time video streaming analysis, environment awareness and active error correction—upgrading interaction from passive Q&amp;A to proactive guidance, with applications in fitness, styling, and other scenarios.</span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozd8yq.jpg">
</p> <p> <span><span>Data marked with * comes from publicly available technical reports</span></span>
</p> <p> <strong><span><span>Substantial Enhancements in LLM and Agent Performance</span></span></strong>
</p>
<p> <strong><span><span>Elevated Capabilities to Execute Real-World Long-Horizon Tasks</span></span></strong>
</p>
<p> <span><span>The Seed team observed a notable capability gap: While language models have demonstrated high proficiency in solving complex contest problems, they still struggle with end-to-end tasks in the real world—such as building a well-designed, fully functional mini-app in a single pass.</span></span>
</p>
<p> <span><span>Why do LLMs and Agents often hit a wall when handling real-world tasks? We believe the reasons are mainly twofold:</span></span>
</p>
<ul> <li> <p> <span><span>Real-world tasks usually span longer time frames and involve multiple stages. Existing LLM Agents struggle to independently construct efficient workflows and gain experience over extended periods.</span></span> </p> </li>
</ul>
<ul> <li> <p> <span><span>Real-world knowledge has significant domain barriers and follows a long-tail distribution. Industry-specific knowledge typically lies in the long tail of the training corpus. Therefore, even models that excel in math and code fall short in specialized settings.</span></span> </p> </li>
</ul>
<p> <span><span>Seed2.0 first addresses this challenge by&nbsp;</span></span><strong><span><span>systematically strengthening knowledge in long-tail domains</span></span></strong><span><span>. Seed2.0 Pro has scored higher than GPT-5.2 on SuperGPQA. Its overall performance in the scientific field is on par with Gemini 3 Pro and GPT-5.2.</span></span>
</p>
<p> <span><span>In addition, Seed2.0 Pro has significantly enhanced its capability to apply interdisciplinary knowledge. It delivered exceptional performance in STEM benchmark tests, such as FrontierSci, with scores in some scenarios exceeding GPT-5.2. Meanwhile, Seed2.0 Pro achieved gold medal results in ICPC, IMO, and CMO tests, demonstrating further improvements in the model's mathematical, coding, and reasoning intelligence capabilities.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymm35oi2l.jpeg"></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozfddp.jpeg"></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozfopl.jpeg">
</p> <p> <span><span>Seed2.0 has also significantly strengthened its ability to follow instructions. Relevant evaluations show that Seed2.0 can maintain strong consistency and controllability, laying a foundation for it to execute long-chain, multi-step tasks strictly in accordance with constraints as an Agent model.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozg40k.jpg">
</p> <p> <span><span>As evidenced by its foundational Agent capability scores,&nbsp;</span></span><strong><span><span>Seed2.0 demonstrates outstanding performance in long-chain tasks</span></span></strong><span><span>. It is particularly adept at continuously executing sequential workflows such as "retrieving information, making summaries, and drawing conclusions". In search and deep research tasks, Seed2.0 achieved high scores across seven evaluations including BrowseComp-zh and HLE-text, demonstrating its advancement capabilities and stability in research tasks.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymm35q1k9.jpeg"></p> <p> <span><span>In the assessment of complex Agent capabilities, Seed2.0 achieves top-tier performance in the industry. For example, when evaluated on real-world tasks with direct economic value, Seed2.0 demonstrates consistent performance across high-frequency user scenarios, such as customer service Q&amp;A, information extraction, intent recognition, and K-12 problem-solving. In complex professional task benchmarks such as GDPVal - Diamond and XPert Bench, the model has also achieved competitive results, suggesting it can handle long-chain, multi-constraint query tasks effectively.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozgwxb.jpg">
</p> <p> <span><span>At the same time, Seed2.0 Pro delivers strong performance on frontier research benchmarks such as FrontierSci-research and leads on AInstein Bench, demonstrating strong hypothesis-driven reasoning capabilities in scientific discovery scenarios.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozi85x.jpg">
</p> <p> <span><span><b>In addition, Seed2.0 can turn "research ideas" into "actionable experiment plans".</b></span></span>
</p>
<p> <span><span>Taking Golgi protein analysis as an example, it not only outlines the overall experimental strategy, but also connects gene engineering, mouse model construction, subcellular fractionation, and multi-omics analysis into a coherent end-to-end workflow. It further specifies how to execute key steps, what controls to use to rule out contamination, and which metrics to apply to assess purity. Domain experts note that the plans generated by Seed2.0 exceed their expectations of large language models in terms of cross-disciplinary experimental detail and step-by-step clarity. Its responses go beyond high-level strategy, producing well-structured, scientifically sound, and executable experimental drafts.</span></span></p><p><img src="https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymlozip29.jpg">
</p> <p> <span><span><b>While improving multi-step task execution capabilities, Seed2.0 further reduces inference costs.</b> Its performance is comparable to other leading large language models in the industry, while token pricing is lowered by approximately an order of magnitude. In real-world complex tasks, where large-scale reasoning and long-chain generation consume substantial tokens, this cost advantage becomes even more critical.</span></span>
</p>
<p> <em><span><span>*For a detailed overview of the evaluation benchmarks and additional real-world case studies of Seed2.0, please refer to the Model Card.</span></span></em>
</p> <p> <strong><span><span>Summary and Outlook</span></span></strong>
</p>
<p> <span><span>In response to the real needs and use cases of companies and users, we have curated and built a series of evaluation benchmarks to create an evaluation system for large language models.</span></span>
</p>
<p> <span><span>Leveraging this reliable and forward-looking evaluation system, Seed2.0 enhances multimodal understanding and reasoning capabilities, while tackling challenges such as long-tail knowledge and following complex instructions. This improves the model's reliability in complex, long-duration real-world tasks. In evaluations based on real-world application scenarios, Seed2.0 performs excellently, reaching top-tier industry levels and demonstrating potential to support scientific research tasks.</span></span>
</p>
<p> <span><span>While Seed2.0 has made significant progress in end-to-end code generation and contextual learning, there is still room for improvement in some challenging and difficult benchmarks compared to top global models. Going forward, we will continue to iterate the Seed language model with real-world scenarios in mind, continuously striving for maximum intelligence.</span></span></p>
</div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>