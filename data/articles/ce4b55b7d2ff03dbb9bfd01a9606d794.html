<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Trump orders US agencies to stop use of Anthropic technology amid dispute over ethics of AI</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  h2, h3 { line-height: 1.28; margin: 1.1em 0 0.45em; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  ul, ol { margin: 0.5em 0 0.9em 1.1em; }
  li { margin: 0.18em 0; }
  blockquote { border-left: 3px solid #825ee4; padding-left: 12px; margin: 0.8em 0; color: #94a3b8; }
  code { background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 3px; color: #ff79c6; }
  pre { background: rgba(0,0,0,0.4); padding: 12px; border-radius: 6px; overflow-x: auto; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
  [id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"],
  [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"],
  [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"] {
    display: none !important;
    visibility: hidden !important;
    pointer-events: none !important;
  }
</style>
</head>
<body>
  <h1>Trump orders US agencies to stop use of Anthropic technology amid dispute over ethics of AI</h1>
  <div class="metadata">
    Source: The Guardian World | Date: 2/28/2026 4:44:36 AM | <a href="https://www.theguardian.com/us-news/2026/feb/27/trump-anthropic-ai-federal-agencies" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <div><div><p><a href="https://www.theguardian.com/us-news/donaldtrump">Donald Trump</a> said Friday he will direct all federal agencies to “IMMEDIATELY CEASE” all use of Anthropic technology in the latest instalment of a very public clash over AI safety.</p><p>The Department of Defense and Anthropic hit an impasse with neither side backing down as a deadline for an agreement lapsed on Friday afternoon. The Pentagon had demanded the artificial intelligence company loosen ethical guidelines on its AI systems or face severe consequences.</p><p>Trump weighed in just an hour before the deadline, <a href="https://truthsocial.com/@realDonaldTrump/posts/116144552969293195">saying</a> on Truth Social: “The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War, and force them to obey their Terms of Service instead of our Constitution.”</p><p>“WE will decide the fate of our Country – NOT some out-of-control, Radical Left AI company run by people who have no idea what the real World is all about,” Trump wrote.</p><p>Hours after its competitor was punished, <a href="https://www.theguardian.com/technology/openai">OpenAI</a> CEO Sam Altman announced on Friday night that his company had struck a deal with the Pentagon to supply AI to classified military networks, potentially filling a gap created by Anthropic’s ouster.</p><p>However, Altman said the same red lines that were the sticking point in Anthropic’s dispute with the Pentagon were now enshrined in OpenAI’s new partnership.</p><p>“Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems,” Altman <a href="https://x.com/sama/status/2027578652477821175">wrote</a>, adding that the Pentagon “agrees with these principles, reflects them in law and policy, and we put them into our agreement”.</p><p>Altman also said he hoped the Pentagon would “offer these same terms to all AI companies” as a way to “de-escalate away from legal and governmental actions and toward reasonable agreements”.</p><p>Shortly after the Friday deadline passed, defense secretary Pete Hegseth said he was directing his department to classify Anthropic as a supply-chain risk to national security, claiming Anthropic’s “stance is fundamentally incompatible with American principles”. This type of designation is normally used for foreign adversaries and could endanger the company’s partnerships with other businesses.</p><p>“Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic,” Hegseth <a href="https://x.com/SecWar/status/2027507717469049070">wrote</a> on X. “America’s warfighters will never be held hostage by the ideological whims of Big Tech.”</p><p>Hegseth said the Pentagon, which had a <a href="https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations">$200m, two-year agreement</a> with Anthropic, will continue to use Anthropic’s AI services for a transition period of no more than six months.The government services administration <a href="https://www.gsa.gov/about-us/newsroom/news-releases/gsa-stands-with-president-trump-on-national-security-ai-directive-02272026">followed</a> Hegseth’s lead and said Friday evening that it too had terminated its contracts with Anthropic.</p><p>Despite the force of the federal government coming down on Anthropic, it’s still possible that the AI firm and the Pentagon could reach some sort of agreement. It’s also possible that other AI companies could take over Anthropic’s contracts.</p><p>Anthropic responded late on Friday with a <a href="https://www.anthropic.com/news/statement-comments-secretary-war">statement</a> saying it hadn’t received direct communications from the defense department or the White House regarding the status of the negotiations, but that it was “deeply saddened” by the unfurling of events that took place over the last 24 hours.</p><p>“We will challenge any supply chain risk designation in court,” Anthropic said, adding that designating the company as such was “an unprecedented action … never before publicly applied to an American company”.</p><p>The public showdown between the Department of Defense and Anthropic began earlier this week after they entered into discussions about the military’s use of the company’s Claude AI system<em>.</em> But the talks broke down as both sides appeared to be unable to come to agreement over safety guardrails.</p><figure></figure><p>Anthropic, which presents itself as the most <a href="https://www.theguardian.com/technology/2026/jan/27/wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns">safety-forward</a> of the leading AI companies, has been mired in months of disagreement with the Pentagon even before the public discussions began this week. US defense officials have pushed for unfettered access to Claude’s capabilities that they say can help protect the country, while Anthropic has <a href="https://www.wsj.com/politics/national-security/woke-ai-spat-escalates-between-pentagon-and-anthropic-433b7c5c">resisted</a> allowing its product to be used for mass surveillance or autonomous weapons systems that can kill people without human input.</p><p>“No amount of intimidation or punishment from the Department of War will change our position on mass domestic surveillance or fully autonomous weapons,” Anthropic said in its statement on Friday night.</p><p>“We have tried in good faith to reach an agreement with the Department of War, making clear that we support all lawful uses of AI for national security aside from the two narrow exceptions above,” the company continued. “To the best of our knowledge, these exceptions have not affected a single government mission to date.”</p><p>Pentagon spokesperson Sean Parnell said Thursday the defense department “has no interest” in using AI for mass surveillance or to develop autonomous weapons. “This narrative is fake and being peddled by leftists in the media,” he said.</p><p>In Silicon Valley, Anthropic has drawn support from its most fierce rivals. Top executives at AI companies have publicly sided with Anthropic, including OpenAI CEO Sam Altman who indicated in a <a href="https://www.cnbc.com/2026/02/27/openai-sam-altman-de-escalate-tensions-pentagon-anthropic.html">CNBC interview</a> on Friday that OpenAI shares the same red lines as Anthropic.</p><p>Nearly 500 OpenAI and Google employees have also signed onto an <a href="https://notdivided.org/">open letter</a> saying “we will not be divided”. Both OpenAI and Google also have contracts with the military.</p><p>“The Pentagon is negotiating with Google and OpenAI to try to get them to agree to what Anthropic has refused,” reads the letter. “They’re trying to divide each company with fear that the other will give in.”</p><figure></figure></div></div>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function stripBlockingPanels() {
      const selector = '[id*="overlay"], [class*="overlay"], [id*="modal"], [class*="modal"], [id*="popup"], [class*="popup"], [id*="paywall"], [class*="paywall"], [id*="subscribe"], [class*="subscribe"], [id*="cookie"], [class*="cookie"], [id*="consent"], [class*="consent"], [id*="gdpr"], [class*="gdpr"], [role="dialog"], [aria-modal="true"]';
      const textPattern = /\b(cookie|consent|gdpr|subscribe|subscription|paywall|abonnez[-\s]?vous|inscrivez[-\s]?vous|continue reading|continuez la lecture)\b/i;
      document.querySelectorAll(selector).forEach((node) => node.remove());
      document.querySelectorAll('div, section, aside').forEach((node) => {
        const styleAttr = String(node.getAttribute('style') || '').toLowerCase();
        const classAndId = String(node.className || '').toLowerCase() + ' ' + String(node.id || '').toLowerCase();
        const text = String(node.textContent || '').slice(0, 800);
        const hasKeyword = textPattern.test(classAndId) || textPattern.test(text);
        const looksFixed = /(position\s*:\s*(fixed|sticky)|inset\s*:|top\s*:|left\s*:|right\s*:|bottom\s*:)/.test(styleAttr);
        const hasPriority = /(z-index\s*:\s*[1-9]\d{1,}|backdrop-filter|overflow\s*:\s*hidden)/.test(styleAttr);
        if (hasKeyword && (looksFixed || hasPriority)) node.remove();
      });
    }
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
    stripBlockingPanels();
    setTimeout(stripBlockingPanels, 60);
    setTimeout(stripBlockingPanels, 220);
    setTimeout(stripBlockingPanels, 650);
  </script>
</body>
</html>