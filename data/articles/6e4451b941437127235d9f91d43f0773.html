<!DOCTYPE html><html lang="en"><head>
<meta charset="UTF-8">
<title>Claude Just Beat ChatGPT on Benchmarks - How Long Will It Last?</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.55; color: #e2e8f0; max-width: 800px; margin: 26px auto; padding: 0 18px; background: #0a0e27; }
  h1 { color: #00d9ff; margin-bottom: 0.35em; line-height: 1.22; font-size: clamp(1.45rem, 2.1vw, 1.95rem); font-weight: 700; }
  .metadata { color: #94a3b8; font-size: 0.86em; margin-bottom: 1.2em; border-bottom: 1px solid rgba(0,217,255,0.2); padding-bottom: 0.7em; }
  p { margin-bottom: 0.72em; line-height: 1.58; }
  img { max-width: 100%; width: auto !important; height: auto !important; object-fit: contain !important; border-radius: 8px; display: block; margin: 0.6em auto; }
  a { color: #00d9ff; }
  .article-elevator { position: fixed; right: 14px; bottom: 14px; display: flex; flex-direction: column; gap: 8px; z-index: 9999; }
  .article-elevator-btn { width: 36px; height: 36px; border: 1px solid rgba(0,217,255,0.35); border-radius: 10px; background: rgba(10,14,39,0.88); color: #00d9ff; cursor: pointer; font-size: 16px; line-height: 1; }
  .article-elevator-btn:hover { background: rgba(10,14,39,1); }
</style>
</head>
<body>
  <h1>Claude Just Beat ChatGPT on Benchmarks - How Long Will It Last?</h1>
  <div class="metadata">
    Source: Dev.to Open Source | Date: 2/16/2026 10:08:51 PM | <a href="https://dev.to/dropthe/claude-just-beat-chatgpt-on-benchmarks-how-long-will-it-last-44a5" target="_blank" rel="noopener noreferrer">Lien</a> | Lang: EN
  </div>
  <div class="content">
    <p>Originally published on DropThe.org.
GPT-4 held the crown for nearly a year. Claude Opus 4.6 might hold it for weeks. The pattern is clear: every new AI king rules for less time than the last.
On February 5, 2026, Anthropic released Claude Opus 4.6. It topped SWE-bench Verified at 80.8%, crushed ARC-AGI-2 at 68.8%, and posted an 84.0% on BrowseComp search. Nine days later, it still sits at or near the top of most leaderboards.
But how long will that last? History says: not very.
We tracked every major model release since late 2022 and measured how long each one held the top spot on key benchmarks before being overtaken. The results tell a story of accelerating displacement.
AI MODEL REIGN DURATION — Days as benchmark leader
ChatGPT (GPT-4)
~365 d
Claude 3 Opus
~67 d
GPT-4o
~92 d
Claude 3.5 Sonnet
~80 d
o1-preview
~90 d
DeepSeek R1
~30 d
Gemini 2.5 Pro
~40 d
Claude 3.5 Sonnet v2
~50 d
Claude 4 Opus
~42 d
Gemini 3 Pro
~35 d
GPT-5.2
~37 d
Claude Opus 4.6
9 d+
Source: DropThe.org analysis of benchmark leadership periods | DROPTHE_
DROPTHE INTEL
The chart tells the whole story. GPT-4 reigned for roughly a year. By 2025, no model held the top spot for more than three months.</p>
  </div>
  <div class="article-elevator" aria-label="Navigation article">
    <button class="article-elevator-btn" type="button" onclick="scrollToTop()">▲</button>
    <button class="article-elevator-btn" type="button" onclick="scrollToBottom()">▼</button>
  </div>
  <script>
    function scrollToTop() {
      window.scrollTo({ top: 0, behavior: 'auto' });
    }
    function scrollToBottom() {
      window.scrollTo({ top: document.documentElement.scrollHeight, behavior: 'auto' });
    }
    window.addEventListener('message', (event) => {
      const data = event && event.data;
      if (!data || data.type !== 'AI_PULSE_SCROLL') return;
      if (data.direction === 'up' || data.direction === 'top') scrollToTop();
      if (data.direction === 'down' || data.direction === 'bottom') scrollToBottom();
    });
  </script>

</body></html>